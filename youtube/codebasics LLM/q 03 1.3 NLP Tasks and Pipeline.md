## 1.3 NLP Tasks and Pipeline

## Questions



#### 1. Which of the following are true about the Rules and Heuristics approach in NLP?  
A) It relies on handcrafted patterns like regular expressions.  
B) It requires large labeled datasets for training.  
C) It does not involve machine learning or deep learning.  
D) It is highly flexible and adapts well to varied text inputs.  

#### 2. In the context of text classification, why is converting text into numerical vectors necessary?  
A) Because machine learning models can only process numerical data.  
B) To reduce the size of the dataset for faster processing.  
C) To capture semantic meaning of words directly.  
D) To enable statistical analysis and pattern recognition by models.  

#### 3. What is a key limitation of using simple Count Vectorizer for text representation in machine learning?  
A) It cannot handle unseen words during prediction.  
B) It captures the semantic meaning of words effectively.  
C) It ignores the order of words in a sentence.  
D) It requires deep learning models to function.  

#### 4. Which of the following statements about sentence embeddings generated by models like BERT are correct?  
A) Sentence embeddings map semantically similar sentences to similar vectors.  
B) They rely on handcrafted rules and regular expressions.  
C) Cosine similarity is used to measure closeness between sentence vectors.  
D) They cannot be used for tasks like spam detection or text similarity.  

#### 5. In the NLP pipeline, what is the primary purpose of sentence segmentation?  
A) To convert text into numerical vectors.  
B) To split a large text into meaningful sentences.  
C) To remove stop words and punctuation.  
D) To identify the language of the text.  

#### 6. Why is lemmatization generally preferred over stemming in NLP preprocessing?  
A) Lemmatization uses grammar and vocabulary knowledge to find the base form.  
B) Stemming always produces grammatically correct base words.  
C) Lemmatization can handle irregular word forms like "ate" → "eat".  
D) Stemming is computationally more expensive than lemmatization.  

#### 7. Which of the following are typical steps involved in building an NLP model for support ticket classification?  
A) Data acquisition from databases or cloud storage.  
B) Manual tagging of tickets if labels are unavailable.  
C) Directly deploying the raw text into a deep learning model without preprocessing.  
D) Feature engineering to convert text into numerical features.  

#### 8. What is the role of a confusion matrix in evaluating an NLP classification model?  
A) To visualize the number of correct and incorrect predictions per class.  
B) To measure the similarity between two sentences.  
C) To tune hyperparameters of the model automatically.  
D) To identify which classes the model confuses most often.  

#### 9. Which of the following best describe the difference between information extraction and information retrieval?  
A) Information extraction pulls specific data points from text.  
B) Information retrieval returns entire documents relevant to a query.  
C) Both tasks always use the same algorithms and techniques.  
D) Information retrieval is primarily used in search engines like Google.  

#### 10. In the context of chatbots, what distinguishes a flow-based bot from an FAQ bot?  
A) Flow-based bots maintain context across multiple turns in a conversation.  
B) FAQ bots provide fixed answers without considering previous dialogue.  
C) Flow-based bots cannot handle open-ended conversations.  
D) FAQ bots use deep learning to generate responses dynamically.  

#### 11. Which of the following are challenges in sentence segmentation?  
A) Handling abbreviations like "Dr." or "etc." that contain periods.  
B) Splitting sentences only at every period without exceptions.  
C) Accounting for language-specific grammar rules.  
D) Ignoring punctuation marks like question marks or exclamation points.  

#### 12. Why might a machine learning model trained on historical support tickets fail when deployed in production?  
A) Concept drift, where language or terminology changes over time.  
B) The model was trained on too much data.  
C) Lack of monitoring and updating after deployment.  
D) The model was built using deep learning instead of rules.  

#### 13. Which of the following are true about TF-IDF vectorization?  
A) It weighs words based on their frequency in a document and rarity across documents.  
B) It is a method to convert text into vectors for machine learning.  
C) It captures the semantic meaning of words better than word embeddings.  
D) It can be used in both information retrieval and text classification tasks.  

#### 14. What is the main advantage of using deep learning-based sentence embeddings over traditional count-based vectorizers?  
A) They can capture context and semantic similarity between words and sentences.  
B) They require no training data at all.  
C) They produce sparse vectors with many zeros.  
D) They handle unseen words and phrases better during prediction.  

#### 15. Which of the following are common machine learning classifiers used in NLP tasks?  
A) Naive Bayes  
B) Support Vector Machine (SVM)  
C) Random Forest  
D) Regular Expressions  

#### 16. What is the purpose of feature engineering in the NLP pipeline?  
A) To extract meaningful numerical representations from text data.  
B) To manually label the dataset for supervised learning.  
C) To convert raw text into tokens and sentences.  
D) To improve model performance by selecting or creating relevant features.  

#### 17. Which of the following statements about language modeling are correct?  
A) Language models predict the probability of the next word in a sequence.  
B) They are used in autocomplete features like Gmail suggestions.  
C) Language models only use statistical methods, never neural networks.  
D) Both statistical and neural language models exist.  

#### 18. In topic modeling, what is the main goal?  
A) To extract abstract topics from a large collection of documents.  
B) To classify documents into predefined categories.  
C) To summarize documents into a few sentences.  
D) To detect hate speech in social media posts.  

#### 19. Which of the following are true about deploying an NLP model in production?  
A) The model should be wrapped in a REST API for easy access.  
B) Monitoring is unnecessary once the model is deployed.  
C) Cloud platforms like AWS, Azure, or Google Cloud can host the model.  
D) Periodic retraining may be required to handle new data or concept drift.  

#### 20. Why is it important to discard irrelevant information like creator name or timestamp when preprocessing support tickets?  
A) Because such information does not influence the priority classification.  
B) To reduce noise and improve model accuracy.  
C) Because machine learning models cannot process non-textual data.  
D) To simplify the input data and focus on meaningful text content.  



<br>

## Answers



#### 1. Which of the following are true about the Rules and Heuristics approach in NLP?  
A) ✓ Relies on handcrafted patterns like regex, no ML involved.  
B) ✗ Does not require large labeled datasets; it’s rule-based.  
C) ✓ No machine learning or deep learning involved.  
D) ✗ Not flexible; struggles with varied or unexpected text.  

**Correct:** A, C


#### 2. In the context of text classification, why is converting text into numerical vectors necessary?  
A) ✓ ML models require numerical input, not raw text.  
B) ✗ Vectorization is not primarily for reducing dataset size.  
C) ✗ Count vectors do not capture semantic meaning directly.  
D) ✓ Enables statistical pattern recognition by ML models.  

**Correct:** A, D


#### 3. What is a key limitation of using simple Count Vectorizer for text representation in machine learning?  
A) ✓ Cannot handle unseen words well during prediction.  
B) ✗ Does not capture semantic meaning; only counts words.  
C) ✓ Ignores word order, treats text as a bag of words.  
D) ✗ Does not require deep learning to function.  

**Correct:** A, C


#### 4. Which of the following statements about sentence embeddings generated by models like BERT are correct?  
A) ✓ Embeddings map semantically similar sentences to similar vectors.  
B) ✗ They are learned representations, not handcrafted rules.  
C) ✓ Cosine similarity measures closeness between vectors.  
D) ✗ They are widely used for spam detection and similarity tasks.  

**Correct:** A, C


#### 5. In the NLP pipeline, what is the primary purpose of sentence segmentation?  
A) ✗ Vectorization happens after segmentation.  
B) ✓ Splits large text into meaningful sentences.  
C) ✗ Removing stop words is a different step.  
D) ✗ Language identification is separate from segmentation.  

**Correct:** B


#### 6. Why is lemmatization generally preferred over stemming in NLP preprocessing?  
A) ✓ Uses grammar and vocabulary to find correct base forms.  
B) ✗ Stemming often produces incorrect or incomplete roots.  
C) ✓ Handles irregular forms like "ate" → "eat".  
D) ✗ Lemmatization is usually more computationally expensive.  

**Correct:** A, C


#### 7. Which of the following are typical steps involved in building an NLP model for support ticket classification?  
A) ✓ Data acquisition is the first step.  
B) ✓ Manual tagging if labels are missing.  
C) ✗ Raw text must be preprocessed before modeling.  
D) ✓ Feature engineering converts text to numbers.  

**Correct:** A, B, D


#### 8. What is the role of a confusion matrix in evaluating an NLP classification model?  
A) ✓ Visualizes correct and incorrect predictions per class.  
B) ✗ It does not measure sentence similarity.  
C) ✗ Hyperparameter tuning is a separate process.  
D) ✓ Identifies which classes are confused by the model.  

**Correct:** A, D


#### 9. Which of the following best describe the difference between information extraction and information retrieval?  
A) ✓ Extraction pulls specific data points from text.  
B) ✓ Retrieval returns entire relevant documents.  
C) ✗ They use different algorithms and techniques.  
D) ✓ Retrieval is used in search engines like Google.  

**Correct:** A, B, D


#### 10. In the context of chatbots, what distinguishes a flow-based bot from an FAQ bot?  
A) ✓ Flow-based bots maintain context across turns.  
B) ✓ FAQ bots provide fixed answers without context.  
C) ✗ Flow-based bots can handle some open-ended dialogue.  
D) ✗ FAQ bots typically do not use deep learning for dynamic responses.  

**Correct:** A, B


#### 11. Which of the following are challenges in sentence segmentation?  
A) ✓ Abbreviations with periods can confuse simple split rules.  
B) ✗ Splitting at every period without exceptions causes errors.  
C) ✓ Grammar rules must be considered for accurate splitting.  
D) ✗ Punctuation like question marks are important sentence boundaries.  

**Correct:** A, C


#### 12. Why might a machine learning model trained on historical support tickets fail when deployed in production?  
A) ✓ Concept drift changes language or terminology over time.  
B) ✗ Too much training data rarely causes failure.  
C) ✓ Lack of monitoring means issues go unnoticed.  
D) ✗ Model type (deep learning vs rules) is not the main cause.  

**Correct:** A, C


#### 13. Which of the following are true about TF-IDF vectorization?  
A) ✓ Weighs words by frequency in document and rarity across corpus.  
B) ✓ Converts text into vectors for ML models.  
C) ✗ Does not capture semantic meaning as well as embeddings.  
D) ✓ Used in both information retrieval and classification.  

**Correct:** A, B, D


#### 14. What is the main advantage of using deep learning-based sentence embeddings over traditional count-based vectorizers?  
A) ✓ Capture context and semantic similarity effectively.  
B) ✗ They do require training data (pretrained or fine-tuned).  
C) ✗ Produce dense, not sparse, vectors.  
D) ✓ Handle unseen words and phrases better during prediction.  

**Correct:** A, D


#### 15. Which of the following are common machine learning classifiers used in NLP tasks?  
A) ✓ Naive Bayes is widely used for text classification.  
B) ✓ SVM is a popular classifier for NLP.  
C) ✓ Random Forest can be used for classification.  
D) ✗ Regular expressions are not classifiers but rule-based tools.  

**Correct:** A, B, C


#### 16. What is the purpose of feature engineering in the NLP pipeline?  
A) ✓ Extract meaningful numerical features from text.  
B) ✗ Labeling is a separate data preparation step.  
C) ✗ Tokenization is preprocessing, not feature engineering.  
D) ✓ Improves model performance by selecting relevant features.  

**Correct:** A, D


#### 17. Which of the following statements about language modeling are correct?  
A) ✓ Predicts probability of next word(s) in a sequence.  
B) ✓ Used in autocomplete features like Gmail.  
C) ✗ Neural language models are common today.  
D) ✓ Both statistical and neural models exist.  

**Correct:** A, B, D


#### 18. In topic modeling, what is the main goal?  
A) ✓ Extract abstract topics from large document collections.  
B) ✗ Classification assigns documents to predefined categories.  
C) ✗ Summarization condenses text, not topics.  
D) ✗ Hate speech detection is a classification task.  

**Correct:** A


#### 19. Which of the following are true about deploying an NLP model in production?  
A) ✓ Wrapping the model in a REST API enables easy access.  
B) ✗ Monitoring is essential to detect performance issues.  
C) ✓ Cloud platforms are commonly used for hosting models.  
D) ✓ Periodic retraining handles new data and concept drift.  

**Correct:** A, C, D


#### 20. Why is it important to discard irrelevant information like creator name or timestamp when preprocessing support tickets?  
A) ✓ Such info usually does not affect priority classification.  
B) ✓ Removing noise improves model accuracy.  
C) ✗ ML models can process non-textual data if encoded properly.  
D) ✓ Simplifies input and focuses on meaningful text content.  

**Correct:** A, B, D

