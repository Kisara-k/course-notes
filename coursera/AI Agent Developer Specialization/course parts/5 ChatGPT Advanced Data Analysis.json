[
  {
    "index": 1,
    "title": "1 ChatGPT with Advanced Data Analysis",
    "content": "Welcome to this course on ChatGPT code interpreter. Code interpreter is an amazing new capability that has been built into ChatGPT if you have the ChatGPT plus subscription. Now, I want to show you why this capability is so exciting and I'm going to walk you through some examples. I'm going to start off with the most interesting document on the planet. It's actually not at all. It's the Vanderbilt travel business expense policy, and I deal with this document all the time. How can we make it more interesting with code interpreter? Well, let's start off with one of the basic things that code interpreter allows us to do, which is to upload a document and have code interpreter read it. I'll just stop for a second and wrap your mind around that we're having this AI tool, read this complex document that we just looked at. This is a document meant for humans, so we're going to upload it and have code interpreter read it so that it can answer questions about it. Rather than me emailing the person who is always trying to help me with travel expense questions, I can just go into code interpreter and start asking questions about this document and what it says. What does it do? It goes and reads the document and it provides us some basic information, some summary of it, which is fascinating, but let's get more interesting. Let's see how much we can push code interpreter. I'm just going to say, let's assume I am in a foreign country traveling in a taxi and it breaks down on the way to an important meeting, can I get reimbursed if I pay someone to drive me on the back of their motorcycle to the meeting, assuming they are private citizen. This tends to look more like the questions I actually ask, the travel expense people. Now, it's not usually, this crazy, but it's always like I was going here, this got canceled, this happen now what do I do? Can it handle this level and scale and scope of question? The answer is it can. It says based on the information provided in the document, the key points relevant to your question are as follows, and notice what it's doing, it's telling us what in the document is relevant to our question, and it, trying to help us answer it. University requires travelers to select the most reasonable and economical form of transportation. Riding on a motorcycle, is it reasonable and economical we'll find out. Non-conventional transportation options are not explicitly mentioned in the policy so it doesn't say that you can write on the back of a motorcycle, just know that non-conventional and notice it figured out this is non-conventional. Then Vanderbilt does not have a separate policy on ride-sharing. You're doing ride-sharing here, although we don't normally think of riding on the back of a motorcycle in a strange situation if ride-sharing really is and it's telling us that. Then it goes on and it says, given these points, it seems plausible that in an emergency situation where no other reasonable and economical form of transportation is available, the cost of transportation by a private citizens motorcycle might be considered an allowable expense. That's good enough for me, but then it also nicely hedges its bets and I'm guessing it's from the document it says, however, the University's policy does not explicitly state this and reimbursement may be subject to review. Well, that's a pretty good answer. Now, let's do something more interesting, I'm always submitting receipts and they get rejected. Why does this receipt being rejected? Why is this travel expense being rejected? If I could only figure this out before I actually, submitted it, so I don't waste all this time going back and forth. I'm going to take it and I'm going to tell it to apply that travel and expense reimbursement policy that had just read to this rental car receipt that I'm uploading. Take that prior document and now, apply it to this document that I'm about to give you. Here's what it says. It goes through the receipt and it says, Hey, this is a rental car receipt, and it's going to determine if it complies to the travel and business expense policy that we previously reviewed, and it finds something really interesting. The collision and damage waiver and that's basically, insurance that I'm buying on the car and I'm paying for it except for domestic travel, the CDW should be declined as rental vehicles are fully insured through Vanderbilt's insurance portfolio. It's telling me, hey, you just uploaded a receipt, it includes this charge for this specific type of insurance. Vanderbilt's policy does not allow you to get reimbursed for that because you weren't supposed to get it in the first place because Vanderbilt's insurance already has it. That's pretty amazing, we just took one document and you'll, if you'll remember, this wasn't a trivial document, this was a complex document. It ended applied it to a receipt after asking questions about riding in the back of a motorcycle, or what else can we do with it. Here's a PDF of Vanderbilt's enrollment report. This is something that gets published by the registrar and has all this information that we'd like to be able to analyze, but it's trapped in a PDF. Can we go and do something with it? Well, I'm just going to ask it to extract all the pages of this PDF into separate files, which it can do and it gives us a link to every single page. Now, as we could have had it as a PDF, in this case, I had to turn them all into plain text. Now what I'm going to say, it's just summarize what's on page 4 for me. Page 4 is of the page I believe that we saw at the beginning of this a second ago. Now it's gone and it's read the page and it's explaining to us what's on the page and notice it has all the data. It's looked at all the data. I just say, hey, turn it into an Excel file for me so I can do something with it. It's going to take that PDF page and it's turning it into an Excel file now that I could download and do something with and analyze myself. But why would I analyze it myself when I could just ask it to do it for me. I'm going to ask it to display four interesting visualizations of the data and notice I'm not telling it what to visualize, how to visualize it. What's important than just say, go figure it out, go generate something interesting for me to help me explore this dataset. It goes through and it says I'm going to do a bar plot, a pie chart, a heat map, and a line plot, none of which I told it it had to do and here they are. It's visualize the data. It's gone into and taken notice of PDF page, it's read it, it's extracted the data, it's turned it into an Excel file. It's now visualized the data on that page four different ways that it chose and I'm looking at, what else can say I do with this? Let's turn it into slides. I've uploaded a slide template for it. It's actually a slide template that I use for a lot of my presentations. I just tell it, hey, save each of those visualizations you created as an image and now insert each one of them as a slide in this presentation. By the way, I want you to write some text in a text box on the slide describing what's in that visualization and it does it. Here's what it looks like in PowerPoint, we have the overall visualization here in the center, on the side of it we have a description of what it is that it's written itself. Now I've got all those visualizations as slides. Now I want you to stop for a moment and realize how amazing this is what we've just seen. I wanted to take you back to when Jane Goodall first realized that chimpanzees were using tools. Or advisor Louis Leakey famously stated, now we must redefine tool, redefine man, or accept chimpanzees as human. I want you to think about how profound what we just saw was. This is something that we never thought a tool could do. Our tool is doing something new. Like this isn't really the tools that we've seen in the past. This isn't the straight work office programs you've been working with. This is something transformative and new that really is going to redefine our experience as humans and work, and redefine how we can augment our intelligence, our productivity, our creativity if we know how to tap into these tools, which is all about what I'm going to teach you in this class. Now, what makes this so amazing is I want you to just use an image in your head throughout this course to think about what's going on. Imagine you've got a shovel in your hands and you're going to dig a hole. But right before you go to dig that hole, your shovel looks down and notice there's a rock right where you're going to dig that hole, and your shovel jumps out of your hands, builds a pickaxe itself, breaks up the rock, and then your shovel jumps back into your hands and you continue digging. That's what you're going to have happen over and over with code interpreter, is it's going to build its own pickaxe to solve a problem that it sees that needs to be solved in order to accomplish the task that you're trying to do. Your shovel that you're holding is going to jump out of your hands. It's going to build a pickaxe. It's going to break up rocks and your path, and it's going to jump back in your hand over and over through this course. Now I'm going to show you where that just happened, that you didn't even realize. When I told it, for example, to save each of these visualizations as images, this little gray box popped up, and when it was working and had a little progress indicator, but it says finished working right now. That little gray box that says finished working is the tool building happening. That's your shovel jumping out of your hands and building a pickaxe in order to break up a rock. If we expand that little gray box, what we see is what's really happening behind the scenes and as you can see it's writing computer software. It wrote its own program to go and solve your problem. What you're looking at there is literally a tool that is built for itself to go and take all those images and save them as files so that it can later go and insert them into the PowerPoint. It wrote a tool for itself to build the PowerPoint. It wrote a tool for itself to do every one of those tasks that I did. My shovel jumped out of my hand over and over it built a pickaxe. It built all kinds of other interesting tools in order to help solve problems that I have. In this course, you're going to learn how to use the most sophisticated advanced tool on the planet. You're going to learn how to use it to augment your intelligence, your creativity, your ability to get work done, your productivity. All these things are going to be augmented by this tool. They're not going to replace you, they're going to give you superpowers in your work, in your art, in your life, and whatever you need to do, you just need to know how to talk to them effectively, how to communicate well, how to structure your thinking and problem-solving. We're going to talk about all those things in this course.\n\nLet's take a look at what's really new about ChatGPT Code Interpreter. So if you've ever experimented with ChatGPT and you open up code interpreter, it looks really similar, right? This is just an option underneath the models right now. Now, this is probably going to change and go out of beta at some point, but it just looks like anything else, right? You still have ChatGPT, you still have the ability to send it chat messages. But the real difference that you want to pay attention to is this plus button right here, that says Upload file. Now, there's lots and lots of other things that you can do with it, but I want to start here because this is one of the most important pieces. Now, one of the things we've always heard is, it doesn't have my data, it wasn't trained on my data. It can't do anything with my documents, with my files. And this little plus button, that Upload file is what changes that. And that's one of the big differences between ChatGPT and code interpreter, is now we can give it our data. So I'm just going to open up some fake sales data, and I'm not even going to tell it anything, I'm just going to upload the data and let it take a look at it. So what we see here is Code interpreter is actually taking our data, and it's saying, okay, you've uploaded a CSV file or composite rated value list. You can imagine data that you have in Excel or numbers or whatever it is, Google Sheets, you can export it as CSV file. It could be sales data, it could be whatever interesting data you have. It could also be documents, it can be PDFs, it can be images, it can be videos, can be all kinds of things. And so the key is that, you can go and upload your own information. Now, in the background right here, it's going through and processing and basically reading the file that we uploaded. And you'll see that it's actually discovering what's inside of this data. So I uploaded a data set. It's a fake Excel data set or a comma separated value list that shows a bunch of sales data. We've got orders, order quantity, prices, order dates, addresses, all kinds of interesting things. And it's a bunch of fake order data that I got off of Kaggle. Now, what can we do with this? Well, it's now it's gone and created a simple table. It's showing us what's in the data set. And notice all I did was upload the data set. Well, let's get started. Let's say, for example, can you visualize some of this data? Create five interesting visualizations. So I'm just going to tell it to go and select its own things. Go and give us some visualizations of what's in there. Sometimes you get a data set and you don't even know what's in there, or you don't even know where to start in exploring it. Now, the key is that we are uploading our own information, but it's also able to do more than just answer questions based on text, like ChatGPT. It can actually go and perform complex analysis by it's writing its own software on the back end. So when you send questions in, when you send documents in, it's actually writing little bits of software to go and process that data that you're giving it, to process the questions that you're asking and to help you perform things. So in this case right here, it took the data, and I said, can you visualize something about it? Give me five interesting visualizations and it says, sure, here's a few ideas. We'll do sales distribution, sales by country, sales by month, sales by deal size and a correlation heat map. And it describes what all these are, and it's picking out the visualizations based on what it knows is in the data and then it's visualizing all of it for us. So if we wanted to then go in and drill into these visualizations, which we will do at a later point in time, we could, but the key to this is, before we didn't have any way to go in and give it our own information. We didn't have it a way to give it our own data. And that's a big limitation of the existing mall. Now, we could copy and paste limited amounts in, but this we can actually go and do large volumes of data, or much larger volumes than before, and we can go and do really interesting things. We can give it our documents, and then it can go and use different tools and write pieces of software to actually interact with the data that we give it.\n\nWe're going to walk through a more complicated example, but hopefully it's an example, but it'll also help you think about how you could use this on a daily basis. Probably most people do things with PowerPoint on a regular basis, or you have to do it every once in a while on a regular basis, and you don't necessarily like it because you have to go and create all these PowerPoint slides. Maybe you are doing sales or marketing, and you need a way to take in the latest data it and add it into a PowerPoint presentation. You need to do some visualization, and you need to put all this together. I have to do things like this all the time. And so I think this is a great example of the power of using code interpreter to build out workflows for ourselves, to help us accomplish different daily activities, either in work or life, whatever it is. So we're going to start off with uploading. I'm going to take a PowerPoint presentation that I created as part of my Vanderbilt Initiative on the Future of Learning that talks a little bit about the Future of Learning initiative. But the idea behind this is I'm going to pretend that I have some data that I need to visualize and incorporate into that PowerPoint presentation. So I'm going to say, I'm going to need your help creating some data visualizations and inserting them into this PowerPoint presentation. I will upload the data next. So I start off with that, and I upload the PowerPoint presentation directly to code interpreter. Now, the next thing we see is it basically has gone through, and it says, I see that you've uploaded the PowerPoint presentation. However, we still need the data that you'd like to visualize. Please upload the data file as well. And so then I go through and I say, please create full visualizations of this data. And I upload the CSV file for some fake marketing data, some sales data, whatever it is you want to call it. And we see code interpreter going through, and it's interpreting all this data. It's pulling out all of the different columns. And I could have gone at this point and visualized anything I wanted. You can imagine that you're going and you're doing fourth quarter sales or whatever it is, or looking at competitive analysis with your closest competitor, trying to do something interesting with it. You could go and do whatever you wanted. In this case, I don't have any particular ideas behind this thing, so I'm just going to go and say, create four interesting visualizations. Use Chat GPT and code interpreter. Go figure it out and do something for me. And it goes and creates four visualizations for me. They're not the most exciting visualizations ever, but they're good, there's visualizations of the data. It gives me basically four things, total sales per year, average quantity ordered per year. All these things I could have gone and told it exactly what I wanted, but all I wanted to do was just get some visualizations. Now, here's where it gets interesting. I'm going to tell code interpreter, I'm going to say, now please insert each of these visualizations as a separate slide into the presentation. Please start inserting them at the second slide. And so it goes and takes all these visualizations and it inserts them, and you notice right here now I've got a link where I could download the updated presentation. So it's actually gone and built all the visualizations. And now I've directly inserted them into the slides. Now, I could have stopped there, but when I do it, I get some visualizations that don't have much text to them. I just get some graphs. And maybe that's what you want. Maybe you want to just go with the stock that comes out of there. Just one visualization on a slide. You could certainly do that. But what I did is I got a little bit more complex, and I said, update the slides to include some narrative text next to each visualization as a text box. The text should be on the right hand side of the visualization, and the text box size should set to approximately one third the width of the screen. And the text should be word wrapped. The colors of the text should match the visualization of the color scheme. Now, I'm getting pretty explicit at this point, and part of the reason for that is I've learned some things, like you want to ask it to word wrap things. You want to kind of tell it how to lay things out. Sometimes it can randomly decide a layout that makes sense, but a lot of times it doesn't really work. So when you get explicit about how you want things positioned visually, colors, styles, font sizes, it can be helpful. So it goes through and it updates the presentation. The new one, it gives me the download link again. And I looked at it and I realized that the problem with it was my title slide. And then the slides that came later, the color schemes didn't really match up. It was using all of this text and colors that really didn't match what I had in some of the imagery. So I just ask it, please extract the first slide of the presentation as an image and extract a color scheme from it. So the very first slide of my presentation has this big colorful image on it, and I want it to just go look at that image and then choose a color scheme from it, which is what it does. So it goes and extracts the image from the first slide, builds out a color scheme from that image, and then gives me all the colors to use. And then it also tells me I could download the extracted image, which I don't actually care about. All I care about is getting it to use those colors, so I go and update the instructions and I say update the narrative for each visualization to be 24 point and randomly choose one of these colors for either the background or the text. If you use one of these colors for the text, pick the best contrasting color from above or wide as the background. The visualization should be zero inches from the left side of the slide. The text box should be nine and a half inches from the left side of the slide and 3.75 inches wide. I'm not going to lie, I had to do a little bit of experimentation with these numbers to figure out when I'm thinking about laying out PowerPoint slides, how to explain it to it and how to get it to work well. And this works well and gets me the format that I want. It then goes through, does some more updates, produces our updated presentation. And the beautiful part about it is then I can download it. And here we go. Here's a sample of one of the slides that is generated. It's taken our PowerPoint presentation, it's added in the visualization, it's put the text on the right hand side. And it's still not perfect. There are some things, like right here where we have the text is overlapping a little bit with the visualization, but hey, it's not bad. And I could fix that problem pretty easily. Or I could go think about how to improve my prompts and my description to it to get it so that it didn't overlap. But the really beautiful thing about this is once I figured out kind of the language and how to describe it and the process for going through and doing this, I could very, very quickly go through and update these slides with new data visualizations. And the key thing here is we're combining multiple information sources. We're combining a PowerPoint presentation with some data. We're transforming the data into some new visualizations, and then we're putting it all together into a totally new out output, which is this new PowerPoint presentation that we want. So you can go and mix and match different contents, do some analysis, visualization transformation, and then weave it all back together into some product that you can download and go and use.\n\nI want to help you break the ice on using code interpreter so that you don't go to it and have this feeling of like what do I do? I want to give you some simple example of what you can do to use code interpreter. Go into code interpreter and you're going to want to make sure you select the code interpreter model under GPD4, you'll need to have enabled this in settings. Then you'll want to go and upload a document. Now I'm going to do a really simple example that probably everybody has done some point in time. I'm going to just take a recipe and I'm going to ask code interpreter, please read this recipe and list the ingredients for me. Now note I'm uploading a PDF. This is not the ideal way to give it the information, but let's just imagine that's all you've got. You've got a PDF that you've gotten somewhere and you want to extract all the ingredients from it. Now I've got a list of ingredients. Now the starting point for just about anything you do with code interpreter is going to be uploading some document that you want to ask a question with about or do something with. Now I'm going to say, pretend I am going grocery shopping, help me prepare a grocery list for that trip. Assume I don't have any of these items and I have to buy them in standard quantities or sizes. Please come up with a grocery list or the minimum amount of each that I need to buy. I want it to go and help me figure out what can I buy to go and build this recipe. I want it to account for the fact that these things come in different size bags, different size boxes or other things, and try to figure out what would be the minimum amount that I could go and do. Now, it's putting together now the vegetable oil, all these different things. Now, it may not know exactly what's in my grocery store. It may not be getting it exactly right. It gives me some recommendations. A five-pound bag of flour, that's probably more than I want, but it also tells me I could get a two pound bag that would be more than enough. But considering how flour can be used in many other dishes, you might want to consider a larger bag so it's helping everybody who's growing wheat. It goes and tells me how much of the onion, how much of the garlic. I've got some different amounts of things that I need to go and buy. Well, let's go and upload a second recipe to this. We'll say, please read and incorporate the ingredients from this recipe into the shopping list. I'm going to go and take my next recipe that I'm going to do and I'm going to go ahead and incorporate it into the shopping list. Again, this is a really simple example, but you can imagine doing this. If you want to take a bunch of recipes, you want to combine the ingredients, yeah, you could do this by hand, but isn't it nicer to have it just do it for you? We can also go and do some interesting things. We might want to go and say, if I eat both of these recipes in a day. Well, let's say if I eat a serving of both of these recipes in one day, can you give me a very rough estimate of the calories? I don't care if it isn't perfectly accurate. Let's just see what it does with that. It go and estimate the calories for us? It can say sure, there are 670 from the first one, 1,340 from the other one. Therefore, you would consume approximately 1,340 calories if you ate servings of both. Can you visualize the macro nutrients that I would consume in some way? Let's see if it can do something with that. Can you give us some type of visualization of these things? It's now breaking down some of the aspects of the macronutrients from this recipes. It's now going to visualize them for us. We're going to have a recipe list now that we've extracted from this thing and we're now hopefully going to have a visualization. It's working on it right now. Now we can see a breakdown of protein, fat and carbohydrates. This might matter a lot if you were trying to eat keto for example, and you want to know, does this thing have too many carbs? You could probably looked at it, but isn't it more fun to create a visualization for it? Very quickly, we're taking a document and we're going through it step-by-step, and we're building something out. Now, we could go and build out something else with it. We could go and incorporate another document into it. We could go and try to generate recipes that might pair well with this. We could go and export it. Let's say, please export or please create a CSV comma separated values file. File that has all of the recipe instructions in it so that I can import it into Excel. We might want to be able to go and take all the ingredients and take the recipe and somehow represent it in a way that we can open up in Microsoft Excel and we could work within Excel and do something else. Basically at this point what we're doing is we're taking unstructured text. We're taking text that is really just meant for a human to read inside of this recipe. We're now getting ingredients. We're putting it into a shopping list. We've given it some structure. We've then gone and we're estimating calories off of all of that, we're going in visualizing it. Now we've got the instructions and we can go and click on it. This is one of the other key features that I want you to think about, is have it going build things for you. Have it build images for you. Have it build files for you. Have it show you things. If it builds something for you, ask it to create a file with it so you can download it. I'm just downloading that file and now I've got a list of the recipe instructions in a CSV format that I can import into Excel. I want you to break the ice, go find some document, find some PDF, find some Excel file, an image, whatever it is that you've got. Go into code interpreter and upload it and just ask it a question about it or ask it to do something with it. Now you might try your first question. It says, hey, I can't do it. I can't process this file. But don't give up. Try again. Go and think about what would be something interesting that I could get out of this? Now certain files are going to work better than others. PDF is not always the best. Some of the PDFs are hard to read. Sometimes images are difficult to work with, but given an image and ask it to resize it, it can probably do it. Go give it a Word file and ask it to summarize what's on the first 100 lines of that Word file, whatever it is that you want to do, just give it a document and go give it a try. Break that ice and get started with working around within code interpreter in your data.\n\nWe're going to have a long conversation about code interpreter in the course of this class. So I want to make sure that we are on the same page in terms of some basic terms that I'm going to be using over and over in my videos, and I want to make sure that you understand what I'm referring to when I talk about them. The first one is a prompt, so anytime you go and type in a message in this box down here, this is a prompt. So anything down in the message box that you're sending in to code interpreter, that is a prompt. It's the same thing as in ChatGPT or some of the other large language models. Anytime you send them a message, that is a prompt. So up here, we can say, please make these images much more stylized by dramatically increasing the contrast and saturation, that is a prompt. Any text that you put into a message and send to code interpreter, that is a prompt. Code interpreter is essentially a wrapper, a set of tools that are built around, you can either think of it as ChatGPT or GPT4. And I may be using ChatGPT and GPT4 somewhat interchangeably. But what I'm referring to is that large language model basically, this AI inside the tool that is really good at understanding text, following instructions, doing all kinds of other complex things. Now, if you haven't taken my course on prompt engine for ChatGPT, you don't have to, but it's a great companion to this course. So if you haven't taken it, I would highly recommend that you go take that because you'll get a lot more out of doing both courses. And similarly, if you've taken the other course and you haven't taken this one, this is a great course to pair, if you finish that other course and you're trying to figure out what to do next. But key thing that you're going to need to know is that this text that you're inputting in there is a prompt and the wording of this text, it makes a big difference. That's the short version of it, the design of the text, what we say and how we structure our words, that's prompt engineering. So why did I not just say, make these images much more stylized? Why did I not number it and say, one, make these images more stylized, two, dramatically increase the contrast and saturation? I could have done it that way too. Prompt engineering is basically the discipline of trying to decide, how do I write out the instructions? How do I design the prompt? What is the language that should go into it? Now, I'm going to talk about output. When I go and put in a prompt, you're going to see some output down here. So when it says, first let's unzip the archive to access the images, that's part of the output. We're also going to see output that is this little gray box. We're going to see this little gray box that says like finished working or it has a progress indicator, we're going to see that over and over in code interpreter, and that's also part of the output. Now, this part of the output is special, this part of the output is where code interpreter is writing software, and this is what I'm going to be referring to as Python code. So anytime I say Python code, I'm talking about the software that code interpreter is writing behind the scenes to help accomplish the task that you've asked. So if anytime you see one of those gray boxes, if you go and expand it, this is Python code in here. And sometimes, I'm going to tell you that for certain interactions, you're gnna want to talk about Python code because it will be helpful in getting exactly what you want out of code interpreter. Most of the time we're not going to have to do that, but sometimes, we're going to want to tell it things about that Python code. Now, this whole thing down here is an output, and it may actually be doing multiple iterations behind the scene to produce all of this output. Now, all of this output down here that we see that came as a result of my simple prompt, please make these images much more stylized by dramatically increasing the contrast and saturation, that was my prompt. All of this down here is the output, now one thing to note is there is a limit on the size of our prompt, we can't just put a book in there, we can't put 1000 pages in. Similarly, there's a limit on how much it'll give us out at one time, so there's a limit to the total amount of text that we will get back in the output. Now, we can do more work if it generates Python code and runs that Python code, and we'll talk about that later. But the short version of this is that what we see that gets printed to the screen here, there's a limit to how much of this it can do. There's also a limit just overall to how much work it's going to do at once, and that's useful to know. Now, that's all of the output, so whenever we're talking about code interpreter, when I start talking about a prompt, I'm talking about the messages that we're sending to it. When I'm talking about an interaction, I'm talking about what we're saying and under what circumstances to continue the conversation. When I'm talking about the output, I'm talking about what it does in response. When I'm talking about code interpreter, I'm talking about this overall application. And when I'm talking about, and I'll use these terms interchangeably, when I talk about ChatGPT or GPT4, what I'm talking about is the AI behind the system that is interpreting our messages into deciding what output to generate, what software to write for us. And when it's writing software, it's writing Python code. So those will be some helpful terms for you to know throughout the rest of this course.\n\nI want to give you a mental model to work with code interpreter. Now, I want you to think about code interpreter like this really fantastic intern that's come to work for you. They're going to be your personal assistant. And whatever you need help with, they're going to try to do it for you. Now, this intern is really smart and knows a lot of things. They can actually program for you. They can interpret documents. They can do data visualizations. They can do all kinds of interesting things. They can work with the computer really well. And that's the key is they know how to program and run different tools on the computer. Unfortunately, your IT department really does not trust this intern, so they've only given them access to a computer that has a limited set of tools and no Internet access. So anything you ask them to do, it has to be something that you hand off to them on their computer. They have to be able to do it with their limited computer that they've got. Now, the other really important thing to note about your intern is your intern makes mistakes, so you absolutely need to pay attention to the help that they provide and double check it. Make sure it's right. Another third thing that you really want to know about your intern is they don't have a very long memory. You can talk to them, and they will remember things through your conversation up to a point. If you start a new conversation, they're going to forget everything that you've said before. They're only going to know about what's going on in the new conversation. So if you're in the middle of a hallway, and you give them a task to do, and you start describing it, and you walk off before they've completed the task, they may not remember what's going on when you see them next time and you ask them to start a new task. They won't remember any of the things that they did before. They only remember what you're telling them right now. Those are some important things to note. They've got limited computer access, your intern is going to make mistakes, and there's a limited memory. So when you're having a conversation with them, you really want to get everything done during that conversation. Because if you walk off, the intern may lose all the files that you gave them, they may forget important information. They may not be able to get started again and pick up where the task left off. So when you're working with a code interpreter, you want to have one conversation, and you want to get everything done with it, and don't expect to come back easily. Now, let's take a look at a conversation with a code interpreter and how we're going to use code interpreter. I wanted to give you a sense of how to talk to code interpreter, how to give it statements. It's just language, it's your intern. What you say is you're going to break statements down, and you give it things in individual chunks. Now, I've given it a zip file. I've given code interpreter a zip file. It has several files from my computer. You can imagine this task where you download all these files or you're building and working with all these different documents. Over time, you don't take the time to organize them properly. So I'd like to give my intern the task of reading through all these documents, figuring out what they are, coming up with a better organizational structure or folder structure on my computer for them. Now, the intern doesn't have access to my computer, so I'm going to have to give them to the intern. The intern will go and work with them on it's computer, and then give them back to me. Now, another thing is I have to break the task down step-by-step for the intern. So here's what I'm going to do. I've given the intern the document. I've given code interpreter the document. I'm going to say, I need your help organizing the files in the uploaded zip. One, I want you to help figure out what is in them by opening and reading each one to create a summary. Two, I want you to propose a folder structure that would better organize the files. Three, I want you to propose better names for each file, just using the letters A through Z and 0 through 9 and keep the existing file extensions. Four, you've done all this, show me your proposed folder names and structures. I'm going to check over the intern. I'm going to check over code interpreter before it does anything with this. Now you notice I'm breaking this down step-by-step, I'm trying to give them a process. You can imagine this, if I went to this intern, I just said, hey, organize my files. It's going to be overwhelming to them, they're not going to understand what to do necessarily, or they may go off in the wrong path. I really want to break this down step-by-step. They also don't know anything about me, they don't know anything about my files. The first step has going to be go and look at this and figure out what's in it. When you're working with code interpreter, typically one of the very first things you're going to do is you're going to tell it to look at the file, read it, summarize it, outline it, figure out what columns are in the data, whatever it is you're going to, often you're going to have it go and try to understand the file first. Code Interpreter goes off and it says, let's begin by extracting the contents of the zip file to see what we have. We will then analyze the content of each file to generate a summary, afterwards I'll propose a folder structure and follow names based on the content. Now notice how it's mirroring what I asked it to do. That's really important. I broke the task down in simple steps like you would give to an intern and now it's repeating back, code interpreter is acting like my Intern, basically verifying, here's what I'm going to do. Then it goes through and it lists, here's what was in the zip file. Now one of the things about code interpreter is this intern is always looking for feedback. The intern knows that it makes mistakes. Code Interpreter knows that makes mistakes, it wants to show you its work. It wants to show you what it's thinking to help make sure it's getting the right thing. It's saying, hey, here's what was in the zip file. It also noticed something and it's been a smart Intern it saying, hey, there's some hidden files, but those probably don't matter. I'm going to ignore them. Now if I cared about it, I would know about it and I could go follow up on it. Then the Internet says next, I'll read the content of each file and generate a summary. Please note we can only extract text from PDFs if they contain selectable text. If the text is part of an image, we may not be able to generate the summary. The intern is trying to tell us its limitations and it's always really important to pay attention to these limitations, what it can and can't do. Now I want you to notice the next thing. Now this is one of the really important things of code interpreter, is some of the tasks that you give code interpreter. That Intern is going to go and write some software. They're going to go program a little bit of software that will help them accomplish the task and the Intern is going to try to decide what are the right things to build a program for it or program in order to solve versus the things that the Intern can just do in its head. Now in this case, it's written all this software right here and basically what this software is doing, is it's going through and it's going to try to read all the files and extract text from them. Now, you can work with Code Interpreter without ever having to understand what is inside the code and that's one of the pieces of Code Interpreter that's really impressive, is that it can go and program on your behalf to try to accomplish a task and you don't have to be able to read the code that it's producing. Now just like your intern, let's assume your Intern said, okay, I'm going to do this, I'm going to go write this program to try to read these PDF files. The Intern may not succeed and the Intern may tell you, hey, I wasn't able to do this. There are certain files I couldn't make it work, I couldn't program. Sometimes that's going to be the outcome. But in this case, the Intern used it's program to go and extract things. Code Interpreter is telling us, hey, here's what's in all of these different files. In some of the files it tells us, hey, the text extraction from this file didn't generate any output, it's telling us that there's nothing there.The Intern then says, it's going to propose a file structure. Again, notice what it does. It goes and writes code again, your Intern is programming and writing some tools to help solve the problem or the task that you've given the Intern. In this case, it's written all of the software, and then it's proposing a set of basically folders that all of these files could go into and how they will be organized. In this case, it ends up with this big bucket of other stuff. Some of the files that says, look, please note that some vowels are categorized under others because the summaries did not provide clear categorization keywords. My intern did its best, but at the end of the day, it couldn't completely accomplished my task in a way that I'm happy with. Now, we could get upset with our intern, but I'm going to instead say, hey, let's give our intern feedback. Whenever code interpreter isn't giving you quite what you run, try to give it feedback, try to help it along with the task, just like you would an intern. Go and give it some more information. I just tell it, hey, don't give up. Can you try alternate methods to figure out what is in the other category? Try other ways of getting texts from the PDFs. Look at the file names, keep trying and do your best. I'm telling code interpreter don't just give up and lump all this stuff under others, go back. This is one of the things you'll want to be doing with your intern is, sometimes the interim is going to fail. They're going to try to write a program to do something, then they're eager to write programs and to write software, basically that's going to help it. But it's not always going to work and sometimes you just have to tell code interpreter, go back and try again, try some alternate methods, try again. Code interpreter goes off. Again, it looks at the file names in particular this time, and then updates the categorization. In this time the other category isn't there, so it does a better job and based on that, I'm happy with the organization. The intern went, followed my step-by-step process. This is going to be really key when you're working with the code interpreter. Look at how I broke the task down into individual steps. I didn't say just go and organize that. Sometimes that'll work, but most of the time you're going to get a better outcome if you tell it step-by-step individual sub-goals or sub-tasks to complete in order to achieve the overall desired effect that you're looking for. In this case, I've broken things down step-by-step. Always break it down step-by-step for your intern or your code interpreter, and don't assume that the intern knows things they don't. It's the intern always needs to be given context, always needed to be given sufficient information to accomplish the task. Now at the very end, I now need a way to tell the intern to give me the file back and to give me the organization. What I say is, this looks good, create a zip with the files in the structure so that I can download it. This is one of the other important pieces that you always want to remember with code interpreter. We're going to go and put things in to code interpreter. They're going to, you can think of it as an intern working with your data and your files on their computer. Then at some point, most of the time, you're going to want to get that stuff out. It could be that you're doing some analysis just for your own edification and learning and so you're going to do the analysis with your intern and they're going to tell you about what's in the document and summarize it for you and that's the outcome. But a lot of times what we're going to want some document, some file, some presentation to be created by the intern and given back to us. At the end, what we can always do is we can just tell it to create the file so we can download it. In this case, I'm going to say create a zip file with the files in this structure so that I can download it. I'm telling the intern, you did a good job. You've gotten the folder structure that I want. You've gotten the files organized and renamed in a way that I'm okay with and I want to download it as is. Now I've got the the zip file that I can go and download. Now, if I was unhappy, I could really nitpick and say, I don't think the file renaming was that great. I could go and try to have the intern push again and really try to understand some of these documents that the intern didn't do that great of a job with. But in this case, I'm happy with it. I've gotten far enough. I'm much better off than where I started with. I now have some organization to my files and I can just download the zip file and get myself the folder structure that's been proposed, the files organized into it, and I don't have to go and do it manually, which is pretty amazing. We can think of all kinds of tasks where if we just had that intern, that personal assistant, that not only were they pretty smart, but they can also go and write software for us on-demand. They can be like our own personal software engineer, but we don't have to know which tasks are the right ones for software all the time. Sometimes we do, but not all the time. They can go and help us and accomplish these different tasks for us\n\nEvery time we upload a document to code interpreter, we need to think about how we're going to use it. Now, when I say document, I mean any file, anything that we are giving it to work on and operate on. Thinking through how we're going to use that document is really important because it's going to change the patterns of interaction we use significantly. Depending on what we want to do with it, we're going to have to interact with code interpreter differently. Now, here are the two models, the first one is the document as an object, as a file that we're working on. Now, what does that mean? Well, if we are going to go and take the file, for example, and we're going to rename the file, or we're going to take an image and we're going to crop the image, or we're going to download that file or something like that, we're thinking about it as an object. Now, I've put together a list, I've had code interpreter generate a list, now, not all of these things are probably completely appropriate. I'm not sure that we can print documents like is shown here. But the kind of the idea behind this is, are we operating on the file itself, the document? Are we trying to edit it? Are we trying to concatenate it with another file? Are we trying to copy it? Are we trying to move it to a new folder? Are we trying to rename it? Think about those types of things on the file itself, the documented as an object that we're going to modify in some way. Or are we using it as a source of knowledge? And this is really, really important because when we start using it as a source of knowledge, particularly textual natural language knowledge, that we want to be brought into GPT-4 for some type of analysis, then we're going to work with it in a very different way. So when we start talking about analyzing it, or summarizing it, or outlining it, or reading it, or interpreting it, or searching through it for something, all of these things typically we're going to want to do by thinking about it as a source of knowledge. And typically the most effective way to do these type of knowledge based operations when we're dealing with natural language in a document. So if it's words and we want it to interpret the words, then we want to think of it as a document, as knowledge, and that's an operation that we're going to want to do differently and we're going to want to talk about differently. And we want to sort of handle very, very carefully because we're going to get very different results on how code interpreter decides to go and perform an operation that deals with knowledge. Now, when it comes to document as objects, that's a much more straightforward thing to do. If we want to rename files and we want to copy files, we want to resize an image, those types of things are much more straightforward. The more difficult things are when we start looking at the knowledge inside of a document. And that's where we have to be very, very careful and very intentional in the patterns of interaction we use to make sure that the knowledge is extracted and represented appropriately. And that GPT-4 is doing the analysis of that language and doing it effectively. So we're going to deal a lot with looking at how do we structure our interactions for these two different use cases on operating on the document as a file versus operating on the document as a source of knowledge, where we need to go and really interpret and understand that knowledge and take action based on it.\n\nI've talked about code interpreter being our intern that's working for us, but an intern that knows how to code and write computer software. But at the same time, the code interpreter is our intern that can read documents, that can reason, that can write outlines, that can draft emails for us. And one of the things that's really helpful is that we want to guide the intern in the right approach to each task. Because as a programmer, sometimes the intern is going to want to write software to accomplish a task that we don't really want it to write software for. And I want to kind of give you some intuition behind this because this is going to be really important, particularly when we start working with larger documents or we're trying to put together larger outputs. There are going to be cases where we're going to have to struggle to make sure the intern does the right thing with the right tool. So certain things we're going to want it to program to solve those problems. Certain things we're going to want it to do itself by reading. Now, when I say itself, I mean we want ChatGPT or GPT-4 to do the work of reading, analyzing, writing, drafting, these types of things. Now I want to help you get a sense of how you can tell what is being done. And also I know this is a bit abstract, so I kind of want to give you sort of a visual for this in a conversation. So this is an example before where I said I wanted to reorganize some files for me. And it's going to do this two ways. The text up here, this is something that GPT-4 or ChatGPT, this is something that it's producing. Now, when GPT-4 is asked to write text, it's extremely good at it. When GPT-4 is asked to read text, it's very good at reading it. It's very good at outlining. But certain things it can't do, it can't operate on files, it can't rename a file, that's not what it does. It reads and writes text is the way you can think about it. So when you tell it to rename a file, it can't do it directly. It has to write some Python code to help it. So when this little gray box shows up, that means that code interpreter has decided that the task that you've asked it to do is going to require some software to be written to help it along. And so what it's going to do, is it's going to write the software, because if you look at the software, the software is just text, and it's really good at writing text. But the software that text that it writes, that program that it writes, can then be run in order to do things that GPT-4 cannot do, like rename a file, or read a file, or in this case, it's extracting a zip file, extracting all the files from a zip file. So you can think of it as Python, allows the GPT-4 to use what it knows how to do, which is to write text. To write text, that's a set of instructions or a way of using a bunch of tools on the computer. So it's programming some software to help itself. Now, in this case, whenever this little gray box pops up, you need to be queued in, that code interpreter has written some software and is running it and is trying to solve part of the problem by running some software. So in this case, what it's done, it says the extracted files from the zip are as follows. And the first thing it does is it tells us what it's doing. It says, all right, let's begin by extracting the contents of the zip file to see what we have. And then this gray box pops up. And so what this is an indication of is that it's decided that the task of extracting the contents of the zip file, that it can't do it itself, so it's going to have to write a little bit of software to do that. This gray box popping up, is it writing the software and executing it. And then what we see after the gray box is the result of its software running. It's getting the output of that, and then it's explaining to us what the output of its software was. So this is a little bit complex to follow and it's honestly just quite mind bending that this is possible now. But I want to walk through this again really carefully because it's important to understand what's happening because you'll need it later for more advanced things. And if you don't fully grasp it now, don't worry too much because as you begin using code interpreter, it'll give you a better sense of what this is. This first part is GPT-4, it took in your message up here and it said, okay, I need to do something with this zip file, I need to unzip it. And that's what it decides. I need to extract the contents of this zip file. Then it says that's not something I'm capable of as an AI, I need to write a software, a program, a little tool for myself to accomplish that task because I can't directly do that. So this gray box, is it writing the software and executing the software to perform that task of extracting the zip file. And then what it's going to do is it's going to take the result of that, which you can actually see over here, which is labeled, result. So if you expand that little gray box, the top part will be the software, the second thing will be the result of it. So this is it ran its program that it decided to create and the result is what it got back, which is a list of all the files that were inside the zip file that were extracted. And then what that comes right after that is it's going to be explaining to you what happened, what the result was. So it's going to tell you what it's going to do, it's going to show the gray box saying, I've written some software and I'm running it. If you expand that gray box, you can look at the details of the software and you can look at the details of what the result of running that software was. And then right after the gray box, it's going to tell you, here is what happened, here's the output or the result of that. Now, that's a really important thing to understand. It's going to all the time be trying to figure out, does it do it itself? Does GPT-4 itself need to do this task or do I need to write some software to do it? Now, here's an example of a conversation. You notice there's no gray boxes here. This is 100% GPT-4. It's doing all the work. It also means that it's something that you could have done with just ChatGPT without having to use code interpreter at all. You could have just gone and selected the GPT-4 model. So if you're not getting gray boxes, you're actually not using features of code interpreter that you need for that conversation. But that's a separate point. But this is what it looks like when it's doing everything itself. It's just reading the text, which is the prompt that you've got, it's responding to it and producing some output. Over here, in contrast, it's reading what you put in, it's deciding that it needs to go and do some task, in this case extracting the contents of the zip file. It's writing some software, which is the gray box, and then it's telling you what the result was by reading the result and explaining it to you or writing a result. Now, I talked about document as an object or document as knowledge. And this is where it gets really, really important. If we're operating on files, if we're going to resize an image, if we're going to rename a file, if we're going to delete something, if we're going to create a movie, write a PowerPoint file and update it, those are things that are best done in Python. So if we tell it to create a PowerPoint presentation, we are going to expect it to pop up a little gray box at some point, because GPT-4 can't just directly create a PowerPoint file. If we tell it to graph something, we expect to see that gray box pop up because it needs to write Python in order to generate that graph and that visualization. If we ask it to do some numerical computation on a large amount of data, in particular, we really expect to see that box pop up. So if you give it some large Excel file and you say, sum this column, you want to see that gray box pop up that tells you it's written some Python software to go and read that data, to do the computation inside of Python and inside of that software, and then it's going to give you the output and tell you about it. Those types of things you really want. If you're dealing with numerical data analysis, images, resizing, those types of things, even detecting people in images, those are the types of things you're going to want in Python. If you're dealing with understanding text, or writing text, or outlining, or summarizing or translating text, anytime you're dealing with text, you really want to do everything in your power to get GPT-4 to do that work in itself and not to write Python code for it. So I've tried to generate, I've worked with GPT-4 and code generator and code interpreter to try to get it to explain this. It's kind of funny because in this conversation, it doesn't know GPT-4 exists yet, which is kind of humorous, although GPT-4 clearly exists inside of this conversation. So if you're doing natural language processing, meaning you're dealing with text, and you want to have it tell you what's in that text, summarize it, so if you upload a Word document and you're going to say summarize what's in this document, that's something you want GPT-4 doing. If you go and you say, I'm going to give you a document and I want you to answer trivia questions based on the document, so you're going to give it a Word document and you want it to answer questions about the document. Or in the case of the Vanderbilt Travel policy, if you want it to answer questions about the Vanderbilt Travel policy, what is it and what's not allowed, that's something that you want GPT-4 to do. On the other hand, if you upload an Excel file and you say generate a visualization, that's something you want Python to do. If you upload an Excel file and you tell it to calculate a correlation between two things, that's something you want it to write some Python to assist in. So you want to see that gray box pop up. If you go and do machine learning on images, you're typically going to want to see that gray box pop up. Or if you're going to do image manipulation, gray scaling, resizing, copying, if you're doing comprehension, you want to read, understand, and explain, that's something you want with GPT-4. If you want it to go and write code, it's saying web development, it should be done in Python. Well, this is a little bit tricky one, and I'm going to give you an example of this. If you're having it write code, you want GPT-4 writing the code, but you want the code it writes to use frameworks and things. So this is a little bit of a mixed one. So I would say if you're generating code, it's a little bit different, but in general, you want GPT-4 writing the code because you're writing text. So I think it gets that one wrong a little bit. Simulating conversations, definitely GPT-4, you want it to pretend to be two people talking. Mathematical computations, Python. Translating languages, GPT-4. It's getting a lot of these right, not all of them. Image processing, Python. System scripting, Python, moving files around, creating directories, things like that. Video processing, Python. Audio processing, Python. So think about this document as an object, I'm renaming files, rewriting files, I'm creating images, I'm doing mathematical computations, doing something that isn't text, we're going to expect that to be in Python. We're expected to see the gray box pop up. Trying to do something that's about understanding knowledge in text, writing an email, drafting something, simulating a conversation, reasoning about some information in text, we're going to want that to be in GPT-4. And we want to make sure that when we go and do something, certain tasks are going to require mixing both. And particularly when we deal with understanding large volumes of information, we're going to be forced to mix both approaches together. And we have to very carefully make sure that GPT-4 is doing the really heavy lifting when it comes to understanding the text as opposed to having Python do it. Now, we'll talk about this later in the course, but I want to clue you in on what it means when that gray box shows up, it means it's writing some software behind the scenes. That stuff is good for certain types of tasks. Whenever you want it to analyze text, you want GPT-4 doing that. And so we'll see how important this is later in the course.\n\nWordle is a word game that is really, really popular, but also GPT4 doesn't necessarily solve it that well. Now, your results may vary if you try GPT4 over and over. Maybe sometimes it'll work, sometimes it won't. But I had somebody email me an example where they said, though this thing isn't very smart, look, it can't solve Wordle. And I want to show you that's a great example of when code interpreter or plus ChatGPT or GPT4 becomes a really powerful tool. So let's look at an example with Wordle where we couldn't solve it correctly with GPT4, but when we put it into code interpreter, suddenly it has the ability to do it. So the thing was, we needed to find a five letter word in Wordle. So the idea behind this is we have a five letter word. We know the second letter is an E, and we know the last letter is a T. In addition, we know that it can't contain any of the following letters. It can't have R, Y, U, I, O and you can see the rest of the list. So we're looking for a word that fits these constraints. Now, if we go and put this into GPT4 like it did now, you may get variation on its answer, but it goes through and it tries to solve the problem. It explains it, and it basically comes up with some different possible words. And it finally says, the word befit fits the given pattern and constraints and is a standard word in the English language. Now, you'll notice from the high level this pattern befit works B-E-F-I-T but it can't include the letter I, so it actually made a mistake. It didn't correctly account for the constraints because this type of three isn't something that GPT4 is as good at, right? This isn't an error tolerant problem where it's going to be exact in the way that we need it to be in the words. And we see that in that it comes up with befit, which is an incorrect answer in what it suggests. So this is something we can actually use code interpreter to solve and code interpreter can do a much better job. So here's what we do with code interpreter. One we have the advantage of, we can give it files. So I've uploaded a list of words from the English language and I say attach is a dictionary. I need you to think step by step how to solve this problem with the dictionary. And then we give it essentially the original prompt that we had, which is, here's the pattern. We have an E as the second letter, a T as the last letter, can't include any of these letters. And then what it does is it goes through, it specifies how it's going to do it, it's going to load the dictionary, it's going to do pattern matching, it's going to apply the constraints to filter things out. Now, GPT4 directly itself manually tried to apply these rules, which it can't do. But code interpreter does something fascinating. It goes and generates Python code to solve the problem. It recognizes that this is not the type of problem that it can solve on its own. So it goes through and uses the dictionary to generate possible words and then says among these the possible English words that it could be are beget and bewet. And it's probably beget in this case is my guess as to what the correct word for this Wordle puzzle is. But the key is now can give it input this case the dictionary. And two it can write tools, in this case a filter to go and filter all the words in the dictionary to find ones that match the pattern. So this is a great example of something that GPT4 couldn't do. But now with code interpreter it can take a file as an upload, a dictionary and it can write code for itself to implement the filter or basically the Wordle search algorithm. And then it can find the correct word.\n\nI had somebody gives me this great example of something that ChatGPT didn't do a very good job of. It's a great task for Code Interpreter. Again, I'm going to contrast what Code Interpreter with ChatGPT can do versus what just ChatGPT can do alone. In this example that the person sent me, it was a great example, they sent me a bunch of batting statistics and other statistics for teams in Major League Baseball. Then they said, using the table of MLB statistics, please sort the teams by on-base percentage. First, list the on-base percentage, then list the team name the percentages should be strictly decreasing. When you go and you work this in ChatGPT, it takes a lot of effort. Now, if you work with a smaller set of data, you don't take this full list of MLB statistics, you can eventually with some prompt engineering get it to work but if you take the whole chunk of data, no matter all the prompt engineering tricks I throw at it I could never get it to sort the list correctly because this is the type of thing that it's that good at. Once, it gets a certain amount of data it's hard for it to do operations like sorting or these types of things. That's not really what it's meant for. When you go and you try to do this, you'll eventually see that it's actually having problems. In this case down here where it's sorted, there's actually hallucinations and it's not completely correct. If you try to rely on this it wouldn't be the best thing. If you go and look at this, it's not the ideal situation. This is not how you would want to use ChatGPT just by itself and it makes mistakes in this list. Now, if I go and I do this with Code Interpreter, I'm going to take the same data but rather than cutting and pasting it into a prompt, I'm going to upload it as an Excel file. I'm just going to first start off by asking you to read and explain every column in the data. It's exact same data it's just this time I'm giving it` to an Excel file. It goes and reads and explains the data to it. Don't worry, I also tried in prompt engineering where I had it explain the data before. It didn't make a difference in just ChatGPT. Is just simply too much volume of data and two, it's the wrong type of task to solve with just ChatGPT itself. Now when I do this in Code Interpreter using the same prompt, slightly changed because I tell it use the table of MLB statistics I don't say above because I'm not providing it in the prompt. I haven't go and do the same thing, which is sort the teams. It goes and gets it right. Now it only provides partial list upfront and I just tell it to display the rest of the list. Then it goes through and it gets the entire list with no hallucinations and it gets it on the first try. In fact, I'm replicating the prompt, some of the prompt engineering work that I've done in the ChatGPT version in this but you can actually do much simpler work. It doesn't require as much prompt engineering to get this to work in Code Interpreter. But this isn't a great example of something that works really well in Code Interpreter but if you try to go and do data analysis like this in ChatGPT, it's just not really going to work. Particularly not for large volumes of data. This is not even really that big of a volume of data because I could actually get it all into a ChatGPT prompt before, in GPT 4. But in this case, if I've uploaded as an Excel file, I get much better reasons and the reason for this is that ChatGPT Code Interpreter can write Python code to help it do the analysis. It can help itself and it can do these types of data analysis tasks much better than ChatGPT could on its own. This is a great example where ChatGPT by itself can't do it. ChatGPT plus Code Interpreter can."
  },
  {
    "index": 2,
    "title": "2 Use Cases",
    "content": "Let's have some fun with code interpreter by learning to work with small documents and what document could be more fun every year to work with than the IRS 1040, that if you're an American citizen, you have to fill out on your taxes? It's possibly the most fun document that I ever worked with in my life. Of course, this is completely not true. It's the document that I absolutely dread dealing with. Usually, I'm trying to avoid it all year long because it's a complicated mess of a document. It's got tons and tons of questions. It's dense, it's hard to read. It's got all these rules. I always feel like I'm lost in what I'm doing. Let's go and do just a simple chat about how we might be able to use code interpreter to help us with the 1040. Now, I'm going to go ahead and state up front, I would not use a code interpreter to do your taxes. It can make mistakes. You would want to go use an accountant, somebody who knows what they are doing. This is not tax advice. This is just an example of how you can take a document that is small enough to fit into code interpreter and read and reason about how you can go and interact with it. Even if that document is really complex. That's the point of this is this is a complex, really dense document, but it happens to fit into essentially a single message. Now I'm not going to go and copy and paste, but let's take a look at this document. I encourage you to go and find some document of yours that is preferably in plain text, but it could be PDF and there are some tricks on that. But get started and go play with a document and start asking questions and discovering the limits and the things that does really well. I'm going to start off by doing a basic pattern that you're going to see over and over when I'm working with PDFs or other documents. I'm going to say extract this document into plain text and then read the document and tell me all of the pieces of information to the question. But the key pattern that I'm doing as I'm saying, extract this document to plain text and then read the document. If I got a document that sits in and can be fed into one single chat message. This is how I'm going to approach this. I'm just going to say extract it to plain text to read it. Sometimes I'll just say read it, but extract and then read tends to work better if you're working with PDFs because sometimes code interpreter will come back and tell you, hey, I can't read PDFs. But if you tell it, extract it to plain text and then read the plain text, that works on a lot of file formats. It's a pretty effective way of doing no, you don't always want to extract it that way. Sometimes there are other ways of doing it. But for now know this is a simple, effective way of handling most documents, as you say, extract this document to plain text and read the document. That's going to trigger code interpreter basically going and looking at what's inside the document. Now, here's what it's done. It's gone and looked through and inspected the documents. That's filing status, and personal information. These are all things that are in the document. These are questions. This is dense document filled with different questions and we're seeing all of that basically brought up here. Now, I'm going to tell it to do something that is another pattern that I often do is I will tell it to reread the document, and make it change how it outputs. What I'm going to do is I'm gonna look at what information it has captured in the first reading. I'm going to think about what information it got that I'm happy within what I want. I'm going to think about what information it missed. Because one of the things to note is information that's brought into the conversation. We see all this information brought up right here. This is information that it's easy for it to reason on because it's visible. We both see it. We can both look at it. We can both fact check it. We can both identify potential errors. But it's also important because once it's in the conversation, then the GPT 4 model can have access to it easily to go and reason about it and do things about it. If you want to do textual analysis, it's much easier if you can get the pieces of texts that you want to work with that unstructured data. It's going to be much easier if you can get it into the conversation like this and then have GPT 4 directly interact with it. I've seen some things that I didn't see in the deck. The information that provided that I want brought out. Specifically the original document as identifiers for question. Now, not all of them have identifiers. It would be really nice if this thing had identifiers for everything, but it does not. Some of the questions are numbered with identifiers and some of them are not. But I want to capture that information that maps questions to identifiers. I'm going to do another common pattern. I'm going to tell it to reread the document and I'm going to tell it to go and get that information that I would like to have in the conversation. It's easier to reason about. I say reread the text and break down the questions into the smallest level of deeper though, I don't want summaries. Provide the identifier for each question in the document or question name if none exists. Basically what I'm telling you it is go into the document, pull out all the questions. I don't want you to summarize. I want every individual question and I want the original identifiers. If they were 1a or 1b or 1c in the document, I want that listed. If they had no identifier, just come up with like make this up, put it in brackets. Now what we see is it's gone and it's extracted all of this information from the document. It's followed my instructions. It's for the ones where there's no actual identifier it just summarized it in brackets. Then when we get down farther, what we see is now it's starting to put in the numbers. We see 1a,1b,1c,1d, and it's extracting each individual question from the text. It's summarized it. Now I've pulled an additional information which is the identifiers. I've done that for the whole document. Now, here's another pattern that you're going to see. Over and over and over we're going to hit the limit on the amount of information that code interpreter will give us back at once or the amount of work it's willing to do in response to a single message we send it. This is something you're going to always see. You're always going to work around. Whenever code interpreter stops, before it is done with your task, you want to tell it to continue or proceed. This is a pattern that you're going to want to know. Code interpreter will start working on something, and then it's going to hit the limit of the amount of information it can give you back and you need to tell it to continue or proceed. Now we see that right here. We've gotten to the end of this line right here, refund, and now I'm telling it continue. Again, really, really important you're going to use this all the time. It says sure, here's the continuation, and then it continues going through and getting the rest of the questions. Now let's have fun with the document. What could be more fun than asking questions about the 1040, the classic US tax document? Well, obviously, it's the least fun thing I do, but I'm going to answer questions about it because it's a complex document, so it's interesting to analyze. Which boxes if checked would require filling out additional forms? This is really interesting it now tells us which of those questions that are check-boxes if I checked it I would have to go and fill out an additional forum. I look at this as like which boxes if I check am I not going to have additional fun going and filling out? I'm going to check this box and that expands this whole new document for me to go and fill out a whole new realm of fun then I will get to go and enjoy. If I sold digital assets like Bitcoin, it's telling me now I'm going to have to go and have some additional fun. Then I know that there's this thing called a Schedule C and I'm surprised that it didn't mention the Schedule C, and so I say, hey, what about the schedule C? Like, didn't you make a mistake? That's really what I'm applying in a nice way, like code interpreter, didn't you forget about the schedule C, I think you've made a mistake. It's interesting because it actually points out that no, I'm wrong because it says, there isn't a specific checkbox on the Form 1040. It's actually pointed out to me, I know what the schedule C is and you're wrong because there's no checkbox there that triggers filling it out. You fill it out because of other reasons. That's really interesting. Now I say, okay, I had read some of the questions and I said, well, if I was born in 1946 and a veteran, which boxes might apply to me? Then it goes and tells me some of the boxes that might apply to me. These are really interesting things that you can do, but here the key, the reason why this was an easy document to work with. Now, it may not be an easy document for me to fill in, it may not be an easy document for me to go and collect all the information that I need to work with, it may not be an easy document to read or understand, but it's an easy document to work with in code interpreter because although it's dense in information, that information can be cut and pasted potentially into a single message. Now, I don't have to cut and paste it because I can ask code interpreter to extract it as plain text and read it for me and I can have it go and extract all of the individual questions for me, but it's a document that's easier. Now, I encourage you go out, this is so much fun and fascinating. Go take documents that you have and start putting them into code interpreter and trying this out. Start with extract this document to plain text and read the document or start with read the document. Then tell it what information you want to pull into the conversation. Here I'm saying tell me all the pieces of information that this document is requesting. Tell it to read or extract and read and then tell it what information you want it to bring into the conversation as it reads, this is for small documents, will have different approaches for larger documents. After it reads it, tell it to reread it and have it change the information that's bringing into the conversation so make sure it's pulling in the information in the conversation you want. In this case, I saw it read and pulling the information about the questions, but I realized I wanted the questions at a greater like I wanted them in finer granularity so I told it to re-read and break the questions down in the smallest level of granularity and I told it to provide the identifier for each question. This is a common pattern, re-extract and read the document and pull in information like tell me. Tell me is the code for pull it into the conversation, and then when we look at it, we're going to say re-read and here's what you're going to pull in or here's how you're going to change, how you're going to tell it to me. That's what I'm doing here. Once we have the information in the conversation like we do here, if we're doing something at a fine level of granularity, we're probably going to hit the limit on the amount of text that it will output at one. The amount of work it will do it once, and we're going to need to tell it to continue or proceed, another common pattern that we're going to have in our conversations. We're going to have to tell it, continue or proceed in order to get it finish pulling in the rest of the information in particular when really granular, and then we began hence asking questions. Step 1 is extract and read or read. Then we say, here's what I want you to tell me, and when you're reading or here's what I want you to summarize for me, that's another one or here's what I want you to outline for me. Those are examples of things you can do. Extract and read, tell me this and tell me could also be summarize this or outline this, and then we're going to have a re-read and get additional things that we may want that may have been missed or we're going to have it restructure it, and then we're going to go and begin asking the questions that we have, like which boxes is have checked would require more fun? In this case, we would require filling out additional forms, which I translate into much more fun in my taxes. We can also ask questions like, what about the schedule C? What does that mean? What's going to happen? Again, this is all for one individual document that is easy to process and get it. Start with a document that if you had to, you could go and copy and paste the whole thing or most of the thing into a single message.\n\nWhen you hear people talking about code interpreter revolutionizing how data science is taught and how data scientists work, it's because code interpreter works really well with structured data. So I talked about how structured data, if you have it, is much easier to work with in code interpreter. And I'm want to show you that. And working with structured data is one of the first places you should start. If you've got structured data, just just go and use whatever data you've got. Of course, make sure that it's okay to work with that data within the privacy and other guidelines you have, but if you've got it, if you've got sample data where you've got something that's representative of the columns and the types of data that you work with, you can go and use that instead. So you can go and use dummy data to help you get a sense of how all this works. Now, let's take a look at an example with Vanderbilt data. In a separate conversation, I took Vanderbilt's annual report, I extracted a lot of key metrics out of that report using code interpreter, and I saved it as a CSV file. Now, this is helpful because now I can go and reuse this CSV file and start from the structured data over and over. So, here's the first sort of interaction pattern that I'm going to encourage you to use, this conversational pattern when you're working with structured data. Please read and explain the structure of the data in this document. Or please read and explain the structure of the data. I'm going to do two things, one, I'm telling it to read it, go look at it, but I also want it to explain it. Now, why do I do both of these things at once when I'm working with structured data? Well, what I want to do is I want to be comfortable that when it loads that data, one, it's loading the right dataset, and two, that the structure that it perceives in the dataset is the same structure that I perceive in the dataset. Part of what I'm trying to do is make sure that code interpreter and me are on the same page. Are we looking at the same data? Does it have the same structure that we expect? Is code interpreter able to parse it correctly and get the structure out of it? And this is going to help us answer that question. So, first pattern, read and explain the structure. Now, it goes through and it says here's the structure of this. It reports on various metrics for Vanderbilt University over the years. This column describes the metric that the data in the row is about. For example, undergraduate, graduate, and professional, total for enrollment. That is correct. It then goes through and describes the different columns there for different academic years, and then it goes and lists a bunch of other things that are in here, count of undergraduate students, yield, masters and PhDs, sorry, Masters and MDS. It has other doctoral. Now, I'm going to come back to this a minute, it didn't go through the whole dataset, it took a part of it and explained it to me. Now, I'm going to start by just taking this data and pulling out of it and displaying something. And this is always a good place to start. A simple pattern is go and have it, read and explain it to you, and then have it go pull some selection of data out and display it in a table. Really simple task, really simple pattern that you can apply, but it can help you make sure that you're going to be able to pull out the right things that you want, and make sure that when they come out, they're coming out in the format that you're expecting, that they are being pulled out of the structure correctly. I want to check and really know that we are on the same page in terms of structure and format and these types of things. That when we begin our conversation, we want to make sure that we are talking about the same data, that we are using the same structure in our heads. In my head I say R, but it's code interpreter that it has that same understanding of structure that I do because we're having a conversation. We want to make sure that when we're talking about things, we're using the same terms and we don't end up creating a visualization that looks correct, but is based on fundamental differences in our understanding of the structure. Now, one way I can help deal with that is I say create a table showing graduate and undergraduate enrollment by year with separate rows for each. So I'm being specific about what I want to see and how I want it laid out, and now I see it going and showing graduate and undergraduate enrollment over the years. So we have 2017 to 2021. Now, that I've seen it can extract it and it's in the format that I expect, I'm going to say visualize each of these as separate series. So now this is a simple pattern you can apply. Go and you've got some data and now say visualize and explain the constraints for the visualization. So the constraints I have are that I want each of these two things, graduate and undergraduate enrollment, to be a separate series. Now, notice a couple of things, I'm expecting it to infer from the conversation what each of these is. And you don't always want to be that loose and trusting because sometimes it's not clear from the conversation which each of these refers to. So, it probably would have been better in this situation if I'd explicitly said visualize graduate and undergraduate enrollment over time as separate series. That would have been the better way of stating this, now I got kind of lazy and sloppy, and I'm just letting it infer from the conversation. And there could be risk there that it misinterprets. Now it shows me the visualization. Now, I didn't give it constraints on colors, sizes of lines, the scales, any other things about the axes or any of that stuff. And what you want to think about is it's always trying to get to something that works. It's kind of gave you a solution, a visualization that works. If you have additional constraints, if you want certain colors, if you want certain series, these types of things, you want to express that in your request. So always be thinking about, am I giving it enough constraints that if it generates something that works, it'll meet my needs. So have I told it enough about what I want? The constraints on the visualization are going to be how you express what you want, and it's going to try to fill in all the other details to make it work. It's trying to find a solution that'll meet your needs or your constraints. This time I have given it very few constraints. I've just told it what the two series are that I'm looking for, and it's done an okay job. But notice, I didn't specify one of the constraints that I look at this chart and I'm like, why on earth is 2021,2022 way over on the left, and 2017, 2018 on the right? When I read things, I typically expect it to go up in time to the right. Now, that may not make sense in all cases, but I need to go in and fill in the missing constraints. So this is a common pattern, is you'll have something that it produces, and then you need to refine it through iterating on the product. You continue the conversation, and iterate on it. So, I give it an additional constraint. Now at this point, to improve its visualization, I say flip the chart so it increases in time as it moves to the right, and now it goes and fixes the chart and flips it to move to the right. So whenever you have something that's not quite right, not quite what you want, don't get frustrated and throw it away and say it's a terrible tool. No, think about how do I go and express my additional constraint to get the right visualization or to get the right table or to get the right analysis. Now, I'm now going to go and I'm going to do something different. I want to go and take the data, and I actually want to do a calculation on it to transform the data into a different format that will be easier for me to work with later. So, I'm going to say ,create a table that shows the ratio of graduate to undergraduate students over time as a decimal, and create a table displaying the results. So I'm very explicitly taking some data in order to create some new data. Because this ratio does not exist in the original dataset. Now I'm going to do something else, and this can be important when you're working with data, is to be really explicit about the formula that I want used. So I'm saying graduate divided by undergraduate. It could have been the other way around, I'm wanting graduate divided by undergraduate. So I'm going to specify that in my request. So what I'm doing here is I'm saying, I'm using a pattern which is to basically give it information on how to create new data, basically to create a new dataset that it can then go and work with. So now it's gone and created the new data and I see it displayed here, and part of the thing that is going to be nice is now that I've reformatted this, it's going to be easier to ask for what I want next, which is I want a visualization that shows this ratio over time. So now I can just say, visualize this data. Again, I'm letting it infer things from the conversation, I could be more specific. But the key is, it's really easy for me now to describe what I want, right? Because I've done this intermediate step to pre-populate and pre-create that ratio and calculate it, now all I have to say is visualize this, visualize this data. And it can go and do what it needs to do. Now, if I hadn't done that intermediate step, I would had a more complex prompt to describe all this. I would have had to say, go and divide graduate by undergraduate to create a new ratio and then visualize this ratio as a function of time or whatever. I'd have to do something more complex. Now, I could have done all that in one step, but often it's easier to work with if we do things step by step and we do it, maybe, one step at a time in a conversation. Now, sometimes we'll just give it a huge list of things to do at once, but it can be helpful to think about reshaping the data through a series of transformations, to get it into a format and to look at it and to verify that process being applied to the data, which I can do up here, and I can see it and it's in the right format. And then to go and generate the visualization. So that's another sort of small thing that you would typically want to do, have it do the transformation, look at it and make sure it looks right before you proceed with the visualization, where it may be harder to tell that it's made a mistake. Now, what else can we do if we're going and looking at a document like this? Well, I'm going to say what other data is in the original dataset that correlates with this growth in graduate population relative to undergraduate population? So we see in time that the percentage of students at Vanderbilt that are graduate students is going up. And so I'm saying, what else in this dataset correlates with that, or could be something related to that? And it gives me all of these different pieces of information. But I noticed something, right? It's leaving out all these other things. In particular, when you're talking about graduate students, typically we're also talking about grants, research funding. Usually we would expect there would be some association or correlation between the number of graduate students and the amount of research funding coming into the university, and I don't see that listed here. Now, this just goes to show you it's not perfect. It's not going to always be able to know the answer to your question. Don't get lazy and think that it absolves you of the need to go and understand the data and to do work yourself and to think yourself. No, you need to keep thinking, and you need to be able to follow up with the right questions. It's a tool to help you, not a tool to replace you in many cases. Now, sometimes if you have a really simple thing and all you're doing is just drawing this graphic over and over, well, maybe it will. But if really your goal is to be the one who's thinking through the dataset, and what does it tell us and those types of things, it's a tool to help you, and you can't just assume that it's going to do everything for you. Now, I then tell it, hey, I realize it's forgotten something. What about grants and contracts? This is something that I would expect correlated with number of graduate students. It goes and tries to process it. Now, notice one of the things it does, it's going to go and say, hey, it looks like there was a mistake trying to access grants and contracts. The error suggests that there's no column grants and contracts. So it's telling me, hey, you asked for something, I don't see it in the data. This could be the actual name, is slightly different. Check the column names again, and it goes through. And then it finds total grants and contracts. So it's named differently. And it's saying, do you want to proceed with this instead? So it's a good thing, it's nice. It's confirming with us, it's not exactly what I said. So if you say exact column names, you're going to be in better shape. But on the other hand, if you say things that are related, it may be able to go and find it. In this case it was able to find that there is a related name, but not the exact one. And this is one of the powers of it, is to go and do those types of things. So, it asked me if I'd like to proceed, I say yes, with that modified column. It then goes and extracts the total grants and contracts over time. Now, notice it's doing something else in here. It says the error suggests that total grants and contract contains dollar sign characters which are preventing conversion to the integer data type. You're going to see it basically. Looking at the data, and if it encounters data that has formatting or other things that are problematic, it's going to try to fix them. You want to make sure that it does that correctly, that it does that data cleansing or reformatting correctly. And in this case, down here, we can see that it is doing what I would expect. Now, it now tells us that it can check the correlation between this and students, would I want to proceed? And again, this is a pattern. Over and over again, we're going to see it stopping at different points, either to confirm that we want to continue, confirm that its analysis of what the column name actually could be versus what I asked for is correct, or that it just hits some output limit. So we're going to say proceed. That's that interaction pattern. And now, it's going to go and tell us the correlation, the amount of grant in contract funding is approximately 0.9, this is a strong positive correlation. Now I'm going to ask it to go and visualize the two metrics together. And now I see grants and contracts over time, graduate enrollment as a percentage of total students over time. So, this is a really powerful technique, going and working with structured data. You can really quickly do interesting visualizations, and do all kinds of analysis on the data, ask questions about it. And it's going to be easier if the data set is smaller, but if you have big datasets that are really well structured, it also works well on them as well, particularly if we're looking at summary statistics and things like that. If you start doing textual analysis, things get a little bit trickier. But if you have numerical, well structured data and you want to do a lot of different types of analysis on it, it can go and do those analyses for you. And it does a fantastic job at it.\n\nCode Interpreter is really useful for working with media. If you have videos, if you have audio files, if you have collections of images, working with all of them, you can do a lot of things really quickly. You can absolutely go into a program and try to create some batch process or try to manually do things in one of these tools, but Code Interpreter is super powerful for going and exploring media and creating new types of idea. So I'm going to give you an example of this. I've taken a video of my son biking. He loves to go and do BMX racing and do dirt jumps and all kinds of interesting things. I've uploaded this video and I'm going to do a simple extraction. I'm going to take 10 frames out of this video, and then I'm going to do some things with them. You can go and play around with media and do all kinds of interesting things. I encourage you, after you do this, take an image, upload it, and try experimenting with doing different operations on the image. I'm just going to go and say extract 10 frames from this video evenly spaced apart. This is something I would probably have to go and look up some command line tool. I know the tool I would use and figure out exactly the commands to do this from the command line. But it's a lot more fun and easier to just do this with Code Interpreter. It goes and generates the code to go and extract the 10 images, and this is super useful. Now I have the 10 images and I can download each of them right here and go and work with them. That in itself is a super useful thing. If I have some image, or I have some movie, or some audio file and I'm going to extract something from it, I want to get a segment of the video. I don't want the whole thing or I want to chop off the start and end, something like that. Now, there's a limit to how much, how big a files you can upload, but you can do pretty sophisticated things and you can get away with a lot. I'm going to say just go and display these 10 images so I can get a sense of what the images look like that it pulled out and it generates this nice graphic displaying the 10 frames that is extracted, and we can look at each one of them and see what they are. Now, what I've decided I want to do is something that you've seen a lot on the Internet. It's a fun little thing to go and do, and that is I want to go and resize these things, modify them some, and turn them into a animated GIF. I'm going to start off by just telling it, now if you imagine you have like 100 images you need to resize, this is super effective. I'm just going to say resize each image, maintain the aspect ratio to 300 pixels wide. If you have a bunch of operations, you want it to apply to an image and you don't know how to describe it and text what you want, you can just go and put that in there. I'm just going to say resize each image, and notice what I'm doing. I'm giving it a pattern to follow on each individual one. I'm saying resize each, and then I'm giving it to constraints what I want. This is going to be a pattern that you're going to see over and over is you're going to tell it what you want to do it and you're going to give it constraints on what you want, and you want it to fill in the details and find a solution that works. Now, if you don't give it enough information, you may not get the final output that you want. In this case, I was very specific, maintain the aspect ratio. I want the ratio between the height and width of the image to stay the same. Even if it's shrinking one dimension, it needs to also shrink the other dimension correspondingly. I'm giving it the constraints that I need, and this something you're going to do over and over is you're going to give it basically whenever you interact with it and ask it to accomplish a task, a lot of times you're going to give it some constraints on what you want, but you're not going to specify everything. Because if you think about a conversation, a more efficient pattern in interacting with conversation is you want to give and just specify the important pieces in the conversation. In your pattern of conversation or interaction, you're going to specify the important constraints that it needs to follow, but not everything. The important information is what you provide, and then you let it infer and figure out the rest. Now sometimes it's not going to be able to infer everything correctly, but you want to think about that. Put in the important pieces, but you don't need to specify everything unless you really do need to specify everything. Now it goes and it resizes each of the individual images. I could go and download this there. But what I'm going to do is I'm going to say, I'm going to do another transformation. I'm going to show you how we can get more complex. I'm going to say convert all of the images to grayscale and increase the contrast 30%. Again, I'm telling it what to do on each image and I'm giving it some constraints on how it's done. This is pretty explicit in this one, and so it then goes and reprocess all of the images. Notice how useful this is. I'm going and applying in natural language and operation to a whole bunch of files. When we've looked at it previously, we've done a lot of work where we look at extracting and pulling out information and reasoning about the information within files. In this case, I'm just working on the files themselves. I'm not actually pulling out per se information that it's reasoning about. I'm just going in and have it apply different operations. This is a pattern of usage where it is acting as like my intern and it's applying tools to a set of files per my instructions. Whereas some of the other tasks that we've seen it doing, it's actually having to go and reason about what's within the files and how to work with that and what that information means. In this case, I'm just having it apply different tools to the files. It's going and processing each frame. Now I'm going to say, combine the images into an animated GIF that flips to the next image at one-second intervals. Very quickly I'm going to go to a completely different product and it goes through, and it generates the image and creates the animated GIF. This is fun. Now we get the result right here. What we see is this nice little animated GIF of the images that have been extracted and the bike riding happening. This is a fun way of going and processing media and getting something new out of it. We can take a video and we can turn it into a series of images. We can do batch processing on these images. We can then take those images, combine them back into a new form of media and animated GIF. But I'm also going to show you one other one. This is going to be really useful probably for a lot of people who are in business, sales, marketing. You can go and create PowerPoint. I'm going to say turn the individual images into a PowerPoint presentation with one image per slide. Now, clue in, you can also go in like generate a bunch of visualizations from an Excel file and then put those visualizations into a PowerPoint or add in text or whatever you wan to do. But clue in, you can create PowerPoint, you can create Excel, all kinds of interesting things. I could also go catalog these images in a CSV. If I wanted to say like, I want to track the source of the movie they came from, where in the movie they came from, I could go and do that. In this case, I've created a PowerPoint presentation. Now if we take a look, I'll open that up and show that to you. Now I've got here's my PowerPoint presentation, and I can go and flip through the various slides that are the same images. This isn't the GIF anymore. This is actually my PowerPoint presentation that I've created with these images. That's a super useful thing we could go and do is turn it into PowerPoint, convert it in different types of media. We could also go catalog it, catalog all of the images in a CSV file with the name of the image, the movie, the name of the movie file that the image was extracted from, the time in the movie that it was extracted from, and the operations applied to it. We could go do that. We could go and catalog all of our operations. If we want to keep this all organized and we want to know where all this came from, we can have that. It's going to go and generate this catalog, and then we'll have that and we could go. If we want to know where all this stuff came from, we want to know how we produced it, we want to be able to reproduce it, we want to be able to find those original images, maybe we want to do bigger versions of them, maybe we want to apply different sets of operations, we could go and do all of that and we have a nice CSV file to organize it. Now we've got our CSV file that's been created and we could go and download that file and begin working with it, keeping it catalog. This is really useful, all the operations you want to see. Going and taking media, doing all kinds of operations to reformat it, to restructure it, to resize it, adjust the colors, adjust the look and feel. We can go and then take it, turn it into different types of media like an animated GIF. We can turn it into a PowerPoint presentation, but then we can also do the organizational aspects. If we're doing this professionally, for example, a lot of times we need to know where are all these assets, where did they come from? How were they created? All of that type of metadata and cataloging can be really important, and we can automate a lot of those processes as well.\n\nWe can always go and upload individual files and download individual files to code interpreter, and we can certainly get by that way. But one of the wonderful things about code interpreter and the way that it works is that it can actually take zip files, unzip them, work on multiple files at once, and automate entire processes for us, and then zip up the results and give us back multiple results at once, which is way more convenient. It also allows us to do interesting things, like when you have a zip file, it can actually have a folder hierarchy inside of it. Or we can give additional things or tools or other possibilities, bits of python code, anything we want to do to code interpreter. But I'm going to give you a simple example of why an archive is so helpful. Let's imagine that you have a series of images, and you want to go and apply a transformation to them. You want to make them much more stylized, apply some filter to them. You've taken all these images, okay? Now, you want to stylize them. So, I'm going to upload an archive full of images to code interpreter. But this could be an archive of any of your files. It could be an archive full of Excel files that you want to combine. It might be an archive full of Excel files, and you want a specific visualization built for every single individual Excel file. Or maybe you want to search across those Excel files and filter them for a subset of rows and then create new Excel files, whatever automation you want to do. So whenever you start thinking about I have multiple files and I need to automate some process across them, you want to start thinking about uploading a zip file to code interpreter. Zip everything up that you're going to perform the operation on, describe the operation and tell it to perform it on the files that are within the zip file. Simple automation, super effective. So, I'm going to upload this archive full of images, and I'm going to say, please make these images much more stylized by dramatically increasing the contrast and saturation. So, simple pattern. Whenever you need to automate something on a set of files, zip them up into an archive and upload the zip. It's basically the archive interaction pattern. So now, what it's going to do is it's going to say, first thing, let's unzip the archive to access the images. It then pulls out each of the individual JPEGs, which were JPEGs that I'd pulled out of a movie, it then goes through and access provides each of them. Now, I could stop and I could download them one by one at this point, but that seems like a lot of work for me, particularly if I've got 100 files or 200 files. So, instead what I'm going to do is I'm just going to say zip up the files so that I can download them. So, we can use zip to automate the processing of multiple files so that we don't have to upload 100 different files. We can just zip them up and put them up there, but also to save us the time of how are we going to get all these files back down. We can zip them up in order to download them. So now, I can just go and click on download the enhanced images, and I now have all the images. The other thing that's really useful and I mentioned this, is that a zip file can have a folder structure to it. If you just upload individual files, you can't create meaning or organization with the folders. Now, you can do this both on the things you upload. For example, you could upload an archive that had different folders and you could say, take all of the files in this folder and all of the files in this folder and do something with them. And so because you have folders, it then allows you to refer to them to talk about certain file sets and already have them organized. So zip files, they don't just give you the ability to upload multiple things at once, but they also give you the ability to organize what the input you're giving it. You can organize the files into different directory structures, different categories, these types of things. And so it's a useful tool for organizing the input that you're giving it and then being able to refer and talk about different sets of files or groupings or to help it figure out what it needs. So for example, if you're trying to do a process and you have all the files related to cats in a folder, and then you go and ask a question related to cats, it's going to be much more likely that it's going to be able to figure out which files are relevant and automatically go and find them. So one way that having a zip file can help is it provides an index for code interpreter to go and find the right things. So in this example, this is one I showed before, I'm going to upload a zip file. I'm going to ask it to read each file and summarize what's in it, propose a folder structure for those files, propose better names for each file. This is another kind of really important aspect of this. It can rename files as well. And then when you have it all done, zip it up, or show it to me in this case. So it goes through, it reads all the files. And this is just a fantastic tool for file organization. You have a ton of files, zip them up, throw it in there. If you haven't kept the organization up to date with what's in those files, and you'd like to figure out a better way to do it, well, here's the AI driven file organization. It's an amazing little utility. It summarizes all the files, it proposes a file organization or hierarchy for all of them. And then I go and I have to work with it a little bit, because it couldn't quite figure out what some of the files are, but I tell it to go and try a different method. And this is a useful thing you'll want to know, is like if it doesn't quite work out, just tell it. Try another way, try to do it again, but come up with an alternate method. So, that this is a pattern of interaction, if it won't do it, say try an alternate method. Don't give up, try an alternate method and often it will find another way to do it. It goes through, and it proposes a new folder structure. We have course descriptions, receipts, reports, and policies, and it turns out that's actually an excellent organization of these files. And then I just tell it looks great. Create a zip file so I can download it. Now, the key thing of this zip file is it maintains the folder structure. So now, the folders are organized inside or the files are organized inside of those folders. So when I get it back, I'm not having to figure out how to do it. Now, notice one thing it didn't do for me. I forgot to get it to make sure that it went through and renamed the files. It didn't actually do that. And I think that's probably my fault for not confirming and saying, hey, the structure looks good, now rename everything, that was my fault there. I just said, go ahead and zip it up. And it did that, and now here's the zip file. So this is a fantastic thing to know about. Anytime you need to automate work on multiple files, anytime you need to automate the creation of directory structures and hierarchy, anytime it would be helpful to you for code interpreter to have a directory structure that organizes the files so it can more efficiently either find things or so that you can more efficiently tell it where things are or talk about the sets of files, zip files are a fantastic way to do that. So, whenever you need automation or whenever you need to output multiple things, or whenever you need structure in the thing that you're getting back in terms of the file organization hierarchy or the file organization hierarchy on the input, fantastic way to do it is with zip files.\n\nThis next capability I'm going to talk about is really one that you can only take from start to finish if you know how to program or you're a software engineer or computer scientist. But you can use it in conjunction with somebody else who is really good at those things if you aren't a programmer or computer scientist. If you're an organization that has a bunch of programmers or you have a friend that it's a programmer, this is a way that you could do that. Now what is this technique? It's a very exciting one from the perspective of software development. One of the challenges that we have is we have all these little tools that we would like to have to help us out. All day long when I'm working and thinking it'd be really nice to have a piece of software that did this and simplified this process for me. Sometimes as a software engineer, I'll go and take the time to actually write the software to do that. The Code Interpreter creates an intriguing new possibility where we can actually turn a conversation with Code Interpreter into software. Now, if you are not a programmer, if you can't read the code, you should not go all the way through with this because you have to be able to look at the code and know if it's going to work correctly, if it's safe to run on your computer. It could delete all the files for all you know, if you can't read the code. We 100% know that large language models can make mistakes, and you need to pay attention to the code that comes out of what I'm going to show you, and if you can't read it and understand it, you should not proceed. You will need to go find a programmer to help the rest of the way. But a programmer at some point, a human software developer, needs to be involved in the analysis for what I'm going to show you. However, it's really exciting. Let's take a look at what we've got. This is an original conversation that I had where I took a movie and I extracted 10 different frames from the movie, I then went and display the images. I looked at it, I'm having this whole conversation, I resize the images and I did a bunch of other things. I turned each image into grayscale, I increase the contrast by 30%, and I turned the images into an animated GIF. I also created a PowerPoint presentation with one image per slide. Now I thought, wouldn't it be great if I could take this whole process so that I can repeat it? Now, I've repeated exactly this type of process for creating tools to help me with the creation of these videos and cataloging them. For example, automatically going and taking my videos and measuring how long they are, creating CSV files for them, doing other interesting things that then help me along. But any conversation that you go and have with Code Interpreter, you can turn into a piece of software in most cases that you can then run completely separately from Code Interpreter and you can even have it call out to OpenAI's APIs to replace the part where GPT-4 was present in the conversation. Then the last step in this thing, I created the PowerPoint and then I also created a CSV to catalog all this stuff. Here's what I'm going to do. This is the real magic now. Again, if you are not a programmer you need to find a programmer if you're going to take this approach. If you're a programmer, you're going to be able to rapidly accelerate the pace that you can create your own personal tools, because any conversation you have with Code Interpreter that yields a good result, you'll be able to kickstart a piece of software for yourself. Here's what I'm going to say. Turn this process into a Python program that I can download and run on my computer and provide the paths to the documents as command line argument, zip up the program for me to download. Now note you could have also gone and said create some GUI application or something else, anything that it has the tools to create, but I'm just going really simple, I'm just saying turn it into a Python program. You can also tell it to replace calls to GPT-4 with calls to OpenAI's API for GPT-4, the completion API. But I'm not going to do that here because I don't need it. What does it do? It says, sure, I can help with that. It's going to create a script that extracts all the frames from the video, resizes the images, converts the images to grayscale, creates a PowerPoint presentation of the images, catalogs them in a CSV file, and makes an animated GIF from the images. It then gives us the command that we're going to need to install all the Python packages for this piece of software, and then finally, it gives us the zip file, which I have actually gone and downloaded. I'm going to show you what this thing looks like now. Here is the application that it has built for me. I'm going to now run it on a new movie that I did not do before, and this thing is going to run for a second. It takes a few seconds to do all of the work that's in here. Then we should be able to see that it's produced a number of different outputs. It created the extracted frames, so if we go and looked at that, we have all the extracted frames from the video, we can go, and we see also that we have this frames presentation, which is all of the individual frames put into a PowerPoint presentation. We have the resized frames, we have the catalog image in CSV. Now, note something. I said it's really important to have a programmer look at this, and the reason is, is because it's not perfect. One of the things that it was supposed to do was to create an animated GIF, and it didn't do that. Now, as a developer, I can easily go and look at the program before I run it, which I did, and I saw that there was nothing problematic in it, I read the code. Then two, I could go and then say, it doesn't have that animated GIF or whatever it is and I could modify it and work with it to get it there. Now the key thing about this is it turned the conversation into a piece of software, and that flow of that conversation dictated the requirements for the software, and the user was interactively developing it. Now if we go back and look at the conversation, as I'm actually going through and running through it, I'm actually going to see incrementally building what I want the conversation to look like. I'm essentially doing the process of trying and building it incrementally and testing it out. Here I'm seeing an intermediate output, I'm then getting to look at the intermediate resized images and check that it's doing what I want. The key thing is it's producing Python code along the way, to do all this stuff. When it gets to the end down here, and I'm telling it to go and create the final Python program, really all it has to do is stitch together all the code that it's already created and modularize it a little bit. Add places where all these paths and things can be taken into the program as command line parameters rather than starting from scratch. Now, if you're not a programmer, how do you use this capability? One, you could kick-start a conversation. You can download it then, and then you could take it to a programmer. You could go hire a freelance developer or some development shop, to then review that, modify it if it doesn't work exactly like you want. But think of how much farther down the path you are. You can show them, here's my requirements, here's the conversation I had where it did exactly what I wanted, here's the initial Python program that it produced for me. Now, go and check that it's going to line up with what I just did. Here's what I want it to do, and here's what it produced. Do a quick audit of it, read through the code, test it inside a container, make sure it looks safe and reasonable, run it on some test cases for me and debug it and run it on my original test case, and then if it looks good, give it back to me. It's a different type of style of software development. It's going to create a new paradigm that's really exciting for creating these smaller tools. We can probably do that much less expensively than when we start from scratch and when we're trying to collect all the requirements, and we're trying to get everybody on the same page about what it's supposed to do and how it's supposed to work. Now we're actually having the end-user build up the process and the flow of what they wanted to do and interact with it through Code Interpreter and generate the initial starting point for the software before taking it to the programmer. The conversation itself becomes a set of requirements, and the software becomes the initial starting point for the developer, so hopefully they don't have to do a whole lot to get it into a final form of a usable tool. Now, if you're a software developer like me, this is awesome because you can take the conversation, you can output Python and you're way ahead of the game. Now in this case, I would have to go and work with a little bit to fix that part that it wasn't giving me the animated GIF I wanted and look for it and make sure there's no other bugs. I'd test it, do all the normal things I would do if I got a piece of software or if I had somebody else write a piece of software for me. But it's a really exciting capability that I think is worth talking about. Now again, I want to warn you, if you're not a programmer, you should not download these things and run them blindly. If you are a programmer, you should not blindly trust the software that comes out of it. You should download it, you should read all the code first, make sure you're comfortable with what it's doing, and you should test it in some safe environment like inside of a container or something else if you're at all concerned about what it's going to be doing. Now, in most cases, these things are going to be fairly straightforward, smaller bits of software, fairly easy to audit. I've created a lot of great tools for myself using this process. It's something really exciting that I think is a new style of software development that's going to be enabled because of Code Interpreter.\n\nI want to help you gauge the difficulty of a task that you're about to start with Code Interpreter. Now, the reason for this is when you get started, you're going to have all ideas of things that you can go and try. But I want you to have a way of understanding how difficult each of your ideas are going to be to accomplish. If you understand two basic things that we're going to talk about, you'll be much better off in terms of gauging the difficulty of accomplishing a particular task. Those two things are, if you want to know how difficult a particular task is going to be, we want to go and look at the document or data that we're going to work with. The first question we want to ask is how structured or unstructured is that data? Structured data is something like a table. If you've got a bunch of tables that you're trying to read through and it's all in Excel format, that's a structured format. This is an example here where I'm uploading a CSV file, that is a structured format. It's like a table. It's some very clearly marked format where you know what all the parts are. CSV files, Excel files, all of these types of things are very structured. If you're working on data that has a clear structure to it, it's going to be much easier to do your tasks. If you're working on CSV files, Excel files, those types of things, and you're trying to do tasks that deal with their current structure or transform them into new structures that are relatively straightforward like visualization is not going to be too hard. Let me give you an example of this. I've got some data right here. This is some information that I've extracted from Vanderbilt's annual report. I've taken this data and I put it into a CSV file. It's very well-structured. I go and insert the CSV file into ChatGPT or Code Interpreter, and really quickly it can end up generating a visualization with almost no effort on my part, because this is a really easy data set to work with because it's very structured. Now, let's contrast that with an example where I took the same data but I didn't start from a CSV file, I started from the PDF of Vanderbilt's report. I had to go and extract the data first. This is what we see in the report. There's all these different pages of data and the thing that I'm looking for is buried on one of the pages. If you look at the text, it's structured maybe to a human, but it's not very structured to a Python program or Code Interpreter or something else. It's not in a great format once you extract it from the PDF. If you can read the PDF and look at it visually, it's structured, but if you actually look at the underlying text and the structure of the text itself, it's not, and it's not very clear what everything is and this thing is hard to read and look through. Basically, what I had to do is I had to take all of this unstructured data and I had to give it a lot of hints about what I could see visually. I told it look, the original data was a series of tables and headers before each. That was something that is easy to see visually. But if you looked at the underlying text it was hard to see. Each table had five columns, so I'm having to do all this work to help it rediscover the structure. If you have unstructured data like this, you're going to have to do a bunch of work to discover the structure. It takes a lot of back-and-forth with it before finally, now I've got it in a structured format. This is what it looks like when it's structured. Now we have a table with clearly delineated parts. We've helped ChatGPT or Code Interpreter to rediscover the parts. But if you look at all this text up here, it was not easily structured, it was not easy to extract and analyze. Important point number one, if you're working with structured data, your task is going to be so much easier in Code Interpreter. If you're working with unstructured data, task is going to be a lot harder and you're going to have to do more work. Just know that upfront. Now, second important point is how much unstructured text you are working with. How big of a document are you trying to analyze? This also is true for how big of a thing you're trying to create. I'll talk about later. But for right now, let's just focus on the documents or the data sets that we're working with. Unstructured versus structured makes a big difference and how easy it is to work with on Code Interpreter. Second one is how big the thing is that you're trying to work with, particularly for unstructured data. Now, for structured data, you can get away with much bigger data sets for most tasks. But for unstructured data where you want to have it read, and this is what I want you to think about is if you're thinking, I'm going to need Code Interpreter to read this and understand it in order to perform the operation well, it can only read and understand so much at one time. If you have a document that is bigger than Code Interpreter can read at one time, and how do you know how much Code Interpreter can read at one time, well, the metric I'm going to give you for this is if you can go and cut and paste all of the data from Code Interpreter. Let me just download this file right here and I'm going to show you an example of this. I've taken the IRS 1040 form. I'm going to go and I'm going to send a message. I basically had it extract this whole file into text. Now I'm going to cut and paste it into a chat message. It's going to tell us, hey, it looks like you've pasted the IRS 1040 for 2022. This document, what I did here is I took that PDF file and I extracted it into a text file, and the text I got out of it, I was able to just directly and copy into a chat message. If you could have taken that document and just copy and pasted everything that was in it into a single chat message and had it say, that's fine, that is what you would call a small, easy to work with document. If you've got a bunch of unstructured text that is of that size, no problem. Now, this is the Vanderbilt financial report that's like 40 pages long. It doesn't fit in a single text message or a single chat message. In this example, I've cut and pasted it. I've left this in place with the error message so that you can see it because it takes a little bit to do all this. Now I've copied and pasted 40 pages worth of material into Code Interpreter. What does it say? It says the message you submitted was too long. Please reload the conversation and submit something shorter. If you are in that situation, you are not going to be able to just tell Code Interpreter, read the document and have it read and analyze the whole thing at once. It's going to have to break it down into individual pieces and read and analyze individual pieces at a time. The moment you begin doing that, it becomes trickier and more difficult to perform the operations. Now, you can absolutely do it and I'm going to teach you all the techniques for doing that. But right now, particularly before you've learned all those techniques, try to start with things that are structured and start with documents that are smaller, and you could literally cut and paste it directly into a Code Interpreter message, because those are the ones that are going to be the easiest to work with getting started.\n\nOne of the most important things that you can do with code interpreter to be effective, particularly if you want to be effective in getting it to reason well. Or to write well or whatever it is is you want it to make sure that it has easy access to the knowledge that you're going to need it to reason on or use as the basis of its writing, or to do whatever it is to filter, to transform whatever it is. Now, the easier it is for it to access that information, the more successful you're going to be in using code interpreter. Now, what does it mean for it to be easy to access? If you can see the information here in the conversation, you are very likely going to be successful in whatever knowledge based task you're trying to have GPT Four do through code interpreter. So let me just repeat this, if you can see the information that it's going to build off of in the conversation, you're much more likely to be successful. This is the simplest, easiest way to try to make sure that the reasoning is sound. Now, in this example, with the 1040 that I did a minute ago, I had it go and extract a bunch of information and then I had it reread and extract additional information. And part of the reason for this was I didn't see the Identifiers for the questions in the conversation. And I thought that was going to be something that I wanted based on the idea that I was going to go and talk about different questions or ask about what checkboxes. Well, if I'm going to refer to checkboxes, I'm probably going to need to know the Identifiers form so I can go and reference back into the original form. Now, you don't have to do this, but it's often the easiest way to reason about what code interpreter is doing and getting it to do the right thing is to get it to read the information into the conversation. Now, there's other tricks that are used in the background to make this happen. Now, there's two places that the reading and rereading can happen. Now, I want to show you something interesting though, because I think this is really helpful to also show you why reading and rereading is powerful. So in the first time that I said read this, we see it pop up this box that's going and getting the information from Python, right? It's using Python to read the PDF and extract the text and then it shows the result here. So one thing that's helpful to note here is it's actually brought everything into the conversation. Now, this is sort of a tricky thing to know, but the fact that it's read it and then it's put it in here in this result, that means it's available and in the conversation, it's possible to have access to it. Now, it may not have access to it all at once and we may need to go and refresh it, but it's all in the conversation. Now, note what it didn't do here, when I said reread, it did not go and run Python again. Now, there's two things that that could mean, and it's helpful to know this. One is the information that it needs to do this task is already present in the conversation, and so it doesn't have to write any new Python. It just goes and summarizes or reshapes or reformats information that's already been brought into the conversation. Or it is possibly hallucinating or relying on data that it was trained on, which may not be what you want. So you want to be very careful, and this is why it's helpful to think through knowing what is in the conversation and what is not. What is clearly in the context of the conversation, the easiest, simplest way to know what's there is to make sure it gets read and is visible in some way. So when you ask it to extract it, summarize it or outline it and put it directly in here and you can see the text written out, that's just a very helpful check. And if you go, let's say, for example, if you do something and you don't see it, write Python code and you just see it refactor or reformat or restructure or summarize down here, that could mean one of two things. Either that information was already present, or it's making up the information based on, now, it doesn't have to be false, it just means that it isn't getting it directly from your document. So it's either getting it out of the conversation, or it's potentially based on something it was trained on. Now, the Form 1040 is something that is so common, it could have been trained on a prior year's 1040. Now, in this case, it turns out that I've uploaded the Form 1040 from 2022. Now, it's possible that this version of the model was updated and based on 2022's Form 1040, I don't think so. And I think what it has done is actually brought the whole form into the context of the conversation. Although we can't see it at the beginning, I think it is already there and available through the result right here. So that's really important to know is, is the information there and readily present? Now, in this case, this is a great case where I just want to emphasize the importance of paying attention to what is clearly visible in the conversation, which in this case is all of this here. What is it doing in Python? Well, we see at the beginning, it's definitely reading the document in Python, so we know it went to the source document originally. Now, I'm getting it to reread and bring in additional information, and it's not using Python. So either that information was already in the conversation in some way, because it read the whole document and has access to it, or it's pulling it out of its own training data or it's hallucinating in some way. And so when we begin bringing information into the conversation and working with it, when we begin asking to reread or summarize our things, we can start getting a sense of what is it really going out to the document and getting versus what's in the conversation, versus what is it pulling out of what it was trained on. Now, figuring out what is coming from specifically from the conversation, the context that we see here versus what it was trained on is tricky and there's no single straightforward way to do this. There's multiple approaches that we can use to try to solve this problem, but at different points it can be a little bit difficult. The best way that we know that it's going to our document is that we see the gray boxes and that we see it's doing something, but we don't always want to go into it our gray document. Because if we're having a conversation and we see that there's a direct mapping between what's above and what's below based on our task, then that's really what we want is to get things into the conversation, particularly for reasoning tasks or writing tasks or summarization tasks. We want to get it into the conversation summarized in some form so we can start working with it. So if you are in a situation where you're working with some document and you feel like you're struggling, that it just can't reason effectively, try to think about how do I get that information into the conversation so that I can see it here. One, it's going to help you get a better sense of what's going on, but two, if it's in the conversation, it's much easier for it to reason on. And three, it'll also help you sort out is it picking up something from somewhere else? Now, getting the information in the conversation doesn't have to just mean that we are going to just literally cut and paste into the conversation. There's all kinds of different ways that we can get information that it needs for reasoning into the conversation. And part of the reason I say this, if you go and look at what I did here, this is a lot of information, it's a lot of text and it actually took a while for it to output it all and we may not need it all. So what we want to do is we want to get the information that we need for reasoning into the conversation and we want to be really careful that we are bringing in just what we need because there's a limited amount of text that can go in. I talk about using a small document and part of the reason we're using a small document is because we can get it all into one prompt and that's easier. When we get to bigger documents, we're going to have to be selective, really selective about what goes into the conversation and how we represent it in order to be effective. But the key is we want to get it the information it needs in order to reason and do the right thing. Now, it could be a summary, it could be an outline, it could be literally go and excerpt and read and paste verbatim into this conversation, essentially the text. There's all types of things that we could do, but one thing that we can do is we can also get a map and we'll talk about this more later, but we can create a map of where information is within the document and put that into the conversation. We can put all kinds of other artifacts or things into the conversation that help it go and achieve its job. So in this example, I went and had it put an index of where different types of policies are covered in a document. Now, if you think about this, if I gave you a document and I said, go find this policy and that document has an index and you can go in and look up the correct section to read, that saves you a vast amount of time, right? You have a very dense little section that gives you exactly the information you need in order to reason correctly about where to go to get the next piece of information. So you could go and look up, I need to go to page two, you then flip to page two and you can read just page two, which gives you less information. Well, that exact process helps code interpreter or helps AI, anytime we can give it a map of where to go find the information. It can read the mapping, which is typically much smaller than the larger volume of information, and then it can jump into the location that it needs to get the actual piece of information to load into the conversation to do the work. Now, if we look at this, we've built an index here and then the next thing that we do is we say read the policies related to staying in an AirBnB. And notice what it does, I'm going to show this, this is code here, but hopefully you can get a sense of what this code is doing, is it jumps because it has the index in separate pages for each piece of information. It jumps directly to the pages it needs to read. And so it says page 4 text and page 7 text. And if you're not a Python programmer or this doesn't look familiar, just notice that it's saying page 4 and page 7 for AirBnB. And if we look at this, we got page 7, which is Mileage, and we've got page 4, which is International Travel, which actually I'm incorrect here. So page 4 and 7 all relate to lodging, sorry about that. And that just shows to show you the AI sometimes gets it better than the human, I make mistakes, it make mistakes, no judgment. So lodging is covered on pages 4 and 7, we're talking about AirBnB, AirBnB which is a form of lodging. So therefore on page 4 it goes and reads it, and page 7 it goes and reads it. So the AI has done the right thing, it's used the information that we brought into the context. This document was too big to fit into a single message, so we basically brought in information into the conversation that it needed to reason effectively. And then it can use that as a jumping off point to go and find the next piece of information and bring it into the conversation. Because you see right here the result is it now brought in those pages into the conversation in the result, and then it goes and reasons about what's inside of those pages. So when you're working with code interpreter, when you're that if you can see the information here that it's going to need to reason, you are much better off. If you can't see the information that it needs to reason here in some form, then there's a good chance that code interpreter is going to struggle or that code interpreter may hallucinate and you not realize it. So when you are working with code interpreter and you want it to reason about knowledge in text, try to get some form of that text into the conversation where you can see it. Or try to get some mapping like we've done here, like an index into the conversation so it can reason about it or try to get something else. If you're working with structured data, make sure it knows about and talks about the columns that you're going to be working with and brings them into the conversation. Now, it may go and rediscover and relook at the Excel file. But if from the beginning you say, explain the structure of the Excel file to me, and it lists all of the columns in that Excel file, and it already has it there, then when you go and ask it to perform a task that requires reasoning about those columns, it's going to be really easy. It's already in the conversation, it can immediately go and do it. Now, you won't always have to get the information in the conversation, but it's a really effective tool if you can get it into the conversation. A lot of times it's going to make things much easier. So one sort of simple mental strategy when you're working with a problem and trying to figure it out and how to solve it, is it's often easier to solve the problem related to the reasoning that you're trying to get it to do or the writing that you're trying to get it to do. If the information that it needs to do the reasoning or do the writing or outlining or whatever it is, is visible in your conversation, it looks like something that GPT Four told you inside of code interpreter. And if you can't see that information, it's going to be trickier to get it right. Now, you can do it, but as a simple rule of thumb, it's going to be easier if you can get that information brought into the conversation at some point. It's not always required, but it's often a helpful tool."
  },
  {
    "index": 3,
    "title": "3 Tackle the Right Problems",
    "content": "One of the most important things you can do is make sure that you pick problems that actually make sense to solve with code interpreter. So not every problem is the right problem to work with. Now, I want to give you sort of three basic things that you can use to help guide you in problem selection. Now, these are not the only three things that you might want to use and take into account, but they're three rough guidelines that will help you out in deciding is the problem appropriate? Now, the very first one is we have to understand that there's always the potential that there's going to be an error, and therefore, we always have to be checking our answers in some way, shape or form. A human is going to have to look at it or we have to have some way of knowing whether it's right or not if we're going to use it and take ownership of the output. So one of the first simple things that we can do is we can make sure we pick problems where it's easy to check if the answer is right or not. And checking if the answer is right or not is a lot less expensive and time consuming than producing an answer. So what is an example of this? Well, in this example that I gave earlier of solving wordle problems, so wordle is a word game. You have to choose words that are five letters long that meet certain constraints. You'll have certain letters that are allowed in certain positions, certain letters that aren't allowed in certain positions. It's a great example of the case where it's easy to find out if a solution is right or wrong because you just plug the solution in and you check the constraints. So for example, this is our pattern, we have to have a word has, e is the second letter, t is the last letter, and it can't include any of these letters r, or y, u, i, etc. Then we can quickly go and check if a solution is correct or not. So when it says beget is a correct solution, we can check that by simply going up here and see, does it fit the pattern? Yes, it fits that pattern. Does it include any of these letters over here? No, therefore, it's a correct solution. But coming up with beget is much more expensive, so you have to go and search through a whole bunch of words in the dictionary, check each one to see if it matches the pattern. And so it's easy to check if an answer is correct or not, but it takes a lot more work to go and find individual answers. You can think of this like in a crossword puzzle. It might be easy to go and check if the words are potentially right or not, but it's much more difficult to go and try to come up with all the individual answers that fit together. So you want it to be easy to check or you want the errors not to be a big deal. Meaning, if there's an error, it isn't the end of the world, right? It's not a big problem for you. Now, the next thing that's really helpful is you'd like to pick problems where a partial solution is better than no solution. So if you're getting closer and closer to a perfect solution, as long as you're making progress, it's a helpful problem to work on. So what is an example of this? Well, when I went and uploaded a zip file full of PDFs with no organization to them, and I said, go and propose a new organization to them. And it comes back and it proposes an organization, and the organization is partial, but it's not perfect because it's got this others category over here. It's already done some work for me that helps me, right? The solution doesn't have to be perfect on the first try, and then I went and I refined it, and iterated with it, and it basically improved on its solution. And its solution is still not perfect, but it's better than I was before when I had total disorganization over these files, there was no organization whatsoever. So a partial solution, meaning a partial organization of these files into categories is better than I started with, so it's helping me in some way. So anytime we have something that we can work on incrementally, and even having a partial result is better than no result, that's a great type of problem to work on. Another one that's really helpful is anytime we can support human reasoning. If we're not supporting human reasoning, we're going to take away people's thought, we're going to make them less creative, less likely to do the right thing. So if you're using it to cheat on an exam, stop right now, you're taking away from yourself, and your own creativity, and thought, you're teaching yourself not to think, not to solve problems. On the other hand, if you're using it in a way that helps you be more creative, then that's a great type of use case or problem. So, for example, when I was going through and I was analyzing all the people that had registered for my workshop, I had this question where they could enter in free text whatever they wanted about how they were using ChatGPT, Bard, all these tools at the time. And then I asked it to go and automatically analyze how people were using it and group it together. Now, the reason isn't because I wanted to take away my own ability to go and reason about how different people might be using it or to look at it. No, the reason was is because I wanted to think through different ways of categorizing people. And the real goal of this was to help me think better about who my audience was going to be in that workshop and think about what I needed to tell each one of them based on different ways they were using it. So I had one categorization, and then I went and said, give me three more possible groupings that describe how people are using it. And it went and proposed other potential groupings based on engagement level, specific task usage complexity. And so the end goal of these was to help me think better. It was to give me additional information so then I could go and think about how to deal with my audience. It wasn't to think for me and think of what should it tell my audience for me, what should it do? No, the goal was for it to give me information that could help me think and improve my own ideas. Similarly, when I had it go and generate potential questions about my presentation, it wasn't so that I could stop thinking about my presentation or have it produce the presentation for me. It was so that I could think better about what might I want to address, what might questions be for people. So all of these types of uses where we're automating things, we're giving ourselves more time for thought, we're going and helping answer questions or seeing other perspectives. We're giving ourselves new insights or visualizations of data that we need in order to reason ourselves, those are really important uses. So one, make sure that it's easy to check the solution, or that checking the solution, whether or not it's correct or not, takes a lot less time and effort than actually producing the solution. Two, is it something where a partial solution is better than no solution and where you can iterate on the partial solution in order to make it better and better? And if you stop at some point and it's not perfect, you've still done a lot of great work, and it's helped you. And third, make sure that you've got a use case that actually is supporting your human creativity and reasoning, that's going to make you think more overtime. If you're starting to do things with the tool that are making it so you can get lazy and not think and not be creative, you should drop that use case and focus on other ones. Because the whole point of these tools is to really, really take advantage of them, really be useful with them, is you want to use them in ways that help you have more time to think, help you be more creative, help you solve problems better, not do less thinking. So if you're doing less thinking with the problem you're approaching and the way you're approaching that problem, then it's the wrong way to to approach that problem or it's the wrong problem to be solving with the tool.\n\nThe most important thing that you can do when you're interacting with a large language model or a tool like Code Interpreter is to use it in the right way. If you're not approaching the right types of problems, if you're not thinking about things in a framework that helps you to create solutions that are really going to be effective and work, then you're really not going to use the tools effectively. So I want to start by talking about how should we be using AI, what are the types of problems we should be applying it to, and how do we sort of assess if we've got the right type of problem in our hands? Should I really pursue this path? Well, I want to give you a framework to reason about this. So I'm going to start off by going through an example that's also based on my belief in the framework. Now other people may tell you different things, but this is my belief in where we should be headed with AI and how we should be using it and employing it in human systems. So I've asked it to go and help me create an acronym for my framework. My framework the focus should be on five key things. If we've got a problem that is related to these five things, then it's probably a good problem to start investigating further to see if it's a good fit. Number one, we want to look at ways of using AI to aid in human coordination. Two, we want to reduce tedium to provide more time for creative thought and problem solving. So all of these tasks that you do every day that are better done in some other way so that we can take people and we can give them more time to be creative, to think, and to do the important things. Because the value in the human is not just tedious repetition of tasks. That's the way we use a lot of people today, but it's not the best way to make people one happy, fulfilled in their jobs. And two, if you've got somebody who can do interesting creative things, then we should try to focus them on that. Or if we can have them use their higher reasoning in more valuable ways, let's do that. Let's not overload them with tasks that aren't helpful. Now, it doesn't mean we don't do any of that. We're always going to have some of that more than likely, but let's help it. Three, we need to help spur better problem solving and creativity with humans, and we can do this in lots of different ways. And I'm going to talk about each of these different points in a minute. But I'll specifically hone in on this one because I think there's a ton of value here. People are biased in all kinds of ways. People talk about IAI bias all the time, but humans are incredibly biased, and we're biased in a lot of different ways. And one way we're biased is in seeing how to solve problems, seeing different points of view on issues, all kinds of things. And there's huge potential for using these tools to help try to overcome human bias. Four, we want to provide a safety net. Humans are making decisions. They're doing all kinds of tasks all the time. And there's lots of human tasks where we just don't have good safety nets in place. And AI can play a huge role in helping those particularly large language models. And then five, we want to allow great human ideas to scale faster. We want to help enable humans, when they come up with some phenomenal idea to take it out to the world and apply it faster and better. And so we're going to be looking at these. Now, I've asked ChatGPT to help me out. Now, I'm not using code interpreter, but I'm going to get started here, just within ChatGPT, and I'm going to show you kind of what I mean by some of these things. And then I'm going to go through each of these aspects of this acronym in this framework. I'm going to show you in separate videos. I'm going to go through the first one in a minute, but first I'm going to tell you, here's my acronym. Now what I did is I took all these statements and I asked ChatGPT rewrite these statements as needed to turn them into an awesome positive memorable acronym. So it's helping support my creativity. I could have spent a lot of time and effort doing this, but I thought hey, maybe it can help me come up with great ideas for how to turn these statements into an acronym that would help other humans remember, this is all about helping me get this message out. Help me craft it, scale it, get it out to people and help them remember it. And so what I want is I want it to slightly rewrite these sentences so that the first word in each sentence becomes part of the acronym. So it's this sort of helpful mnemonic that we can use to remember this framework. Okay, so here's what it's done for me. And I actually ended up taking its first suggestion because I really liked it. I think it's moving in the right direction. So it created the acronym ACHIEVE for me. And this is the framework we're going to use, ACHIEVE. This is what we want to do with large language models is we want to help human beings achieve, achieve their goals, achieve whatever creative, inspirational thing that they want to pursue. So how do we do that? How do we achieve with large language models? First, we want to aid human coordination with them. Two, we want to cultivate creativity and problem solving. Three, we want to help spur better problem solving and creativity. Four, we want to initiate a safety net and five, enable great ideas to scale faster. You know what? It's pretty good and it kind of got what I wanted, but not exactly right. And some people come back and they're always freaked out, right? AI is doing everything right, it's creating your acronym for you. What room is there for human creativity in this space? And this right here shows you that it's all about a conversation. There's lots of room for human creativity in this. There's lots of room for human reasoning coz I look at this and I'm like, it's okay, it's pretty good. It got me a lot of the way there, but it's not there yet. So I then follow up and I say, can you make the help be help provide a safety net? Coz I think that better aligns with the help safety net help that makes more sense to me. And then turn the I into something related to spur better problem solving and creativity. Because the I was really originally related to inspire. So it comes back and it says ACHIEVE and now it says Aid human coordination, cultivate creativity and problem solving. Help provide a safety net, inspire better problem solving and creativity, and enable great ideas to scale faster. Now this is helping me kind of think through and create and craft this message. And I'm doing it faster than if I was having to iterate by typing or writing it by pen and paper or some other method. This is faster for me on iterating with my creativity. So I'm kind of going through this process. I'm actually kind of demonstrating and working through, almost all of these ideas are being based on this. Now I look at this and I say, it's still not quite right. Number two here is not quite cultivate creativity and problem solving is not quite what I had in my original one, which was reduce Tedium to provide more time for creative thought and problem solving. It's not really the same thing that it's saying here. Cultivate creative problem solving is not the same thing as reducing Tedium, so you have more time to think about things. So I go back and I follow up and say, two needs to focus more on using automation to reduce the time that humans have to spend on Tedious tasks rather than thinking. And then we get an updated version. So our ACHIEVE acronym is now Aid human Coordination, cut Tedious Tasks through Automation. Freeing time for creative thought and problem solving, help provide a safety net, inspire better problem solving and creativity, and enable great ideas to scale faster. So these are the five things that I think are really the key areas we should be focused on when we are working with large language models. If we can help humans coordinate better, I mean, goodness knows we make mistakes all the time in communicating with each other, especially when we have teams and multiple teams working on the same project. There's so much human language that gets produced so much miscommunication. There's so much space to help improve that overall process. Not to replace, but to improve it, to help humans do a better job. We want to cut Tedious tasks through automation, allow more time for creative thought and problem solving. Also allow people to do more fulfilling work, thinking and other things. Now some of this may make sense. Maybe there's Tedious tasks and problems that are always going to be there and that people find joy from, and that's great. And we can leave those. But there's lots of people that aren't being used to their most effective, their greatest potential. And if we can help use them and help them do a role that is more suited to all of their potential and thought and ideas, let's do it. Three, let's help provide a safety net. Humans make mistakes all the time. And it is hard when you make a mistake and it goes and has an impact on the world that has consequences. So let's help catch those mistakes. Let's make it so people feel the freedom to go and be creative and to try things out and to innovate and to work without as much fear that they're going to make a mistake and cause some problem. And then five or four, and see right there, I made a mistake, right? If it helped catch me but luckily I caught myself. We want to inspire better problem solving and creativity. And people talk about AI bias, humans have bias. We have bias in problem solving. We have bias in different perspectives. We have bias in our beliefs about other people. We have bias and lack of information on all kinds of topics. Let's try to help use large language models to address those issues. And then five, let's enable great ideas to scale faster. Let's use automation, all kinds of things to help people build and create systems, real world, tangible outputs, be it creating some piece of software, be it better organizing my files on my computer by creating a phenomenal presentation to help communicate with other human beings. Let's help them do all of this and scale it up faster. Now I'm going to go through each of these in a separate video. Originally, I said I was going to go through one of them in this video, but I think I've run out of time. And actually that's probably a mistake that I made. And if I'd really had AI, and it probably would have told me and provided my safety net and said, hey, you're running out of time. You're not going to make it in one video. So I'm going to come back with another video and I'm going to go through each of one of these because I think if you start looking at it, you'll understand how to apply it using this framework to really help humans. And this frame work also is a great framework for helping to figure out what types of tasks should I be looking at and also thinking about, what is it that I really want to focus on in my organization? Where am I going to find the efficiencies? And I think this framework will help us get there.\n\nI introduced the ACHIEVE framework for thinking about problems that might be a good fit for solving with AI. Now, just because it fits into this framework doesn't mean it's the right type of problem. And we'll follow up on that later. But for now, I want to go through each of these elements because I think they're really useful. And we're going to start off here with the very first one, which is aid human coordination. Now, there are so many types of tasks that we do all day long that require human coordination and we make mistakes on them all the time. And if you think about how much money is wasted in poor human coordination, you can imagine how much potential there is. If we talk about operational efficiency, things like a lot of people talk about different types of tasks, but so much time, money, effort, headache, unhappiness other things just comes out of poor human coordination and communication. So let's look at how we can aid human coordination. So I'm going to start off with a simple example here, right? I've taken a bunch of meeting notes. I call it a transcript that was actually a typo and a mistake on my part. And I say, act as my personal assistant, read the following meeting transcript and provide me a summary of the key points of discussion, right? One of the things you always had a problem with is if you had a personal assistant or you had enough people looking at things, they might be able to get eyes and be really critical and identify problems, project managers. But imagine being able to have as many sets of eyes as you want, as many different extra eyes as possible that can take a perspective on this. Now, notice I'm using the persona pattern in this. I'm saying act as my personal assistant and I want you to read these following points and summarize them, so it goes through and it says thread one academic workshops at Prestige University. I've taken some of the ideas from a real workshop scheduling problem that was being done where we were trying to create faculty workshops at Vanderbilt to go and help Vanderbilt faculty learn about generative AI. So what I've done here is I've actually taken it, I anonymized it, I had it turn it into different titles, different roles, different email addresses so I could have this discussion. And so it comes out with a transcript. Basically, we have the academic workshops at Prestige University. We've got Daniel Brown and Reema Mistry. It describes who they are. And basically, what they say is they proposed a plan to hold a series of training sessions focused on the educational impacts and applications of AI chatbots. And the introduction to AI chatbots and prompt engineering. Now, I changed the titles, I changed the names, I changed subjects and things to make this a little bit more interesting. But the key thing is, and this is changed transcript this is correct. We're scheduling a series of workshops to look at training Vanderbilt faculty. Well, actually, in this case, university XYZ and Prestige university? Now, there's a couple of different things in here we have what each person is suggesting or doing. Kenneth Ethan suggested that in addition to the Deans, the Associate Deans of Graduate Undergraduate Studies should also be informed to help spread the word. Alex Pearson suggested a modification to the description of the second session, which Aaron agreed to incorporate. Aaron planned to involve the IT department in the communication process and aim to get the first email announcement sent out by the end of the following day. A webpage would be created to list all the sessions and should be regularly updated. So we've got a summary of the key things that are happening in this meeting and in the discussion. So what can we do to aid human coordination? Well, one is just taking this, taking the notes and building a new summary of them, a new representation of them is a super useful way. And in fact, we can go in and we can summarize it from all kinds of different perspectives. We could go and summarize it from a particular role, like act as this particular Associate Dean and summarize it, or act as somebody who's focused in the IT Department and summarize it. And we could try to build different summaries that emphasize different aspects of the information to better communicate it to different roles. All kinds of interesting ways of using the LLM to help us support the human communication and coordination. Now I'm going to show you where we start really getting powerful is, I'm going to say, list any potential ambiguities in the plan that the team should address. Now the team as a whole has put together and had this discussion. Maybe some of the team was checked out during a zoom call. Maybe some of the team didn't hear something important, or maybe the team as a whole didn't think through all of the things that were being discussed and the details that were going to have to be known in order to make it concrete. So let's just go and ask. This human team is coordinating on a task. Where are ambiguities in their current plan? And so we get a number of really important things. One, the exact number of registrations for the July workshop is not provided in the transcript. This information is critical for planning and logistics. The specifics of the faculty AI communications John is drafting are not clear, such as what the communication will entail, who it will be sent to, and what its main goals are. Again, that's a really interesting one. There is no clear deadline for when John should provide his draft for review. That's a really important thing. Maybe we should address that. The communication plan for the training sessions is not fully detailed. Okay, we've got that. There's no mention of how participants will register for the sessions, which is important for tracking attendance and planning purposes. It's unclear who is responsible for updating the web page listing all the sessions or how often these updates will occur. So you can imagine, even at the end of a meeting session, like, let's just take 15 minutes, and before we adjourn, let's go look for ambiguities. And then you end up with all these interesting tasks that before you adjourn, you now go and quickly figure out, how do we address these things? Or maybe some of them you already know the answer to, but it gives you a second set of eyes, or a third set of eyes, or a tenth set of eyes, as many different sets of eyes from as many different perspectives as you want. Each individual participant could go and run this task and change their prompt, change their perspective to get different ambiguities out, and then prompt a discussion on what it is we need to go and follow up on before we leave this meeting. Now let's go on to follow up, right? Who should help address each of these ambiguities? Like, maybe we walk out of here and we'll figure them out after we leave, but who should do it right? How do we figure out that breakdown based on all these things? So we just ask who should follow up and it proposes a possible breakdown. So, you know the typical thing, right, we have all these things we need to do. Who's going to do what? Well, let's just start with ask the AI and let's start doing allocation based on what was discussed and responsibilities and roles that it perceives, and maybe then we go and adjust. But it's not a bad starting point to get things going, rather than the silence and the meaning of who's going to do what, right? Let's just say based on what's discussed. Okay, number of July registration. Sam Grey, who was directly asked about this, should provide the information to Daniel Brown. John Burke, who is preparing the draft, should clarify these specifics with Reema Mistry. Reema Mistry, who initially requested the update, should set a clear deadline for John Burke. So we're starting to get human coordination sorted out here. It doesn't have to be done this way, but at least we can start the conversation between the human beings of who's going to do what and by when and get that figured out. And then we have the second university notice. It's multiplexing and understanding not just who's involved, but who's involved at what university. So we have communication plan for the training sessions with Aaron Nash. Aaron Nash should propose a method and timeline for collecting and incorporating feedback in consultation with Sarah Freeman and Kenneth Ethan. All this great stuff and all we did was just go and say, hey, give me the breakdown. It's great for analyzing human communication, helping us to plan, be more effective in thinking through what we're doing now let's also think about this. What else could we do with this in terms of human communication and coordination? Well, if you're anything like me, you've been on a project where there were multiple teams. This is a classic problem in software engineering. You have multiple teams that are meeting and making decisions and late in the game you realize two teams made conflicting decisions. And so how do we help identify conflicts earlier? Well, let's just take the meeting notes. So I've got the meeting notes here that I've prepared for a second team and these meeting notes have a conflict, or one or more conflicts, potential conflicts. Maybe they don't end up being a conflict, but because of ambiguities and the way things have been done and discussed, there's actually some conflicts in here. So I say a second team working on logistics for the workshops just met. These are their meeting notes. Please point out any potential conflicts in decisions made by this team and the other team, and that actually should have been other teams. But I've got a meeting notes for one of the universities and it says the meeting notes from the second team, logistics team reveal several potential conflicts with decisions made by the first team, Aaron Nash's team. So we could go back up here and we could look, we can see Aaron Nash is at University XYZ here's, Aaron Nash. And now we've got some specific issues. So it's identified within which university and which people have particular pinch teams that potentially have got conflicts. So now we see venue size and layout. The logistics team suggests using the university's main auditorium for the sessions, which conflicts with the initial plan to conduct the sessions in a smaller setting, presumably in Conference Room B. So now we've got a conflict of some kind and we could go follow up on that. Now let's imagine for a second that the LLM made a mistake and let's just follow up on this. Let's assume that Conference Room B doesn't even exist. Let's just say it hallucinated, that what's the harm done in this? Probably zero, because at the very minimum, if we send this and we say hey, logistics team and Aaron Nash, hey, there's this potential conflict on venue size and layout. The logistics team said main auditorium and the second team or Aaron Nash's team said Conference Room B, and let's say Conference B doesn't exist. Well, Aaron Nash could say hey, we didn't say Conference Room B, we don't care, right? But the main auditorium sounds great. Or they might say the main auditorium sounds terrible, but at least it identified this important point of coordination and required both teams to come back together. So even if there is a hallucination there at that moment saying hey, there's a potential conflict, it requires both to look at it and say is that an issue or not? Now, if we just say, tell me what the other team said and we summarize what the other team did. Now maybe there's an issue if it hallucinates Conference Room B, but if we're starting to tell them here's what you said and you said and it conflicts, both teams are going to put a set of eyes on it and check it. And so it's forcing points of coordination when it gets interesting. So when you're working through things, you want to think ways of bringing people together and getting second sets of eyes. And this would be a great example if they completely miss on venue size and layout, that's a problem. IT requirements, logistics team's list of necessary equipment includes high-resolution projector, multiple wireless microphones, a good sound system, and several laptops. This contradicts with the initial team's It requirements, which were likely based on a smaller room setup. So it's saying, hey, look, if they set a smaller room and your IT requirements are like multiple wireless microphones, it's kind of noticing this mismatch, but there's not a direct discussion of what that means in the first meeting. But it's kind of recognizing smaller room likely means different It requirements. Session times, there is a scheduling conflict with the main auditorium for the second day of training, which means the training session's timing would need to be adjusted. This would conflict with the first team's plan as they have already drafted a schedule. So, lots of potential here. We just need to think about how do we engage the LLM in getting humans to talk and coordinate. And this is kind of a great example of something that's good because the goal is to get humans looking at the discussions, it's to get them to talk to each other more. So, how do you use this effectively? Number one, help use It as a tool to spur human communication, to spur different ideas. If we go and look at the beginning, we said, okay, here's a summary. Well, one way to use a summary that's maybe not the best. It might be good, it might work is if we could do a lot of work to try to get it to generate a really accurate summary and make sure that its summary referenced back to things that we could go and check in the original meeting notes. And that's one way to do it. Now another way to do it instead would be to instead generate the summary at the end of the meeting, take a couple of minutes, and have everybody read it or read it out loud and say is it accurate? And yes, then you go and use that summary or provide it or it gets everybody on the same page potentially like do something to help make sure that it's accurate. Or send it out to everybody at the end and say here's the summary. Does this capture everything accurately? Engage humans in the checking process because it'll also have them rethink everything that's in there and hopefully do a better job. Now we don't want to overwhelm. So we have to think about how to do this intentionally. But the key is we want people engaged and we want to use it as a tool to help them engage. List any potential ambiguities. This is a great one. Again, we're going to have it sort of say what could be ambiguous or what's being missed, that would be another great one. And then take the group as a whole and have them look at it. Use the time more productively by maybe even using this, having everybody do their work ahead of time. Give it all the documents, all the materials ahead of time. Let's start with here's all the documents for our meeting. Where are the ambiguities in our plan? Where are the ambiguities in what we discussed last time? Start it off at the beginning of the meeting and then help figure out who should do what or how. There's all kinds of different ways you could do this by phrasing who's doing what from a role perspective. You can also look at burdens and think of different ways of allocating. But it also helps get people thinking is that the right person to be doing that? Am I overburdened at least gets the conversations going? It also helps getting this aspect of who should be coordinating with who. So when we see number of July workshops and registrations now we also see Sam Grey, who is directly asked about this, should provide the information to Daniel Brown. We're getting more specific about who's going to coordinate and how. Very, very helpful. And then we can also do this across teams, wherever we have multiple notes like things. We want to make sure things don't fall through the crack because people aren't talking. So let's get bringing together multiple meeting notes. If you take code interpreter, you can bring together meeting notes, PDFs, all kinds of documents from different teams. Explain which teams are producing what and let's start doing these analyses to try to catch mistakes that are being made. Conflicts, other issues, and coordination so that we can be better and more effective overall as human beings in accomplishing some problem together or solving some problem together. Hopefully, we don't accomplish problems, hopefully, we solve problems. So hopefully, we'll be better at solving problems in teams by using these tools effectively to help us.\n\nOne of the things that can drive me nuts is that I love solving problems, but a lot of times the manual work can be really tedious to actually go and implement the solution. So one of the things that's really exciting about code interpreter is we can help use automation to cut a lot of these tedious tasks out and allow people to focus more on problem solving. So I'm going to give you an example of this. But this is the C in the achieve. How do we cut tedious tasks? Through automation, freeing time for creative thought and problem solving. Now, I'm going to give you an example of this. And so what I'm going to do is I'm going to take a workshop that I ran at Vanderbilt. So this was a workshop for faculty and staff to talk about prompt engineering and ChatGBT. And so what did I do at the beginning of the workshop? Well, I had a registration form so you could go and you could sign up. You could provide your name, your email, your department, and some information about how you were currently using Generative AI or ChatGBT or prompt engineering or if you weren't at all. And sort of a key thing and I'll come back to in a minute was the department was just free text, put in whatever you want. And how you were using it was just free text. Give me anything you want. Now, this could have been a mistake and it could have ended up being a bunch of tedious and error prone work, but I'm going to show you why it ended up not being. So I started off by going and I upload here. This is the list of people that registered for my workshop on prompt engineering and ChatGBT. Describe the data in this file and it goes through and describes all of the data that came out of this. Now, this was just a simple Google form that was saved to an Excel sheet that I've now uploaded. So I've got the different columns that are available in this worksheet. So what can I do with it? Well, at the beginning I thought, well, who registered for my workshop? And unfortunately, I didn't actually think of doing this at the beginning, but I'll never do it, have a word of the workshop or meeting like this again where I don't do this because once I did it, I realized it's so helpful. But I thought after the fact, when I'm creating this video, I should have done this. And this is what I wish I had done at the beginning, which is I said, please create a bar chart showing total registrations by department. And it goes and it shows all the different people across campus who are registering which departments are most represented here. Biostatistics was the most represented department, so it seemed initially, and maybe that didn't change at the end. But one of the things I also noticed was it looked there was actually some duplication in this data. And the reason for that is I just let people fill in any department they wanted. And when I started looking down at this list of departments, I realized that some of them were being repeated. There were variations on the IT department's name, there were variations on the business school's name. And so I wanted to go and fix that. So I went in and I just tell code interpreter, it looks there's a lot of overlap between departments. Alternate spellings, can you list all the departments and then do some intelligent grouping of them? E.G Owen and Owen XYZ because some folks said Owen some folks said Owen School of Blah some people said Owen School focusing on this some people said DBMI on all lowercase, which is Department of Biomedical Informatics. Some put it in all uppercase, some people spelled it out and so I had this all over the place. Now, I could have gone through 100 entries of this manually and tried to create the list, tried to clean it all up, manually mapped and created all of this stuff. But why do that? This is the exact type of thing that we can use code interpreter to help us solve and so that's what I did. So I basically asked code interpreter to do this. It goes through and comes up with a plan, and then it comes back with the list of different departments cleaned up to some degree. Now, when I went and read this, I noticed, hey, there's still some overlap here. There's this OGSM and then OGSM Financial Market Research Center, and there's also VUIT with a space between VU and IT, and then VUIT with no space between them. And so I wanted to go and clean up a little more of that. So it's not necessarily going to be perfect every time, and that's okay because it's so much easier to just interact with it and help it refine what it's doing. And the problem solving of that gives me so much more joy than it would to sit there and manually mess with an Excel sheet through 100 different rows. So I just say, hey, look again at your grouping, critique your work, come up with a plan to fix any issues you see, and then execute that plan. So then it identifies, hey, there's Inconsistent Capitalization, Misspelling and Typos, Broad Grouping Names, some things like that. It comes with a plan and it goes and revises the list. And this time it still does a pretty good job but there's still some things left over. OGSM and OGSM's Financial Market Research Center. And I point out some of these things to it and it goes and helps fixes it, and I go through it a little bit more. And then what I do is I say, okay, now I want you to map all of the original departments in the registration to one of these sanitized departments. And notice I say manually, that's a little keyword that I'm telling it that I want it to do it GPT Four to do it and not to go and rely on Python to try to do some programmatic version of this. Because it's small enough list of departments that it can do it directly. So it creates the mapping here and it shows me basically how it maps all of the original department names that were in the form into actual department names and provides that listing. And then what I said is, I want you basically, to save your work, create a CSV file that has this mapping. You should have a column for original department and final department. And basically the idea is I want this sort of messy original value in the CSV file and then the final one. Now, this is to do two things for me. One is I'd like to save this so that I have this list and I can help myself in the future if I ever need to bring it back up and do this sanitization work again, I can have a starting point. But also I want to be able to look at it and see what it's decided for every department. So I downloaded it, I looked at it, and it did a good job, it mapped everything over. Now, I could have done this by hand 100%, it's a small enough amount of data. I could have gone and done all of this by hand, but why would I do that when I can automate it? So I said, take the original CSV file with registrations, go through each registration, and replace the department by looking up the final department that corresponds to the original department that has the same value in the file that you created. Now, this is interesting because this is a place where if I'd thought through my naming a little better when I was building that CSV file with the mapping, then I could have made this prompt a little more straightforward to word. But based on the way that I described things earlier, I ended up with having a prompt that wasn't as straightforward as it could have been. So think through how you word and structure and save things as you're working on it, because later, when you're having to describe instructions, you're going to be stuck with how you organized or described things prior. So it would have been a lot easier if I just in that new CSV file I had final department and department, because then I could have just said, go look up department in that mapping and replace it with final department. But I have this whole original department thing as well. So anyways, it goes through that, it automates the work. And now I have my updated registration list where it's gone, and cleaned up all the department names into this set of department names. That actually is what I want, which is it's not all these different misspellings and all these different issues. If you've ever created a form that had free text for some of these things, and then at the end really regretted it, this is an example. Or if you can think of all the places on the internet or data sources that you're dealing with that are free text unstructured in some way and you would like to extract structure, regularize them in some way or make them more sanitized. This is a way to do it, or even to turn them directly into data so that you can do some type of analysis. This is a great way to automate it, all those types of tasks, taking text, turning it into data, very manual, very labor intensive, you can help automate a lot of that. So I then asked it to tell me the mapping of departments to schools within Vanderbilt, because what I thought is, well, now that I've got this sanitized list, I'd really like to do this grouping by schools. And it told me it couldn't do that. And I could have gone forward with that and had some sort of interaccurate mapping, or I could have given it a mapping and have it do it. But I just said, hey, you know what, it's okay. I don't have to have that. Because I think there's a more interesting question to dive into, which is this unstructured text on how are people using it? So I know where my registrations are coming from. Now, I have sort of a cleaned up list of departments, but I'd really like to know something about how people are using it across campus. So you can imagine anytime you have survey data, anytime you have articles, maybe you just go and scrape a whole bunch of social media feeds. Maybe, you have emails from customers, maybe you have bug reports or problems you'd like to turn that into something that is manageable and usable, you'd like to extract structure out of it, a great task for this type of automation. So I tell it the registration head. How are you using ChatGPT, Bard, Bing, etc. As a question? Can you turn this into a list of types of usage and then group the responses underneath the types? So it creates types of usage for me, not using yet, that's a type of usage. And it then has all the different ways that people expressed not using yet, which was not at all yet, not yet, not currently, I'm not using it. I have not used these tools yet. Now, I could have manually gone and done that grouping. I could have also manually created the categories, but it was so much faster and easier to do it this way. It saved time that I could use, and that took that cognitive burden off me of all this tedious mappings and allowed me to do this exploration. It also grouped it into learning and exploration, preparing to use it for my class, learning, still learning, regularly, just beginning to try upskilling to support student requests. Writing in communication, research and training, coding and development, specific tools or applications, business and professional use and other specific use cases. Now, it's not perfect, the mapping is not perfect but it doesn't have to be perfect for me because I had zero before to go on. I couldn't have done anything with this, I couldn't have turned it into any concrete analysis. So then I said well, create three more possible groupings and a visualization for each grouping. So I have grouping by engagement level, not using, exploring and learning, academic use, professional use. Grouping by specific task, not using it has different things and I don't know if I agree with these but the whole point is it's doing it for me automatically. Grouping by usage complexity, now, if I had had to go through and generate all these four groupings by hand, even if I generated the first grouping by hand, I probably would have been done right there. That's the limit of the time and energy I would have had because that task would have taken so much manual labor to perform that I probably would have stopped right there. But now I can go and I can say let me look at this from a lot of different ways. Let's take that unstructured text and let's give it structure but using a lot of different sort of buckets or categorization approaches or whatever you want to call it. And so now I have multiple ways of looking at that unstructured text and now let's go do something for interesting. Now, we can start seeing how people are engaging with generative AI on campus. So we have professional use, not using, academic use and exploring and learning and we see a lot of people are actually using it professionally. That's how they describe their use and that's how their use gets bucketed. If we look at this other aspect, grouping by specific task, we see other and not using are really the biggest categories. So other writing and communication, research and teaching and coding and development are really much smaller than some of these other categories. So people are using it in innovative interesting ways or not at all. And then when we look at complexity, advanced use, which is not surprising on an academic campus, there's a lot of advanced users out there and there's a lot of people who aren't using it all who are showing up for the workshop. So we see both sides which also as somebody who's teaching the workshop if I had this in front of me beforehand thought to do this, then I would have had to think through how do I balance it. To make sure my advanced users get out something out of it and the people who are not using it all get something out of it. So then what I said is, let's combine all three of these into a 3D visualization. So now we have a 3D visualization that's across all of these different dimensions. And I didn't like it that it was actually overlapping here. So I thought, well, I'd like to just go through and have it create abbreviations for all the labels so I can get less overlap and I get a cleaner visualization. So I simply go and I say, can you abbreviate all of the labels so they don't overlap, so I make the chart hard to read. It goes and generates abbreviations for all this. Now note, I could have gone and manually abbreviated all of this. I could have then gone and updated all these mappings, all these abbreviations, I could have done all of this. But why do it when it can generate it for me? And so now I've got my new visualization and if I don't like this, I could go and generate ten others really quickly because I don't have to do the tedious sort of error prone work of figuring out how to do all of this reshaping. Now, it doesn't have to be perfect for me in this case. I'm not going to go and take this and turn it into some really important thing. I need an approximate grouping to help me build a mental model of the audience for my workshop and for this type of task it's phenomenal, right? If it's got some error, if it's not perfectly accurate, that's okay. As long as it's generally accurate, I'm going to be in good shape. I'll have a better idea of the audience that I'm dealing with. And remember, all I started with to do this was a list of registrations. I cleaned the list up into a list of departments that were sanitized. I then grouped it across different ways that people were using AI. I ran into some things that just didn't work and I didn't want to explore further. But by the end, because I wasn't stuck in this model of I have to manually go and map and do everything, it gave me more time to think about what did I want to know and see. And I could go and create all of these different categorizations of the data, all these different ways of looking at the audience and to help better understand them. And so that's the key thing. When you go and you start using the tool to automate, to get rid of these repetitive, tedious tasks, you free up time for people to think and do more effective work because they can think more about the work. They can think more about the problem solving. They can think more about the analyses that they would like to do, that they can't do today because they're spending so much time on these other tasks. So we should be looking for things that cut out these tedious tasks through automation, using tools like code interpreter, that's where we want to go and target this type of stuff.\n\nCode interpreter can help us provide a safety net so that we can catch mistakes by humans before they go out and cause a problem. So let me give you an example of what I mean by this. We want to try to catch things that would be hard to catch other ways or that would require some human review to catch. So we want to provide an extra safety net. We'll probably always have humans reviewing things, but in addition to the humans that are reviewing things, maybe we want to have an additional check to make sure nothing accidentally gets out or accidentally is done that causes some negative impact. And so this is a second check for a human. So I'm going to give you an example. I'm going to upload the Vanderbilt Travel and Business Expense policy as a PDF, and I'm going to upload an invoice. And you can imagine now we could also do this in the case where we could go and upload it before we purchased it would be an even better example. But let's imagine we've purchased this and we want to check for compliance on expenses. Make sure that something gets approved, doesn't get approved accidentally that shouldn't have been approved, or that even better would be that when we're submitting our travel expense report before we submit it, we're told, what are the things that might be wrong with it so we can go and fix them, so we don't have a lot of back and forth. All of these types of things that help prevent humans from making mistakes by catching them earlier or checking for things that would have been something that would have been missed by another human checking it. So it goes through and it reads the Vanderbilt Travel and Expense policy, summarizes it, and I go through with it to read and summarize all of the expense policies as we go through here. And then at the end of this, what it's basically done is it's read into the conversation all of the relevant details. So then I ask it to read the provided receipt and tell me if it complies with travel policy. Don't list what is on the receipt, just if it complies why or why not. Now, what's interesting is this actually isn't a travel receipt, which I didn't notice my prompt, but it smartly detects that this is a receipt and looks at the relevant policies. So based on the policy, it lists what it is, it extracts what this receipt is for, and it says here's an analysis of compliance with the relative sections. And it says business purpose. The receipt does not indicate a specific business purpose or approval from a supervisor. Without additional context or information, it's unclear whether this expense aligns with the university's business needs. And it turns out if I submitted this thing without the business purpose, it would likely be rejected as an expense and come back to me and I'd have to update my expense report to include that. So if you were going through and you were trying to produce something, you could have it provide feedback, a safety net for the human sooner, so that before they submit this receipt and have to wait a long time and then get told it doesn't comply, they could do it immediately. You could get a sooner safety check on the receipt and whether or not it complies and help them to fix the mistake. Here's another example where I've gone through and I've asked it to go and analyze a rental car receipt. And I'm basically saying analyze the receipt and let me know if it complies. And so it goes through and it reads through the receipt. A lot of different aspects of the receipt are read through. And then one of the interesting things is it then says, but other elements CDW, liability insurance, PAI may not comply. And if we go up here, we see collision damage waiver insurance. For domestic travel, the collision damage waiver should be declined as rental vehicles are fully insured through Vanderbilt's insurance portfolio. The receipt shows a charge for CDW which may not comply if this is domestic travel. So basically, what it's telling us is if you submit this receipt, like this you asked for the collision damage waiver and you shouldn't have done that because Vanderbilt already has insurance for that and they're not going to reimburse for it. Similarly, liability insurance, the policy does not specifically mention liability insurance. If this is domestic travel, the inclusion of liability insurance might not comply. Personal accidental insurance and personal effects coverage. These are personal coverages and may not be considered allowable expenses. And so it goes on to list the specific things that may not be complied and notice what we're doing. I didn't tell it here's explicitly what I want you to check for. I said, here's the Vanderbilt travel policy. Here is a receipt, go see if you can find any issues that would be a problem. And so you could do this in all kinds of different ways. Now you could use it to try to deny people all day long, but that's not a good use, that's not providing a safety net. The safety net is to give the traveler upfront feedback. So, for example, when they book the card, they could upload, here's what my contract is and what I selected on services. Is this going to comply, am I going to get reimbursed? That would be a great example of helping support and provide a safety net for the human. Or if they're getting ready to submit their expense report like we saw up here where it says there's no business purpose, it's not listed, help them provide a safety net so they don't submit the report and have to wait for that report to go and get reviewed by somebody else before being told that it's not going to comply and therefore they need to go and update the report in some way. So providing a safety net to humans to help them get feedback faster, to help them prevent making mistakes that have it caused problems. All of these things are great use cases now as long as they are not replacing other human beings. So you want them to support humans. So if you have somebody who's already checking expenses, well, maybe you have this as an automated system behind them. Or even better, have it as an automated system on the front end for the traveler, so that when they submit a listing of what they've booked before they've actually gone on the trip, that they can check if that's going to comply or not. Or they could even before they book it, go and check, is this going to comply or not. And provide all the details and try to get a ruling on whether or not that will probably comply. All of these types of use cases where you're providing that safety net for the human being but not replacing judgment of the human. You still want a human there who's going to decide yes or no, is this allowable or not? And maybe the human is going to say, well, under this condition we're going to allow it because it's an exceptional circumstance, something that the AI may not be able to reason as well about. So providing a safety net for humans is a great example of something that it can do well.\n\nThere seems to be a common perception that when we start engaging with AI and some type of conversation. When we start using ChatGPT or code interpreter, that somehow we're going to become less creative, that it's going to make us just let it do all the work. But I want you to see that, really, this is a tool to help inspire creativity in humans. And it's all about having humans start to ask questions that they're not not asking today. This is part of what we want to do. Is inspire people to really start asking questions about thinking about different ways to do things and using these tools to help them think of different ways to approach things, or to inspire new jumping off points and ideas. Because when you really engage with the tool in sort of a more sophisticated way, it's not about having it do all the work for you, it's about asking it the right question, getting it to generate output. And then using that as a jumping off point to other creative avenues of exploration that you never could have gone and explored before because you didn't have the time to go and jump off and do that. It's a lot like going into a room with a lot of interesting people with diverse perspectives and having them help you brainstorm. But imagine a room where you go in, and nobody's going to say anything unless you ask the right questions. And that's really one of the key things that you need to learn to do with this tool, is to ask the right questions. But when you do, then what you can do is you can really help inspire better problem solving and creativity. So I'm going to show you how to do this. Now, when you're thinking about something like, how would I do this? Or how would I do this? Whatever it is you're thinking about, take a moment and just go into ChatGPT and say, give me ten different ways of solving this problem, or ten different ways of thinking about this issue. Or ten different perspectives, or ten different, whatever it is, or three, or four whatever it is. But get more than one, because often we get into this path of just going down, I'm only going to think about what I know, and only my perspective is all that I'm going to look at. I've solved this problem in the same way before, that's the only way I'm going to consider solving it. Or this is my perspective on the issue, that's the only thing I'm going to look at. So, use it as a tool to help you understand different ways of solving problems, different perspectives, different audiences, all kinds of things. So now, I'm going to give you an example of this. So, in the faculty workshop that I had on Vanderbilt's campus, I had a set of slides that I had created for it. So I was going to be talking to a number of faculty from across the campus, a variety of different departments. So I started off by taking my slides and I uploaded them to Code Interpreter. And I just said, please read and summarize the key points on each slide. So, Code Interpreter goes through, reads all of my slides, starts summarizing them, I tell it to proceed through the rest of the slides, and it goes through and summarizes the slides. And I keep working through it until it finishes summarizing all of my slides, which I had over 116 slides. So, what do I do then? And how do I approach using this as a tool to help inspire my creativity, to help me get outside of my normal way of thinking about things, right? Well, I say, act as a skeptic of everything I say in this presentation, find flaws in my assumptions, assertions, and other key points, and then generate ten hard questions for me. Like, I'm the one who's so excited about all this stuff, right, and I'm generating my slides, I've captured these ideas in my slides. Well, turn around and give me the opposite perspective, give me the hard questions, look at what I'm saying in my slides. Now, what's amazing is that it can do this and it can do it well. So, assumption one, ChatGPT and similar tools will bring incredible increases in productivity, which is exactly what I essentially assert in my slides. And the question is, isn't it possible these tools might also introduce new challenges and inefficiencies, such as the need for additional oversight or the risks of misuse? And that's a great question, of course that's an issue with these tools. And so, then thinking about that helps me to frame, when I go in and give this presentation, I can give a better presentation because I've thought through that question and that issue. Or if I look down here, ChatGPT is surprisingly effective, it's self assessing content. And then the question is, given that ChatGPT is fundamentally a machine learning model, without an understanding of content, how can it truly assess in a meaningful and reliable way? That is an interesting question, how do we know it's going to be reliable in its self-assessment? And if you're going to rely on that, how can you trust it? It's a great question. So this basically allowed me to then go and rethink my presentation, and what am I missing? What are other points or perspectives that I need to be thinking about? Now, I could have stopped there and just said, hey, give me the questions. And that's always a great way of going about things. But another way of looking at it is to say, okay, now I've got the questions, go ahead, and also generate three different possible ways of addressing each of these questions. So, I can have it look at both sides of the question. I can have it be the one that's going to question all of the assumptions that's going to ask the hard questions. And then I can have it go and try to answer its own questions and come up with perspectives. And so, if we look at question one, isn't it possible that these tools might also introduce new challenges and inefficiencies, such as the need for additional oversight or the risk of misuse? It says, absolutely, like any technology, AI tools can introduce new challenges and risks. However, the key is to develop a robust governance and oversight mechanism to manage these risks effectively, I think that's true. While there may be new challenges, the potential benefits in terms of increased productivity and efficiency can outweigh these. It's about managing the risks and harnessing the potential, I think that's another great way of looking at it. Now, I could have gone back and forth on these issues many different times. But the key is, the next time you go and give a presentation, you don't have to just give it blind and not have thought through what are the assumptions you're making that may be incorrect. Or what are the points that you're making that people may not be agree to, you can start looking at it from different perspectives. Now, I gave it the perspective and the persona of a skeptic, but you could give it all kinds of different perspectives. Act as somebody who's very concerned about ethics, or act as somebody who's concerned about cybersecurity, and you could go and target the audience. I could have gone and looked at the different departments that we're going to be attending, and I could said, act as a professor in biostatistics. Now, be a skeptic of everything I say, and have a more pointed set of questions that are tailored to the background in that domain. But you see what's happening here, it's inspiring me to think deeper about my presentation and the topics I'm going to cover. It's also inspiring me and helping me to think through different perspectives that may not be my own. And I could even target the perspective to different departments, or different feelings about AI, and so, that's really effective. And then it's also helping me think through different ideas and ways of responding to those questions, different perspectives. And these may be exactly what I've got, or I may not agree with them, and I may throw them away, but at least it got me thinking and inspired to think. And then I went through this process and it generated all these different responses to the potential questions. Then I thought, well, let's go and try to visualize something in this presentation. I said visualize the ways that I could address these questions, which it kind of pointed out that wasn't a very good way of doing things. And it explained to me why I would need more data, but it didn't really have it. And that then triggered up a way of saying, well, just try something else, even if it's more textual, give me some visualization of my presentation to help me think about what's in there. And then it came up with different themes and went and then visualized the different themes within my presentation, which was really interesting, because I hadn't really thought about, I had 116 slides. I'd never really thought about what are the themes in my presentation, am I missing important themes? Are there other things I want to touch on? And so, this had a lot of different sort of key ideas, and it really did a good job of sort of capturing important information for my presentation, visualizing it and helping me think about it. Which also then kind of I started to think about, well, maybe there's some areas that I'm not really effectively covering in this that I should go back and cover. Now, I thought, well, at the beginning of the workshop, I wish I had done something. At the very beginning of the workshop when I was trying to plan it, I thought, okay, well, how am I going to collect registrations, and then how am I going to send out emails afterwards? Or how am I going to send out emails to everybody with the link, so that people can join online for the presentation? And I should have, and now I will never or not do this again, is I should have gone and asked Code Interpreter. So I said, the slides are for a workshop, I'm hosting for faculty, I don't want to spend any money, but I need to have a mechanism for managing registrations and sending out email notifications with the Zoom link for the workshop. Give me three different approaches for this process and reference specific tools that I could use. So then it goes and says, okay, I could use Google Forms and Google Sheets, Eventbrite, the Free Tier, or Microsoft Forms & Microsoft Power Automate. And I could have gone and had it generate ten additional ideas for me, and keep thinking through. Now, what's interesting is at, the time I had used Google Forms & Google Sheets, but if I'd run this I might have gone and explored other ideas. I just was familiar with doing it through Google Forms & Google Sheets, and so, I was used to solving the problem that way, but now I have other ideas about how I could solve it. And so, I would go back next time and think through them, or get Code Interpreter to help know try to slice and dice this. Now, one of the things that I thought about at the end was, how do I engage the faculty? We've had this workshop, these people are interested, how do I keep them interested? How do I send them follow up materials potentially that will show them interesting things? And so, I uploaded the registration list as an Excel sheet into Code Interpreter, and I basically said, these are the people that registered for my workshop. Don't list any names of people, just look at their departments and ways they are using generative AI. And then give me some ideas for topics, questions, or other things they will care about related to my slides. So let me try to think of some follow on content that might be relevant, and then it comes up by department, different things that they might be interested in. So example, Biostatistics and Science utilizing ChatGPT for statistical analysis and data interpretation, integrating AI into bioinformatics workflows, questions. How can generative AI models enhance the accuracy of biological data analysis? Now, that's interesting, people are always talking about them not being accurate, and this is a question of how can it actually enhance accuracy. And it goes through lots of different departments or for other groupings, like for attendees not using generative AI, for cross-departmental topics. Here's some topics potentially to explore introduction to generative AI models and their potential applications, step-by-step guidance on implementing and utilizing ChatGPT like let's help them get them going. So it's starting to create and get me thinking about, what are topics or questions that would be useful to different groups that I've just had this workshop with? Then I thought about, well, how could I use this to help me interact with them in another way? So I say, I'm going to create customized post workshop emails for every attendee. I want you to create a list of interesting ChatGPT prompts and ways of combining large language models with each discipline or department. Each department needs at least one very interesting and creative prompt targeting the department's discipline and one idea of how to apply large language models in the discipline. List all departments and the prompts, and ideas beneath them. And so, now, I get by department a list of prompts and a list of ideas for those departments, so I can see whatever I want to go. Like for example, in alumni relations the prompt is, outline a year long engagement strategy to reconnect with alumni, including events, communication, and collaboration opportunities. So it's generating its own prompt, which somebody in alumni relations could go and use to generate ideas for engaging with alumni, which is fascinating. Right now they could go and do this, and if they just saw my presentation, now they have a direct prompt that they could go. And if I emailed this to them, they might try it out, and it might help them engage some more with generative AI. And then the idea is, implement LLMs to automate personalized outreach and communication with alumni, fostering community building and engagement. That's an interesting idea that they could follow up on. How do we use this to get more personalized outreach? How do we effectively leverage it? So it's an interesting way of going and then generating ideas that I could follow up on. And so, I went through a lot of different departments for doing this. And then I went through and I did something interesting. I thought, well, one of the things I'm also going to have to do for all of this, is I'm going to have to generate the emails that go out to everybody at the end. So I said, generate three exciting post workshop email templates for myself. And so, it goes and generates the post workshop email templates along with the place within the templates where these ideas that I had it generate could be inserted. And then the last thing I thought was, well, what else could we do with this? Like, what other ideas can we inspire? And I thought, well, let's look at interdisciplinary collaborations. We have a whole group of people from a variety of departments, across all the different schools and campus, and we know they're all interested in large language models. Maybe we can figure out some topics that they could potentially collaborate on. And so, I say come up with four interesting interdisciplinary collaborations that could be formed amongst the departments that involve large language models. Use your list of departments, ideas, and the current usage of large language models listed in the registrations to inspire you. And then we get different collaborations between schools to go and potentially look at so, engineering, health and wellness & health policy, design smart healthcare devices for remote monitoring and intervention. And then it says, the Engineering department can contribute skills in device design to IoT integration and data analytics. While the Health and Wellness & Health Policy department can offer insights into healthcare needs, policy considerations, and community engagement. Together, they can create smart devices. And then the application of LLMs is, leverage LLMs to analyze health data, enabling early intervention, personalized support, and policy alignment with evidence-based practices. Now, this is really high level, it's not super specific, but I had zero before. And if I wanted to take that idea and that possible collaboration, and follow up on it, I could, I could try to make it more specific. I could try to say, feed in the BIOS of all of the people that were in areas related to this, so I could take a list of attendees, I could filter it down to these departments. I could then go and upload a zip file with all their BIOS and this idea, and say, okay, make this idea more concrete. Who would contribute what? Then I might go and take a zip file of their papers, and say, here's the papers that they've done. Who might give me specific ideas of what they're working on and how that might make this overall collaboration come to fruition. But the whole thing is, once you get going and you realize, wait a minute, I can have it explore this for me, I can have it generate ten ideas for this. It suddenly becomes not just a tool about simple automation, but it can help you really rethink your approach to things, to come up with ideas that you couldn't come up with or feasibly implement before. To think about how to solve problems in different ways, to think about your audience, to think about their perspectives on issues. To explore the other side of your message and to really question, what are the issues or the assumptions that you're making that may not be wrong? But all these things are kind of key in that, they help you inspire better problem solving and creativity when you're using the large language model correctly. And we should be seeking these types of use cases, seeking these ways of using the tool.\n\nThe last type of use case I want to talk about, and the way that we should be using these tools, is to help enable great ideas to scale faster. So a lot of times, we can come up with the idea, but to go and implement it requires work that we just can't do today if we do it manually. So, I want to return to something I did before, because simultaneously I was really doing two things. I was getting inspired about ways that I could go and use code interpreter to basically come up with interesting engagement things for the attendees for my workshop from different departments. But I also thought about how would I realistically scale this up, let's say before Code Interpreter, I'd said, okay, I want to come up with interesting prompts and ideas for each department. For me to sit down and scale that up to all of the different departments that came to my workshop, probably wouldn't have been feasible in terms of the amount of time and effort it would have taken me to do that. And also, I might not have known enough about the departments to even know where to begin. So, when I went through, and I said, generate different prompts and ideas that could target each individual department, it was scaling up my idea. My idea was like, hey, let's get it to generate the prompts and the ideas targeting each department. And it can do it for me, it can scale it for me, it's my idea, but now, I'm going to have it run with my idea and scale my idea up by mapping it into each individual department. So it went through and mapped it into each individual department, all the prompts and ideas, all the way we have chemistry and biochemistry, and then it saved it all in a CSV file for me. Then I went through and I did some additional work that basically, I took the list of attendees and I added in the ideas and prompts targeting each attendee. So that they could go and see interesting things related to their domain and not see all of the other just random prompts across other departments. Although, that may have been interesting for people too, or maybe I needed to think through a way to use ChatGPT to figure out how I might incorporate both, so that they can see both aspects of it. And so, I went through, and I did that, and I ended up with a CSV file that I could take. And I could now scale this idea up, because I've got the CSV file, I've got all of the ideas built into the CSV, so that they're already mapped to the email addresses of the attendees. So, I could go and do a mail merge and automatically generate emails to be sent out to each attendee that included the ideas. And then I wanted to go and explore and scale up the idea of, well, how do I have these post attendee emails? And so, I had to go and generate possible email templates for me, it's scaling up my idea of email templates, but it's also scaling up by showing me lots of different ways to do it. But it's also providing the template that I'll potentially use for a mail merge. Now, I could go through and edit this once I know which mail merge tool I'm going to use. Or maybe, I use it to help me get ideas about how to do the mail merge, if I don't know how to do it. And then it gives me all the email templates. Funny enough, I pretty much absolutely do not like any of the ones. Because any sort of academic email that comes with an emoji at the beginning of the in subject line is probably not going to be paid attention to very well, or it's going to get filtered out via spam. So I should have probably followed up on that and had it rewrite these different templates, but I could have easily gone and done it. I also went and said, okay, generate possible interdisciplinary collaborations. So this was an idea I had, but to scale it up and really think through all the different departments and how to generate collaborations, that's hard to do, and I could say, do 100 of these if I want. I'm taking the idea that I've got and I'm having it scaled up. The idea is, we're going to go find potential interdisciplinary collaborations that involve LLMs and the participants. And now, we're going to come up with those ideas and seed it. And then we're going to give that overall template, which is the real creative important part, is that we asked that question, can we do this? And now, it's scaling it up and coming up with all the different potential collaborations. So when you're thinking about it, it's all about being creative and using it in a way that really amplifies our creativity, our problem solving, we're helping humans coordinate better. We're helping remove a lot of the tedious tasks, so that people can think more about the problems they're solving, or think of other analysis and other ideas that they can go and pursue to improve operational efficiency. To teach better, to be in a more effective communicator, to create something you just didn't have time to create before, or explore something you just didn't have time to create before. We want to free up time to do those types of explorations, to provide safety nets, right? We want people to feel comfortable exploring. And part of the beauty of these tools is they can help improve our systems, so that we have additional safety nets in place, so that people do make mistakes, we have a better chance of catching them. We're never going to just, my perspective is, we're always going to have humans in the loop and we want to have humans in the loop looking at things, but why not supplement them with additional supports and infrastructure? So, when we look at this overall approach, we want to help enable human creativity. We want to bring time and space for additional problem solving and thought. We want to provide safety nets, so that when people do explore or they try out new ideas. Or even when they're doing the ideas that they're already doing today, or the tasks they're already doing today, there's more ability to catch mistakes before they go out the door and cause a problem. And we want to really help people think of different ways of solving problems. And then when they come up with really interesting ideas or ways of solving problems, we want to help use these tools to scale up those solutions, and do things that we just can't do today. So, when you're approaching these tools, we're going to start probably in a lot of cases with lots of small simple problems. But don't think just as the small simple use case of, I'm going to turn this Excel into a visualization, think bigger. How do I learn something about my attendees? How do I think about their perspectives on this workshop? How do I automatically fix all these registrations? Or how do I extract data from this unstructured text in their registration systems, or whatever source it is? How do I identify potential mistakes in my email before it goes out to all of these registered attendees? We want to think of these more creative and inspiring uses for the tools, because long term, there's going to be huge value in those areas. When we solve problems more creatively, when we build systems that are safer for humans, and when we go and scale those solutions up. When we make people happier because they're doing less TDFs work and they're getting do more meaningful, thoughtful work, all of these things are going to build solutions that are lasting and meaningful to humans."
  },
  {
    "index": 4,
    "title": "4 Human and AI Process Planning",
    "content": "I'm going to give you a basic picture in your head, of what you're going to do with code interpreter. And I'm going to try to differentiate a little bit how you use it, from how you use Chat GPT. Because you can do a lot of things with both of them, but code interpreter wraps some additional things around Chat GPT, and those things that it wraps around. It's really important that you kind of understand what they're doing for you. So the basic framework that I want you to member, and that will help you when you're working with code interpreter is to think about extract, transform, AI. It could be analyze, it could be a lot of things and create. So basically, you can think of this as attack, extract, transform, analyze, create or extract, transform, AI create. And probably AI is the more accurate one, but we're going to go through what each of these pieces means. But I want to differentiate a little bit what's different and what's new. Now in the middle, this red part here that we're visualizing, this is really what Chat GPT could do originally. So you could always go and copy and paste text, into Chat GPT, and then have it do AI operations on it. It could analyze it, it could also do all kinds of other things. It could do transformations and analysis, and it could create new things in text, but not really, it couldn't go and create a PowerPoint file for you, for example. Now you might be able to have it create some text that you could copy and paste out, but it couldn't directly do it for you. It couldn't automate that process. At the same time, you couldn't just go and upload documents and have it extract data out of them, you had to go and cut and paste and do things to get the data out, to extract the data out and put it into Chat GPT. So the real difference, one of the big differences. Now there's many differences, but in your head, two of the key pieces to really take advantage of the power of code interpreter. Are to make sure that you're giving it and having it do extraction for you, from documents and other things and having it create products that you care about. So you don't want to be having it do things and then copy and pasting out. Now you can do that, but it's much more powerful when you have it actually and go and create things for you. Now, what does extraction look like, let's talk about that first. Extraction is going and getting information, or getting something that you need out of some document file or other thing that you upload. And it can use a variety of different formats, a variety of different types of media. You can do documents, you can do video, you can do audio, you can put in data sets like Excel. You can do imagery, and all of these things are places you may be pulling information out of, that you may be performing operations on them themselves. You may be trying to go and modify a video to make it short. You're going to extract some subset of it, or maybe you're going to take a series of images out of that video. You're going to save them and then have it create a little animated GIF for you. All kinds of things can be done. So, I went ahead and asked ChatGBT to think about, because remember what ChatGPT has is it's like your code intern, right? And it can program a little bit, but it's got this restricted laptop that it's got access to, that only has a subset of libraries. And so I asked it, given what's on your restricted environment, basically what are the Python libraries is the wording for this basically. What can you do with the tools at hand? And so it gives us examples of things that it could go and do, like text extraction, so it can go and extract text from a document metadata. So if you have documents that have all kinds of metadata in them, like when they were created, who are the authors were, other things. It might be able to go and do other more complex operations, can do things like frame extraction. Give it a video and have it pull out certain frames, or doing object dissection. So it's actually got access to different computer vision libraries. So it can do some fascinating things with like detecting faces. So you might want to go and try to see what's there. Now, some of the things that it's told us in this list here, I don't think are actually true at this moment, but hopefully they'll get fixed. I'm pretty sure it can't do speech to text yet, but I could be wrong. But it can do different operations on audio files, and it can do other things like you can give it an Excel file and extract what are the columns in here, what are other things in this Excel file? If you give it documents, sometimes it can go and find all the sections, all the individual pages. And then you can take images obviously, and go and look for things with computer vision inside of them. So this is just a small subset of probably what's possible. But I want you to start thinking about like, imagine it going and being able to take files and things and pull things out that you want to work, with and try to do something with. So here's some examples of this, this is an example of what we call structured data. That's an Excel file, and an Excel file is structured data, meaning I've already sort of explained or labeled what the parts are. So if you have like a have you have table in some table that's structured where it's clearly labeled what the different pieces are, that would be like a structured format. And this is an example where it's going in and extracting column names, from that structured data. It's telling me here's what's in that Excel file. Here's an example where I've given it a video, and I've told it to go and extract a frame from the video. So that's another type of thing that we can go and extract. Here is an example where I've given it a PDF, and I've asked it to extract each page of the PDF into a separate file. And so this is another type of extraction. And so a lot of times figuring out what we need to extract and how to specify it's going to be really important. Particularly when we start working with larger and larger pieces of data, or larger and larger sets of data. What we're going to have to do, is figure out how do I tell whole code interpreter to extract the things I need from it. In a way that will scale up and work, and that it can do something useful with.\n\nThe next step in Extract, Transform, AI Create is the transform piece of this. And when you're thinking about transform, this is all about manipulating the data to put it in some format that is more amenable to whatever we're trying to accomplish, with the AI and the creation later down the road, or more like what we want the final product to be. So let's look at what this is. Now, I'm going to give you a simple example like I've got this diagram drawn here where I'm showing extract, transform, analyze, create or AI create. What does that mean when I'm talking about this flow, what am I really talking about? Well, what I'm really, really talking about, one way to map it is to map it into the conversation. So think about the flow in your conversation with code interpreter. So when you're having the discussion, you're basically moving through this flow. You start off by giving it a document and asking it to extract some information or sometimes you don't, sometimes you just start by having it create something. But imagine that you're having it go and extract something and there's just a model to kind of think through the capabilities. So in this case, as I'm moving through the conversation, I'm basically moving through different phases of extract, transform, analyze, and create. Now, you can have much more complex flows that move back and forth, but it's kind of a helpful model to have in your head to just simplify this and think about taking data out from what you upload or provide, transforming it in some way, analyzing it and create it. Now there's much more complicated flows, but this simple one will take you a long, long way. So here's an example. I started off, I had this graph, and now I'm going to go and transform it. And I'm transforming it by basically taking what I had before and I'm turning it into something new. I'm modifying it and I'm moving that red dot from Extract down to transform to highlight it. And then I'm transforming it again in this image down here where it's completely changed. I've changed the title, it's been redrawn completely and now Transform is highlighted. And so there's basically a series of transformations and basically each time I'm giving it instructions on how to do the transformation. In this case, I said redo the graph to have the title extract, Transform, AI Create. That was basically specifying a transformation. So when you're having a conversation and going through and saying, here's the thing I want to do next, you're going to be walking through these basic steps and you kind of have them in your head. It helps you to kind of think through and structure what you can do. So let's take a look at some transformations. So earlier I took a PDF and I extracted it into individual pages. So I just pulled pages out of a PDF for a travel policy for vanderbilt. And now I'm going to transform that into a mapping of the policies to the pages that they appear on. So basically, I'm transforming individual pages as raw text into essentially a structured index where now I can go and look up, okay, well, here's what's on page one. Here's what's on page two. Now, the original PDF had everything, but I've extracted pages, and then I'm transforming the pages to have a subset of what matters to me. That's the transformation from raw text on the page into a sort of a description of the key topics that are on the page. Now, AI is really being used to do this. Probably. It may or may not be. It may just be reading section headers, but you can kind of think of it as a transformation. And then here's an example where I've taken a data set that I uploaded in Excel, and what I'm doing is I'm reshaping that data set. So I'm transforming it to give it a different format. So this is not the format. The columns were different. All of this data was there within it, but it wasn't in this format. The rows were actually these different prompts that we see up top, and the size and the values and these other things were associated with prompts being more of the rows. And all this information was associated with a particular prompt. Now I've reshaped it. So that the problem, is what everything is sort of associated with. And so I've sort of reshaped and moved all the data around and transformed it in a way through AI. So I'm taking this information in this Excel file, and now I'm transforming it and reshaping it to be more in the format that I want to work with. And sometimes the reason we're doing this is because if we do it step by step, and we build these things step by step, if you remember earlier, I told you that code interpreter is like your intern, right? And so the more that we can do to simplify each individual step as opposed to just giving it a long, huge, complicated task all at once, the better off we are. So if we simplify this into, okay, let's extract something, go do that, do a good job with it, come back, show it to me. Now I'm going to transform it a little bit, and I'm trying to get this data into a format that is going to be easier for it to work with and also easier for me to talk about. Sometimes part of the reason we're doing a transformation is because it's easier to explain what we want if the data or the text or the image is in a particular format. So if we've already done some work, sometimes it's easier to explain what the end goal is going to be. And then here's an example where I've done a transformation, and I've drawn a red box on top of this image. Now, it turns out I've actually probably done several things in here. I've actually detected faces and other things. But I've done a transformation to the image where I've transformed it from an image without the red box to one with the red box. Now, if I wanted to go back and talk about the image in the red box, I could do that where I could use that red box as some type of target in order to crop the image for example. So that I might be able to now go back and say, pull out the part of the image that's surrounded by a red box, and it might be able to go and do that. Whereas if before, if I said go and find the face and then extract it from the image, that might be harder. But having it step by step could potentially be easier to talk about. So there's different things that you can go and do and transformation is going to be one that's helpful to you both from the perspective of getting data or getting text or getting whatever it is in a format that's closer to your end product. But also so that when you talk to code interpreter, it makes it easier for you to explain what you're actually trying to accomplish.\n\nLet's talk about the AI or analyze piece of this whole workflow. How do we use this and what types of things should we think about using it for? I'm going to give you a number of examples. There's lots of different things you can do for it. It's going to build tools for you. Obviously, the AI is going to constantly be building tools to help you with these things but I want to specifically about what are examples of things that you can ask it to do to help you? Well, the real power comes out when you haven't worked with text, unstructured text in particular, when you're thinking about the analyses. It can go and write code to do all analyses and Python was structured data. But when you have unstructured data and you start thinking about really interesting powerful analysis. Here's one example, going and looking for ambiguities. Take a document or meeting notes or something and ask it to find ambiguity. That's a great example of something that can help support your human reasoning, they can help you find things will be difficult to do any other way. Another way is to explain things, give it documents, give it different types of files and haven't tried to explain them to you. Have you gain insight from it going and looking at a large volume of text trying to help you understand what's in there answer questions about it, explain it, provide things that's a great use case is taking large volumes of texts and trying to help explore it and understand it and support our reasoning on it. Another one is to ask questions, asking questions is a great thing that you can do is generating questions. Now, those could be questions that you're going to then answer for it so that it can gather additional information to do something better or it may be questions that you might want to consider yourself in giving a presentation or creating a document. In this example, I'm having to ask me questions about something in order to better understand what it should create for me, that's another great example of analyzing. Another one is to generate examples. In this example I'm asking it to generate crazy travel scenarios and I'm going to use this to create a training guide for a travel expense policy and so I'm having to generate all crazy travel scenarios and it generates this one about transcontinental travel on camels. But there's all other ones, Antarctic Research fiasco and so it's generating all of these examples. What's amazing is it can generate really great examples following patterns. In this case, it's looking at the actual travel of where you might have gone for this trip. It's then going in and generate a map or examples of where you might have gone, how you might have traversed the world. It's then going in and generate all different artifacts like knowing the currencies for the places you would have gone and then actually generating receipts for all of these travel in different currencies and converting between them and understanding what they're for and what would have been relevant and actually putting them into the correct languages for the place. This is another thing they can do really well, is it can generate great examples that follow the patterns in information related to where you're going. For example, if you're going to generate travel stories, would generate receipts in the native languages and the appropriate currencies to go along with your crazy travel story and generate the geographic flow of that and the map of it. Generating examples is another great type of thing that it can do. But we want to generate things that help us get more creative. I could have gone and written my own travel story, but the amount of time it would have taken me to go and create receipts in different languages and to try to draw the map and do everything, it would have taken me a lot of time but the key thing was the idea and the creativity to say let's do that, let's create that because it'll bring more richness to the overall story. Or the ability to stir in your own mind the ideas that things you should never go into class again or into a talk or into some type of presentation and not have questions to answer if there's material provided to you beforehand. But you can simply take the document or the presentation and provide it to code interpreter and have it analyze it and give you questions to ask or give you questions that then you can go and use to help better understand the material or have it try to explain and give you examples of it. Now, it may not get it exactly right, but then you'll be better prepared when you go in to ask good questions to interact with the other side or party. It's a really phenomenal tool for helping to support you through having it do different types of reasoning. Or maybe you have a proposal for some companies going to do something for you and you can take the nonsensitive parts of the proposal. You can put it into code interpreter and have it analyze it where the weak points, where the ambiguities in the proposal, where the things and schedule or other requirements that might be missing that we need to go and address. All of these types of analysis, these types of additional things to augment our reasoning about what's going on around us are really important.\n\nWhat can we create with Code Interpreter? Well, we can actually create a ton of different things. But whatever we create, I want you to think of it as a draft. Whatever we create is a draft that you are then responsible for. You are personally responsible for taking the draft and looking at it and taking ownership of it before anything happens with it. Now, I often talk about this as authorship. If people talk about it in authorship, sometimes they get a little bit nit-picky here about, it isn't really you authoring it if you're working with the AI tools. I have my own beliefs on this. But the fundamental important thing to really emphasize is you're creating drafts and you need to own them. Whatever content you create is yours and you need to take ownership of it and responsibility for it. Really important concept, but what are the all types of things that we can create? Well, I'm going to show you how to find out. I've uploaded a list of the libraries that Code Interpreter had available to it at the time that I created this video, it may have changed by the time you're watching this video, but hopefully we'll keep this up to date so that anybody that wants to go and try this can. I've also got a follow up reading here that you can go and try to replicate this entire conversation. I'm going to give it the list of libraries available to it, which will tell us what types of files that can create. Then I just ask it to give me examples of what it can create. It can create text files, image files, code. If you want to write programs, data files like Excel and CSV, audio files, video files. Now I haven't tested every one of these, but I've tested a lot of them. If you find one that doesn't work, see if you can come up with some other approach to make it work. But usually it can documents like a Word document or a PDF executable. I don't think it can create an EXE file, so I think that's actually wrong, but I think sh file, it could, compressed files, it can definitely create ZIP files, market files like a ZIP, like an HTML file or marked down. So you could go in, create text files, PDFs, Excel, Jupyter notebooks. This is a great way if you want to create Jupyter notebooks that you can run outside or in Google Colab, e-books. It's amazing you can do EPUB, Python code, JavaScript. Maybe you're not a coder, but you want to use it to try to create some interactive webpage, JPEGs, scalable vector graphics, low-tech if you're writing academic papers, HTML, CSS, GeoJSON. I don't know how you would use that, but probably if I had gone through and done the trip where I was doing the trip planning and using examples from this crazy trip, I probably could've had to generate GeoJSON for it. Astrological data. I don't know what the format of that is, but apparently it could do it. Graphs, it can definitely do graphs. QR codes, dates, and names. You can do obviously Excel, PowerPoint, that's a big one that I think is really useful. We can go and do YAML if you're doing the YAML, CSV, Excel, we talked about those lots of Python generate domain names. I hadn't thought about that one, come up with possible domain names. Lots of different formats that it can work with. Now what might we do with these different formats? Well, sometimes it's helpful to think about what can we create? What are the things that we can create in draft using this tool based on the domain. I'm going to take it and ask it just using a series of domains to give me examples of things that I could create for that domain. Education, interactive, educational e-books. I haven't fully tried to create a fully interactive one, but I did as a result of this, get it to create or try to create a EPUB format which seemed to work. Lesson plans, generating and coming up with ideas for lesson plans and how you might spend time. This is also great if you're going to host a workshop or some type of meeting and you want it to think about the topics that should be covered and how much time should be allocated for each one. Lots of interesting things there. Student performance dashboards using Excel or CSV, or maybe we just haven't visualized or we have it create the Excel format, and then we come in and we can do different visualizations. Now, granted, you should make sure that it adheres to whatever privacy laws are in place. All of these, of course, you have to deal with whatever privacy. Now student performance dashboards might not be something that you can do based on the laws in your area in the country related to. For example, in the United States, this might not be filed for compliant. Just so you know that you should check these things out, make sure they're appropriate legally as well. Online learning modules, you can definitely create all educational games and things. Educational videos haven't tested with one. I'm not sure if it worked, but it's still a great idea. Virtual labs, definitely something you can do really interesting virtual lab experiments with this, where it can even run code and have code do things and output things for students. They can go and interact and then have it generate run analyses to see if something worked or not encode. Infographics, presentations for class so maybe you're talking about a particular topic, building lessons plans you want presentations. Further reading lists. You give it a whole bunch of books and then say give me a list of the ones that might be relevant for this topic that could be interesting. Budget templates for finance investment portfolios in Excel, financial reports as PDF or Word, tax preparation guidelines. Again, these are in drafts, so at the end of the day you need to eyeball the content and read through it and make sure it's appropriate. Again, videos, I'm not sure how well that would work, but I'm curious to try that myself, since I just spent a vast amount of time creating these videos. Investor presentations and economic research papers, banking tutorials. Then we go into sales. We could do sales dashboards with Excel and then we keep track of everything in Excel. Then maybe we can go back and update, upload it directly into Code Interpreter to have it visualized different aspects for its product catalogs, sales training manuals, CRM template, sales presentations, lead generation reports, email marketing templates, product demonstration videos. Again, I don't know if the video is going to work out yet, but I bet it will soon. Competitor analysis charts, sales scripts that they could read. Marketing, we have marketing plans, social media calendars, ad campaign reports, content marketing guidelines, email newsletters, infographics. Then leadership, leadership development workbooks, team-building activities and guides, performance review templates, leadership webinars, motivational videos, not sure about that one. Org charts, leadership blogs, certainly succession planning documents, conflict resolution guides, vision and mission statements. Project management templates for management employee handbooks, inventory management spreadsheets, business plans, meeting agendas. Meeting agenda is fantastic one. Also doing analysis of what took place in the media, and if you've transcribed it, process flowcharts. I know it can do Gantt charts and all interesting project management visualizations, time management tools, Excel spreadsheets with time tracking, task prioritization and productivity analysis. Then you could upload it back into Code Interpreter to do all analysis with the data, compliance manuals and corporate presentations. Note, these are just a small number of examples I'm going to link in this is CSV file that I used to do this. What I would encourage you to do is to replicate what I've done. But for your domain and your interests and what you work with, give it the list of the CSV and then have it go through and list all the things that could create, and then having to have it go in, specialize it for your domain, similar to what I've done here. Using the domain of whatever you're interested in and then scope it. I also made it specifically eliminated a lot of things that I didn't want it to focus on. I just said, like here's a subset of things to go and look at, but you can broaden this out to what is interesting view. If you're a software developer in particular, and I write a lot of software, I've eliminated a lot of software things from this. But you can go and include those in if you want for your analysis for your domain.\n\nThere are two very distinct styles of working with code interpreter and talking to it. I want to really dive into these a little bit here because I think it's important to know how you can approach a problem either through step-by-step instructions that you give code interpreter, or by asking code interpreter to figure out the steps to tackle a problem. Now, let's think about what this means. Imagine that you have your intern and you have something that you want them to do. One way you can solve this problem is, you can say, hey, go do this and then do this, and then do this, and you make the steps really concrete, really specific, and you tell them exactly how to solve the problem in an order. What you're really looking for them to do is to do the work for each individual step. But you're going to build the overall plan. You're going to decide what comes first, what comes next, and you're going to get to choose what the individual steps are that the problem is broken down into. That is one way of solving problems. Another way of solving problems with code interpreter or with your intern is you tell your intern. Hey, I need to accomplish this. Here's my overall goal, go and build a step-by-step plan to accomplish that goal. There's a difference here. In one case, you are deciding the plan, you're choosing, here's what the plan is, the individual steps and you're making them very concrete. In the other example, you're asking your intern to go and generate the plan that then they are later going to apply. We can do both types of things with code interpreter. We can either go and step-by-step, break down the problem and explain to code interpreter how to solve the problem and what we want, or we can go and we can ask code interpreter to come up with a step-by-step plan, which then it can use and apply. We can talk about the plan and we can interact with with code interpreter and tell it how we want to change its plan, but we can have it generate the initial plan that will then use to apply and solve our problem. Now, I'm going to give you an example of what this looks like. If we take a look at this chat with code interpreter, I started off with very specific instructions. I said, draw a directed graph for me that has nodes for extract, transform, AI analyze and create, and arrows connecting it. This is one step, I'm telling it, right now do this. I'm not even giving it what's coming in the future, I'm just saying here's one step go and do it, and it goes and completes the step. Based on that completion, I then say, okay, here is the next step, you're going to highlight extract by changing its color. What I'm doing is I'm step-by-step going and explaining the code interpreter what I want. One of the things that I'm doing is I'm basically executing a plan that I've created in my head and I'm planning on the fly as well. Then I go in and create a more complex step. I say, now create a table that lists different types of extraction operations that code interpreter can perform. I describe what should be in the table and I tell it how to accomplish the task. But again, this is really one step at a time, one task at a time, I'm choosing the tasks and the ordering. Now, let's contrast that with a completely different way of solving a problem with code interpreter. Exact same problem, I'm going to try to draw these graphs with extract, transform, AI create. But I'm going to say, I need to create a series of graphics and corresponding texts that go along with the process of extract, transform, AI create. Now, notice I'm telling it my high level goal. Then I'm telling it step-by-step what I want. I want a graphic, probably a directed graph that shows the overall flow. I want to highlight one step in the process and then explain it. I want to have a table under the graph that explains the different type of data. I want to explain the operations related to it. Then I say, please create a step-by-step plan for you to create the graphics and tables for me. Now, I'm having it choose the overall plan upfront. I'm not going one item at a time and saying, if you remember, I said go do this and I looked at the result and then I said go do this. Now this time I'm saying, here is what I'm trying to accomplish. Now, the key to this is that I'm saying, please create a step-by-step plan for you to create the graphics and tables for me. You being code interpreter. It says, okay sure, here's a step-by-step plan for creating the graphics tables and accompanying text, design a directed graph, generate graph, highlight one step at a time. Table creation for different types of data, explanation of operations for each type of media type, visualize the table, review and refinement. In this case, it's choosing and creating the plan that it's going to execute. In the first case, I am imperatively saying here step-by-step, do this, do this, do this. I'm deciding the plan and I'm driving the process. In the second example that we're looking at right here, I'm saying, here's my overall goal, please create a step-by-step plan for you to create the graphics and tables for me. In the second case, I'm asking code interpreter to do the planning. The second case is AI planning, the first case is human planning. Now, you're going to use both of these when you use code interpreter. Well, you don't have to, but often you're going to be most effective when you know that you can do it either way. Sometimes you're going to want to use an AI planning approach, sometimes you're going to want to imperatively go step-by-step to solve a problem. But if you want to be really effective, you have to know that you can do it either way, and you have to be able to fluidly switch between the two depending on the problem that you're solving and the aspects of that problem.\n\nLet's dive deeper into AI planning because oftentimes this is going to be one of the most efficient ways of solving problems. The other really interesting thing about AI planning is sometimes it can come up with really unexpected good ideas that we can use and incorporate into our plan. Let's look at an example with AI planning. As I'm filming this course, one of the things I've been doing is I've been creating tools to help me go and extract the transcripts from the videos and then try to use them to create different types of content that I can then go and expand and edit and work with. I'm going to look at how I might use code interpreter to tackle this problem with AI planning. Here's the prompt that I'm going to use for code interpreter. I'm going to say this is a transcript from a video that I just recorded. I'm uploading a text file. I've used the whisper model to extract the text in a transcript of a video that I created. I'm going to say this is a transcript of a video that I just recorded. Can you create a step-by-step plan for taking the transcription and rewriting it as a blog post and to a series of social media posts. I'm explicitly stating here's what I want to get out of it. I wanted, my goal is to get a blog post in a series of social media posts. How do we turn this conversation, discussion into one that has clear paragraphs with topic sentences and supporting discussion, etc. One of the things I'm also doing in my plan, and this is a really important thing to know, is you really want to think about how you phrase the things that it needs to know when it's generating the plan, like the information, the problems that it should be aware of when it's formulating the plan. The more information about what's going to be tough or what are the important aspects of the problem that you want focused on the better a plan you're going to get. Just like anything else that we're doing with code interpreter we want to give it a lot of information, a lot of details about our goals, about the challenges, other things so we can build an appropriate plan. Then I say, I want the blog post to be 10-15 paragraphs. I'm providing additional constraints or information about what do I want to achieve with this plan? I want the social media posts should be 1-2 paragraphs with exciting ChatGPT prompts that could go with them. I'm asking it not only to do this, but I also want it to generate new information or ideas. Create a step-by-step plan for you to do this. Here I'm engaging with code interpreter. I've asked it now to go and build the plan and I've given it the initial document to look at. It goes through and it says, step 1, understanding the content. Step 2 identify key points and themes. Step 3, drafting the blog post, and you'll notice one of the other things it's doing, especially down in step 3, it's starting to break the problem down into subtasks. I'll start with a compelling introduction. I'll then write the main body of the post. I'll end the post with a conclusion that wraps up. The in step 4 drafting the social media posts and step 5 refine and polish. Now, one of the things that's really important just always to have in your mind with code interpreter is step-by-step is the most effective way. If you're doing the planning, you still want step-by-step very explicit, clear, concrete instructions and you're more likely to get a good result. Similarly, when the AI is building the plan, the more concrete and indirect those actions can translate into something that it can do, the better off you're going to be. When we have at planning, sometimes it's going to plan at a high level at the beginning. We want to make sure that we iterate on that plan till we get something that one tells us enough about what it's going to do, that we can be confident that its plan is going to succeed and we don't waste a lot of time while it tries to execute its plan. Two, we want to make sure that it's able to interpret its own plan and apply it concretely. One of the ways we can do this is we can think about plans as outlines of what are the tasks and what are going to happen. We can look at individual items in the outline and we can ask, are these concrete or these directly actionable? One way to think about this as we start off with an outline and we keep expanding or iterating on the outline, adding bullets and sub-bullets until we get a plan that's very actionable by code interpreter. What I'm going to do to help make this happen. In this case, it's plan was pretty good, but I'm going to just ask it to take some additional detail and then say first, make your plan more concrete by extending each bullet into 2-3 additional steps. Now notice I'm actually mixing inter imperative and not impaired. I'm basically doing some human direction here. I talked about how we're going to mix these things. It's given me the plan now. I'm using my human I'm knowledge to decide how to edit the plan and I'm planning to my head now I'm going to tell it to edit It's bland, complex. We could also have the AI plan, how to modify its own plan, but we don't have to go there right now. I'm going to tell it specific changes that I want. I want to make your plan more concrete by expanding each bullet into two to three additional steps. Each step should be concrete and actionable by either you or Python code that you write. Create the step-by-step actionable plan. Now, two things here one, I'm telling it, break your plan down further and we don't have to go way down the rabbit hole with this. I'm just saying two to three additional steps. Give it a little more detail underneath each action item and we want each action to be really concrete and actionable right here. That's another nice piece of this, is we want it to get us to things that we can do very concretely. Actions that it can take. We're doing one other thing. We're differentiating between what it can do, meaning code interpreter, the chat GPT or GPT for the model itself, versus things that can be done in Python code that it writes and then I say create the step-by-step actionable plan. I'm giving feedback on its plan. I'm telling it how to refine it. One two to three additional steps. Two I want it concrete and actionable. Three, I want it to think about in differentiate what it's going to do versus what Python's going to do. I want it to plan which one is the appropriate one to use for each task and then I'm going to tell it to go ahead. Here's what it does. It breaks it down. Now we notice understanding the content was a solo item. Originally it was just a paragraph. Now it's actually breaking it down into sub steps and it's more actionable. Load the transcript, identify the overall tone and context. Identify the participants that could be interesting. Identify key points and themes. Drafting the blog post and it's breaking these things down into additional steps. There are more actionable, they're less text. Now, it's not a perfect representation of what was there before, but it's breaking the plan down and it's giving us more actionable things and we can iterate and refine on this. But the key point is it's building its plan. Now, we get down to a point and it says, once this plan is executed, the result will be a blog post and a series of social media posts ready to publish. If you agree with this plan, I can start working on Step 1 right away so I say please proceed and you see what it's doing. It's now executing its plan and so it's starting to go through, it's looking at its plan and starting to execute the plan. This is a example of one way that you can tackle the problem. No, I didn't go all the way through this example. Because in most examples you're going to go back and forth. You're going to have a plan. It's going to do some things. You're going to realize that maybe the plan wasn't fully fleshed out and this happens if humans planning. If you're going in and doing some planning, the plan may not go as expected and you may stop and say. Well, we're going to change plan here a bit. We're going to refine based on what we're seeing happening. You should expect to do that with the AI planning to. Sometimes you might get lucky and it may do exactly the right thing from the beginning of the plan may be perfect, but many times it's not going to be and so as you see at producing things, you may need it stopped generation and say, hey, wait a minute, let's refine the plan this way or you may have it fully generate. You may look at it and you may say, we need to change one thing about the goals. I didn't tell you this about the goals and it may need to reformulate it's planned. Or we may take individual outputs that it's produced with its plan and we may refine them manually. But this is an example of going through and having it build the plan and then refine its own plan. Because what we want to do is we want to take these plans, think of them in its outlines of what's going to be done. We want to try to break them down into enough granularity that it's clear what's going to happen and how to accomplish all the individual tasks. Now sometimes our plans can grow too big and be too complex and too hard for code interpreter to follow. In those cases, we may have to go and take individual parts of the plan and save them and provide them separately to code interpreter and that's another reason why having this hierarchical breakdown where we have our top-level action items and then we have sub actions beneath them and we can go in store individual pieces of the plan and we can go and take those individual pieces and we can say, code interpreter, just go and do this part of the plan and then we can go back and get another piece of the plan. We can say now go do this part of the plan and we can help deal with some of these issues that we it's not going to remember everything, it's not going to be able to follow perfectly necessarily and so by doing this hierarchical breakdown, we can help it solve problems. We can help it generate the plans, but then we can also take those hierarchical pieces and provide it to it at different points in time.\n\nLet's look at some techniques that are helpful when we're working with AI planning and code interpreter. These techniques can help save you a bunch of time and headache when you're trying to figure out why it's just not doing what you want it to do or where the process is going off the rails. So I'm going to work on this example where I'm taking a transcript of one of the videos and I'm trying to turn it into a blog post and social media posts. Now, the reason why this is an interesting problem to work on is we want to create something that's longer and bigger. And we're going to try to get code interpreter to incrementally build all the different pieces we need for our blog post. If you tried to get code interpreter, write 10 to 15 paragraphs just all in one go, it's probably going to be kind of hard. And so part of what we're going to be doing is we're going to try to break the problem down, subdivide it into a series of individual steps, have code interpreter go and work on each individual step in its plan, and then bring all the pieces back together. And anytime you're working on bigger and bigger outputs that you're trying to get, you're inherently going to be limited by how much code interpreter or ChatGPT or whatever you want to working with, whatever tool you're working with, there's always going to be some limit to the amount of output it'll give you at once. So when you're working with problems, a lot of times you'll use AI planning to break the problem down into a series of steps. And then you'll execute each step individually to produce some piece of the final result that you want. And then you'll go and tie all those results back together into one cohesive file or thing that you can start editing as the human. So what I'm going to say is, I'm going to say this is the transcript from a video that I just recorded. Can you create a step-by-step process for taking the transcription and rewriting it as a blog post and a series of social media posts? We're only going to look at the blog post piece for this, but I went ahead and put it all in there. How do we turn this conversational discussion into one that has clear paragraphs with topic sentences and supporting discussion? I want the blog post to be 10 to 15 paragraphs. Now, this would be harder to get if we were just doing it. I could have done 30 paragraphs, I could have done 100 paragraphs. 10 to 15 takes long enough so I'm going to stop there. And then I describe some initial things and then I say create separate plans for blog posts and social media posts. So sometimes this is a helpful thing to notice if you have different pieces of the problem or if you're trying to solve for multiple goals at once. Have it do things and break them apart into separate plans that can be executed so you can refer to them individually or save them individually. So it goes through and it says, here are the step-by-step plans for turning your video transcript into a blog post in a series of social media posts. And we get the plan for the blog post, and we get the plan for the social media post. And notice we've basically split it and we've said create two separate plans. So although we are asked it to do planning, at the same time, we're saying build separate plans. And this is useful when we want to be able to work with them individually, which we're going to do in this case. Now, what I'm going to do is I'm going to refer to one of the individual plans and I'm going to show you a technique that's helpful. Which is we want to adapt the plan for the content that we're actually working with. So I know that it's got this generic plan and if we look at the plan, it's going to have very high-level sort of things that aren't specific to the content. And it may be able to go and read the content and the actual thing that it's going to work on and get a better plan. So what I'm going to ask it to do is I'm going to ask it to refine its plan based on the actual content that it's going to be working with in the plan. Because sometimes knowing what that content is can help you inform what gets done, what are the individual steps, what's important and what's not. And so based on that, what it does is it goes and reads the first 500 characters of the transcript, which, this is actually a flaw. And I'm not going to go into too much detail on this, but I should have had it go through the entire thing. I should have made sure it went through the entire set of content before trying to do this. And this was actually a mistake on my part. Always try to make sure it gets as much context as possible. Then it rewrites the plan. It says, here's what I'm going to do, and it defines a concrete plan that is based on the content. So before it didn't say anything about what was in the content and now it's saying, okay, my specific plan is I'm going to define the structure. And it's describing exactly what is going to be the structure of the blog post down to paragraphs. It's saying it's briefly introducing the topic, which is the differentiation between code interpreter and ChatGPT. It's going to explain what ChatGPT is, it's going to introduce code interpreter, and it's going to describe the additional features that code interpreter wraps around ChatGPT, provide examples or use cases, and then recap. And notice it's gotten the plan down the structure down to a series of paragraphs. This is much more actionable than the high-level plan. Then says I'm going to draft topic sentences for each paragraph. It's going to expand on the topic sentences. Write an introduction and conclusion, review and edit, add headers, subheaders. Now, notice what I'm going to do. I'm going to drop back into actually just telling it something to do. I'm not going to say plan on your plan. I'm just going to say remove step eight. I don't care about that. This is one of the nice things. When you have it generate the plan, you can also go and tell it toss out things that I don't care about. So I'm saying remove step eight it goes and refines its plan. But notice again we started with this very generic plan of the blog post plan. We had two plans. I'm now just telling it I want to just work with the blog post plan and I told it to take my content and refine its plan based on the actual content. Then I told it to toss out one of the steps. So I'm editing the plan to remove things before it executes it. And then I said save the plan to a text file so I can recall it later. This can be a useful thing one, because if you ever want to use this plan again, if its plan works really well, was really well designed, you don't want to have to be copying and paste it necessarily. You can just go and have it in a text file. So I ask it to do that and I now have access to it. Now I'm going to tell it execute the plan step by step and save the result of each step in a separate file. At the start of each step, read the result of the last step and reflect to make sure the next step aligns with the result of the prior step. Now there's a couple of things I'm doing here that I want to talk about because they can be really useful. One is I'm telling it to save the result of each step in a separate file. This can be really useful to you if you want the individual pieces, if you want to be able to download them as it's accomplishing the task and you don't want to wait till the very end. It can also be really useful if something happens. You don't want to lose all the work from the individual steps. It can be useful if you, as you'll see at the end, want to go and build something that's probably bigger than you can get in one output from ChatGPT or from code interpreter. This way you can have it build everything incrementally in different files and then put everything back together in one thing. The other thing that's really useful is if you're trying to figure out why is it going off the rails. You can just click on one of those files and you can look at it and say, it's completely missed the point here. And you can know where in the process where in its plan it sort of missed what you're trying to get at, where it's misunderstanding. Now the second piece of this that's important is I'm saying at the start of each step, read the result of the last step and reflect to make sure the step aligns with the result of the prior. So what I'm telling it is at the beginning of each step that you're taking, don't just go off and do it independently but think through what you did in the last step and make sure that you account for that. And if something happened in the last step that maybe requires you to adapt the plan slightly, go and account for that. So you can think about this as just being very cognizant of if there's something in the output of the last step that we need to know about, make sure and take into account that thing. And so you're telling it just look at the output, look at what happened in the last step, and use it in the next step. Now this also can be important if you want to make sure things are cohesive because it may go off and just do each step totally independently. And that may not always be what you want, particularly if you were writing a blog post and you want to make sure the sentences and topics are cohesive. So now it goes through and it starts working on the plan and you notice all these here links that I can download where it's basically executing the plan and giving me links to download the individual pieces. So that's really helpful to me. And it's going and executing the plan. It writes the introduction, it writes the first paragraph and then it stops. And it says please note this is a time-consuming process and involves all this other stuff, blah blah blah. But this is one thing that you were absolutely going to see for a longer plan, particularly one where you're trying to generate more content than can typically be done in one time if you entered it in a chat message. That is it's going to get to some limit and it's going to stop. And you see we got it to do a lot of steps but it didn't execute the entire plan. And so one of your jobs as the human interacting with the tool is always going to be to look at and identify when it's hitting a limit and stopping its output and then coaxing it to continue on. Now sometimes you're going to see that it's going to take something like the topic sentences and try to just generate one or two paragraphs or do some smaller version of it to get it to fit in its response and its limits that it has. And sometimes you have to tell it, no, go into each of those individual items and do this step by step separately. because what we really want to do is get all the pieces generated into individual files so we can always go put them back together. You can think of this as like it's writing a paper a paragraph at a time, but we have to output each paragraph to a separate file. And at the end we'll just tell it, combine all the files together so it doesn't get stuck. So I'm going to say, please proceed executing the plan for each topic sentence. So notice I'm being the conductor here. I'm telling it, okay, go back and continue the process. But I want you to run the process for each of the topic sentences that you wrote. And now it goes and starts executing the plan again, giving me the paragraphs in separate files that I could go and individually download if I wanted to, to see what's happening. I could also look at these incrementally and see do they look like paragraphs that I really want or has it gone off the rails and I could stop it at any point. This is always useful. And so it goes through writing all of the paragraphs. It gets the 11th paragraph again, it hits a limit on how much it can do at once. And so I have to tell it to go ahead and proceed. Proceed is a great word whenever you need it to keep going in its plan. It then keeps working. It keeps writing the individual paragraphs. It goes through editing some of them, and notice it stopped. It only did the introduction, first paragraph and second paragraph, and then it wanted to stop with its editing. Now I could have coaxed it back into doing the rest of the editing. It did the same thing for the headers. It only did the headers for the first three, the introduction, first, and second paragraph. I could have coaxed it to go and do headers for each paragraph, read and revise and edit each paragraph. I'm not doing that in this case, but I could have done that. And that's one of the things you're going to have to do as a conductor, is recognize when it skipped over things in the interest of trying to compress it into one response. And then at the end this was really important. I had to build all these individual pieces all in separate files. I could absolutely go and download them myself and manually combine all of them. But I'm just going to tell it, please combine the 12 paragraphs and conclusion into a single file and then it does that. And I can download that here. So we could also have gone through and said, zip up all of the files, create a zip file of all the individual files, and let me download them. That's another thing that you can do to get the output. But I want to just return and go back through this thing really quickly, some of the things that we did in this to make this successful. One, we built plans, but we also separated plans. We built separate plans. Now we did a lot in this conversation. If I hadn't separated the plan, the social media plan may be forgotten, lost, may not be easy to use. I've got a separate blog post plan, a separate social media plan. So I've got two separate plans to accomplish my overall goal. I then ask it to take one of its plans, the blog post plan, and I have it refine its plan based on the content that I'm actually going to work with. So I'm taking the high-level sort of generic plan and I'm telling it to refine it based on the content. This is a really helpful thing that you can do, particularly with writing. And the result of that is that we get a plan that's much more structured and specific to the content that I'm going to be working with. In this case, it won't always work out like this, but in this case part of what I got as the output of the plan is individual paragraphs that are going to be written. And this is really helpful because this is going to be very actionable for it. It then I went through and I edited the plan. I removed steps that I didn't want. No point in keeping anything in that plan that you don't absolutely need. It then refines its plan and then I told it to save its plan. Super important, super helpful. If you get a great plan, don't throw it away. Refine it and then save it somewhere so that if something happens, you can always start with that plan. You at least can pick up from there. I could have also done that for the generic blog post plan at the very beginning and then started from that. I could have always saved it and then started a conversation by saying, here's the plan. Now I could upload the content and say refine the plan based on the content and then start this process rather than having to regenerate the plan from scratch. Next, I tell It to execute the plan step by step. Again, this is important. We're going to say execute the plan step by step. We're telling it what to do and we always want to make it step by step. Typically and very importantly, save the result of each step in a separate file. This is going to save you so much headache many times. Sometimes you'll get it to go through a great complete plan and process, do everything perfectly. You don't have to worry about this. In my experience, this is a really useful thing and sort of a safety net for you. You want to get the output of each step and be able to access it if you need to. And then I tell it at the start of each step, look at what you did before, read the result of the last step, and reflect on it to think about what you're doing and how it aligns with what you did before. It then goes through and executes the plan. And then, very importantly, we're going to need to be the conductor. We're going to need to recognize when it's hitting limits and it's stopping execution of its plan. And we're going to need to tell it to proceed, or we're going to need to give it a little bit of extra instruction like proceed with the plan, but proceed with the plan on each individual topic sentence. Don't just do the first two. Go to each individual topic sentence and do it step by step, whatever it is. And then finally, typically, what we're going to do when we're trying to build something that's larger that can be built in a single output. We could go and copy and paste from these things, but instead what we're going to do is we're going to say at the end, take all the individual files of all the individual pieces that we want, or we may be able to pick and choose pieces at the end and put them together in our final product. The final thing that we're creating. So this is an example of AI planning all the way down to the end to create this blog post with all these sentences. And some different techniques that you can use to make sure the AI planning is effective, is doing the right thing as it goes, and can help you build larger things than can be built typically. If you're not sort of saving incrementally and building individual pieces that then are stitched back together into the hole.\n\nWhat can be really helpful is to save either plans that you create or in particular, when you have AI planning done and you get some great plan out of code interpreter, it can be really helpful to save that as a separate file so that you can reuse it down the road. Now, I'm want to show you an example of this, but the key thing is you want to be saving these plans, these intermediate products, because they're useful for picking up where you left off or starting a new conversation with that same process in mind. So you could go and try to recreate that plan from scratch, but it's probably going to be kind of hard to do. But let's imagine you got some great plan out of the tool or you took the time to write a great plan, you want to have it and you want to be able to reuse it. Now, as a warning, of course, you're never going to get exactly the same output, probably. You may have variations in output, but a lot of time you can get more consistency if you start with the same plan or you pick up from some point you left off, some intermediate products plus a plan at some point in time, and you use those. So how would you take a plan that you've saved, and use it to kickstart a new process? Well, let's go back to this example that I gave with turning my videos into blog posts. So I got a plan that was pretty good as a starting point. It wasn't perfect, and I'm want to pick up on that plan and I'm want to refine it and work with it. So the first thing I do is I pick up with restating the goals, because this is really important. And I restate the goals that were explained in the original conversation before I created the plan. So I explained it's a transcript from a video I recorded that I'm trying to get a plan for creating a blog post, and then I want to make sure we turn the conversational discussion into paragraphs with topic discussions. And I want the blog post to be ten to 15 paragraphs. Now we need this information. Now, we might not always need it, sometimes it may be showing up in the plan somewhere, but in this case I felt like it was important to include it. And then here's what I do, I say this is the plan that you previously created. So I'm basically providing its prior plan back to it. And I take the blog post plan and I just copy and paste it in to start the chat. So this is all part of the very first prompt. And I'm basically seeding this conversation with a prompt that will, hopefully, help it remember the plan that it had before and use it as the starting point. And so it goes through and basically reiterates what's in the plan, which is helpful, but then I explain to it how I want to tweak the plan. And this can be great if you've used it before and then you realize, you know what, there's something I wish I could do differently. Will you just take the plan, put it back into a prompt and then start working with code interpreter to have it modify the plan. So I tell it, last time this plan didn't completely work because I want the blog post to be instructional. I really want the post to emphasize concrete skills with accompanying examples, how could you improve or fix this plan based on that? And so I'm going back to it and asking it to think about how to iterate or improve on its own output. And so it goes and updates the plan, review the transcript, identify key skills and examples, define the structure, draft topic sentences, expand topic sentences, and this is fairly close to what was done before. But notice that there's some additional things here, instead of Step 3 being draft topic sentences, which came right after define the structure, so it basically was reviewing, defining the structure and drafting topic sentences before, now what it's going to do is review the transcript, identify key skills and examples, then define the structure, and then draft topic sentences. So it's basically gone and it's rewritten its plan to incorporate this issue that I brought up. And now, notice I didn't tell it how to fix the plan, I told it what the problem was with the plan, why it didn't work. I'm getting feedback to do its own planning. Now, I could have manually told it, remove that step, add this step, of course I could have done that, but in this case I wanted it to think through how to do this. Now, I then say, read the entire transcript, I uploaded 2000 characters at a time, summarize it and then update the plan based on what is in the transcript. So again, what I'm want to do is I'm want to take the plan and now I'm want to use my content to refine the plan and make it more targeted towards what I'm about to actually operate on. So it goes through, reads the transcript, and basically produces the new modified understanding, basically the summary of what's in the transcript, it does a good job of that, and then I tell it create a concrete actionable plan around this outline for turning into a blog post. Each step should revolve around writing one of these sections. And so, it then goes through and rewrites the plans, and it's very specific to the content. Now describing exactly what the content is going to be, and then basically I take it and I realize it's pretty concrete but it's not quite concrete enough. From my perspective, it's still a little bit too high-level, and so I tell it to write a separate plan, write a separate step by step sub plan that explains how you're going to write each of these sections and save them to a separate file. Provide the key topics that will be covered in each section, and you will make sure the section aligns with what came before. Discuss the examples that will be used in the section, include ,in your plan, rereading the original transcript in 2000 character chunks to find relevant information to include. Show the subplan for each section. So there's a bunch of things that I'm doing here that I want to break down. I've pulled in the original plan, I've asked it to modify it, I've now taken it and refined the plan using the actual content that I'm want to work on, and now I'm having it build out the step by step sub plan where it's going to go through. And for each, basically one of these paragraphs, it's going to create a plan for writing that paragraph, saving it to a file, it's going to look at what topics were in the prior paragraph, it's also going to look at the information that is in the sort of corresponding part of the transcript, and then it's going to provide and discuss the examples. So I'm basically trying to give it a lot of different individual steps of things to bring in. Now at this point, I'm really manually refining this plan and telling it exactly what I want injected into it, and then we get this much more refined concrete plan. It's going to reread the first 2000 characters of the transcript, it's going to draft a catchy opening sentence, it's going to write 2-3 sentences providing overview of the topic, it's going to conclude with a sentence that clearly states, it's going to save this in a separate introduction, and so it's basically doing through and describing step by step what it's going to do. Now, it could be that we've lost some information, but I think what we've got is a pretty good thing. If we look at Step 5, for example, detail code interpreters capabilities, and we go down here, we're going to reread the transcript, discuss the Python libraries and what they enable to perform, and we're going to save this as capabilities. And this is a fairly good description of what's there, but also we're fusing it with the new information that we're going to be reading in from the transcript. So, this is an example. The key point here is that if you have a plan and you've saved it, you can kickstart a new conversation by basically going and providing your original goals, providing the plan that either you created or AI created. And then you can go and sort of use that as a starting point. And you can either try to execute it as is and see if you can get a similar result to before, or you can go and use it as something that you can refine, as we did in this case, and try to have it fix problems or issues you had in a prior iteration of it and see if you can improve. So if you can get to a point that you think is good, you can save that. And then if things go awry beneath it, you can try to go back, start from there again, and then improve the outcome.\n\nA lot of times the AI is going to need our help when it's building its plan. Now one way we could do that is we can just say go and build a plan and then we can wait until the end and we can iteratively try to figure out where it needs additional help or information to fill in its plan. But sometimes what's a helpful approach is to use the flipped interaction pattern. This is basically a pattern where we ask it to ask us questions so that it can generate a plan. The idea behind this is it may have specific topics that it thinks should be addressed in order to effectively build a plan, and if it goes ahead and from the beginning, assesses questions, it can help us produce a plan. Let me show you what this looks like. Here's what I've done. I've uploaded a article that I wrote. This as an academic article and I tell it task, I would like to write a blog post based on this paper. Then I say, read the document and asked me questions until you have enough information to build a step-by-step plan to accomplish this task. Note what I'm doing. I'm flipping the script and basically telling it go and ask me questions in order to accomplish this task. Basically in order to build a plan to accomplish this task. I'm flipping the interaction and having it go and asked me the question so we can figure out what information it needs. Let's see what happens. It goes through, it summarizes the paper, and then it has a bunch of questions. This was a little bit overwhelming. I could have gone and answered each question right here individually and one prompts at one. Here's what I want two, well, here's what I want. But instead what I'm going to do is I'm just going to tell it to ask me the questions one by one. Then it goes through and it says, let's take this step-by-step. What is your target audience for the blog post? That's a really helpful question. If it had assumed that I was going for an academic audience from the beginning, then it would have written something that was targeting the wrong audience. I say general public. Great, keeping the content accessible to the general public will be a priority. What is the main takeaway that you want to convey to your readers? I say I want to emphasize that just generating a single-cutting solution is not effectively leveraging ChatGPT's capabilities that future is in prompting for hundreds of solutions and automatically ranking them based on code quality or marketing message quality or anything else. This is one of the futures of all these tools. Get it to generate a lot of solutions where you automatically rank them. Then it asks some questions like what specific sections of the paper would you like to focus on? This is something that I think is a great pattern to use whenever you're asked a bunch of questions, it just let it choose for you. Just say you choose what will be best and give it how you want it to choose to support the emphasis. This is a pattern is you choose, is a pattern you choose in order to accomplish these things. Then it goes through. It asked me some other questions about how long I want it to be. It has a number of other questions and then it goes and builds out its plan for the blog post and the structure of that blog post. This is a super effective way of rather than going and just get in to generate a plan and then coming back to you with a lot of questions, were a lot of questions at the end. It sometimes will just generate something that is 100% what you want. Sometimes it's going to generate something that is not at all what you want based on assumptions that you wouldn't have made. Sometimes you'll get it to start generating a plan, then it'll tell you all the questions at the end. This is a way to trigger it just right from the get-go, go into to generate questions that would be helpful. Often the questions will be very relevant to the problem that you're asking it to create a plan for. If you're asking me to write a blog post, it's going to start asking you questions about link and the audience, which are relevant questions. If you're asking it questions for something, or if you're asking it to do some other task, it's going to find relevant questions. When you're planning, often a really effective way to start is by using the flipped interaction pattern to get it to ask you questions in order to go and begin producing the plan"
  },
  {
    "index": 5,
    "title": "5 Error Handling for Large Documents & Outputs",
    "content": "It's inevitable that when you're working with code interpreter, it's not always going to be able to accomplish the task that you're asking it to accomplish the way that it planned to do it. For example, it might write some software to try to extract text from a PDF, and the libraries that chooses to do that task just don't happen to work with the PDF that you've got because your PDF either isn't OCR already, it doesn't have text, it's got images, it's got something complex in it, and it needs to try other ways of accomplishing the task. You're going to see this all the time where it tries to do things one way that it planned, but it doesn't work out and so you need a nudge it along. You can do this, anytime it runs into some problem, don't just give up necessarily try to figure out a way to overcome the problem by using the alternate methods pattern. The idea behind this is that you ask code interpreter to use an alternate method or to try alternate methods in order to solve some problem. Let me give you an example of this. This was example where I was trying to extract some text from a PDF so that it can help me do some work with the knowledge inside of that PDF. When it went to extract it it says, it appears that the text extraction from the PDF file using the current method was unsuccessful, possibly due to the specific structure or coding of the PDF. It's telling me there's a problem. Now I could just give up here and say, hey I can't do anything with this PDF, but you always want to try alternate methods. What I'm going to do right here is I'm going to basically tell it, please try other methods to extract text from the PDF. Then what happens is it goes through and it says, okay, here's alternate methods for doing this. It's basically looking at a receipt I had for a purchase for Bolt AI, this software program, and it goes and it says, okay, let's try using PDF polymer which is an alternate way of doing this. All I had to do was go and say, please try other methods. You can do this other ways. You can also say please, can you try an alternate method to figure out what is in the category. This is an example of where I gave it a number of files and I told it to read and summarize them and then try to come up with categorizations of those files. Now the problem was the first time it looked at them, some of the PDFs it couldn't figure out how to read them. It had to figure out, well, how do we go and fix this. I just tell it, try alternate methods to figure out what is in the other category. I'm telling you go and try again, figure out alternate methods. Then I say, look at the filenames. Basically I give it a hint as to how it might do this. Not only I saying that you can try alternate methods of getting the PDF text out. But I'm also giving it hints of other ways that it might go and do this, like just look at the file names and try to guess what's inside them based on the filenames. Then I say keep trying and do your best. The idea behind this pattern is, you don't want to let it give up. You want to tell it to go and try alternate methods, and if you have some ideas of what alternate methods might be, you want to go and give them as examples to it so it can go and try them. In this case, it then allows it to go and figure out based on filename and in some cases, what these files are supposed to be or it might go and try to switch up the libraries, how it's writing those tools that it's using to accomplish job. Don't let it just give up always, say try alternate methods. If you have ideas on what methods to try, then put them in there, say the equivalent, try guessing based on the file name.\n\nYou're going to run into the problem sometimes that code interpreter tries to analyze text by writing Python code to do the analysis. And whenever this happens, it's completely missing the power of GPT-4. Whenever you're going to analyze text, you're tryna reason about what is inside of text. You really want GPT-4 doing that work and not Python. And I'm going to show you a pattern to help you overcome this challenge. Basically the pattern is, when you have a text where you want GPT-4 to do it by looking at the text itself. You're going to say do it manually, you're going to tell it to do it manually, or you can tell it to do it without Python. But it's essentially the manual pattern. So, this indicates to GPT-4 that it shouldn't do it with Python. This is really important. It shouldn't write another tool to do it. So I'm going to show you an example of what an error looks like when it starts doing this. Kind of give you some clues that you can look for that it's making a mistake. So, here is an example where I've uploaded a transcript for one of these videos and I'm having it go and analyze it to look for key themes and topics. So it says, now that we have an understanding of the content, let's move to step two, identifying key points and themes. Given the nature of the task, it requires human understanding and interpretation and can't be fully automated. However, I can use simple text analysis to help identify frequently occurring words or phrases. This is exactly what we do not want it to do, is try to do simple text analysis. We want the powerful text analysis that's in GPT-4, not some Python code that it's going to write. And what we see is it starts giving us errors. Whenever you see these types of errors, these should clue you in that it's trying to do the wrong thing. So in this case it says, I apologize for the error. It seems I tended to use the natural language toolkit. That's something in Python that you would use in Python programs, it's not GPT-4. Given this constraint, let's change our strategy a bit. I'll use simple Python code to manually tokenize the transcript and identify frequently occurring words. So it's telling us right here, I'm using Python to try to read the text and do something with it which is not what we want. And then what we see is a really sort of poor analysis of the text. So it says, there was going was mentioned, go, document, travel, policy, us, all of these things, all of these words that are really unhelpful in analyzing the transcript. Now let's see what the difference is when we use this manual pattern. So, I give it the same transcript, but this time I say manually identify key points and themes in this transcript and that clues in GPT-4 that it itself is supposed to analyze it. It's not supposed to write Python code. Now, another way you can say this is you can say do it without Python, that's another one. Or sometimes you need to combine both, manually identify key points and themes in this transcript without using Python. And Python is the programming language it uses to write tools. So if you put those together, you're trying to signal to it, don't write Python code for this task, do it yourself. And it says certainly. And it does write some Python code, but not to do the text analysis it does it just to read the transcript into memory or into the conversation. And this is the difference. You can see the difference. Key points and themes. Introduction to the task, demonstration of ChatGPT and code interpreter, capabilities and benefits, real-world applications, reflection on the advanced technology, emphasis on accessibility. And it talks about all the points related to that. It's summarized it, it's read the transcript, it's dissected it into an interesting sort of key points and themes. Compare that to what we get when it tries to do it with Python, where we get this really primitive analysis of it that's not at all the same thing. The difference is, sometimes it will do the right thing, but when it doesn't, we need to tell it to manually identify or do it without python. Or manually identify or manually summarize or manually outline without Python. These are key phrases that will help you overcome this challenge of when it starts trying to go and use Python code. Now, sometimes if you get into a conversation and it's already tried writing Python, you may not be able to get it out of doing that. You may have to start over a new conversation, and this time specify from the beginning that you want it to do this task manually. But manually identify, manually summarize, manually outline, don't use Python. Those are helpful terms you can use to get out of this trap, where it tries to use Python code to do simple textual analysis, which is not what we want. We want GPT-4, reading text and writing text.\n\nYou're going to encounter errors and you're going to think about how do I fix this error? And one of the natural ways that you can fix an error is by having a follow up message where you say, no, don't do it that way, do it this other way. And that will work sometimes. But I want to teach you a technique to try to think about when you're working with code interpreter that'll really help you a lot, and that is when it makes mistake to go and fix it at the point in the conversation where the mistake first occurred. Now you can go and continue the conversation, but sometimes you'll end up in a trap where it keeps making the same mistake over and over and over again, no matter how many times you ask it to go and follow up. And part of this can be because it's following its own patterns. The pattern in the conversation is that it makes a mistake, you tell it to correct it, it makes the mistake again. So you can almost think of it as self reinforcing its own mistakes. Now, this is sort of a simple explanation for it. Another way to think about it is like the conversation as a whole is going to influence its output. So you want the accuracy of the conversation and the steps leading to each subsequent interaction to be as correct and as error free as possible. So in this example, I was working through this analysis of one of the transcripts I had created. I got to a point and I wanted it to fix the transcript. Basically, it was supposed to be working on step two. So up here it started working on step two. It didn't do a very good job of step two, which was analyzing the language because it started trying to write python code. And so one way I could have fixed that is I just uploaded the transcript again and I said try again and it did the wrong thing because it skipped to step three. Now, at this point, I could have gone down to the last message and I could have said do step three. But what I'm going to do instead is when this starts happening and I recognize that it's making an error, I'm going to stop it as early as possible. One, I'm going to click the button that says stop generating to just completely cut off that answer because I don't need more of it. And then I'm going to go back to the point in the conversation where the error occurred, this chat message, I'm going to edit it and I'm going to say try again on step two. And the idea behind this is I'm going to be more explicit this time. I'm going to modify my language, I'm going to give it more constraints and I'm going to have it try to fix the error from here so that I don't have this error inserted into my transcript. I want it to go and from the point that the error was introduced, I want to eliminate it and try to have it regenerate something that is correct and is getting what I want. So in this case, just by going and editing the message, then I've gone and given myself the ability to basically edit the conversation, edit the transcript at the point that I'm unhappy. Now I can't edit its text. If I could edit its text, that would be one way of fixing this, but I can't. So what I can do is I can go find the first point before the error occurs that I'm trying to get rid of. I edit my instructions to it, to get it to regenerate like it's doing right here. It's basically going and regenerating, and then now it's going and trying to produce what is the key points. And so now it's actually going and doing the right thing, which is before it did a simple textual analysis and we got all of this, which isn't what I wanted. So then I went right after that and I went and said followed up and then it did the wrong thing because it started working on step three. So I went back and I said, no, I'm working on step two, go and do step two again. So the key is, in some cases it's going to keep making errors or it's gonana make an error. So it's better to find the place where the error first occurred in its output and edit your message to it in that error, right before that error occurred, and then let it regenerate and work off those regenerates, those new content items that it generates. Because you don't want it basically reading its erroneous content over and over. You want it to have your very specific message that gives it the details it needs in order to generate correct output. You want it to read the correct output and then you want it to be responding and sort of following that chain of reasoning that was correct from the beginning. Now, you don't always have to do this, but sometimes this is a really effective way to overcome errors that you may be having, where it keeps sort of producing the same wrong output or it keeps heading in the wrong direction. You'll just find the point in the conversation where that error occurred, in what it generated. You'll edit the message that you gave it, trying to give it more details to improve its output. And you'll do this several times if needed, until you get an output that works. Or sometimes you just may want to do this a couple of times to see it generate a couple of different outputs and see if you can get something better to be the basis of the rest of the conversation. Now note, if you go and you edit something higher in the conversation, everything that came before is going to be thrown away. So as an example of this, if I went way up in this conversation and I edited this initial message right here, the rest of the conversation is going to go away. Everything it generated, all the work that was done is going to go away. So do be careful when you do this and make sure you're okay throwing away all of the outputs that come later because they will go away after you have it regenerate something earlier in the conversation.\n\nI want to give you a simple sort of heuristic that you can use. Now, this won't always work, but it's a good heuristic to help you identify when you're moving into an area where you're more likely to get something dreamed up by the large language model. Something dreamed up by GPT Four that might be a hallucination. Now, we might want hallucinations, we might not want hallucinations, and I'm going to try to show you what I mean by this. But I want to start off by just kind of give you a rough sense of how do you know if you've moved into a space where it's more likely that you will have it create new ideas as opposed to build new ideas that are based on input that you provided it? So a really simple heuristic to look at is how much information are you giving it in the prompt versus how much information is it generating for you? So here's an example where I really want it to hallucinate to dream things up for me. And I'm basically telling it generate a sample receipt from a car rental car company that includes all of the various forms of insurance. And then down beneath here, it goes through and generates all kinds of information. Now, look how much more text it's generated than the information I gave it. I gave it a very small amount of information. I just told it generate a receipt, I didn't tell it what should go in it. I just said it was a rental car receipt and I said it had to have various forms of information, but I didn't specify exactly what. That's not a lot of information in my prompt, but what it's giving us is a whole lot more information. So if you look at the amount of information in your prompt relative to how much information it's producing, if it's producing a lot more information than is in your prompt, that means it's having to fill in the gap somewhere. And typically where it's going to be filling in that gap is by either relying on something that was in its training data or trying to generate new data that looks like the pattern that you're kind of describing to it. So anytime you move into this space, you're more likely to get some output that could have an error in it. You're more likely to see errors in this scenario where you have a very small amount of information going into your prompt. You're defining what you want, but you're not giving a ton of information about what you want. It's just one sentence and we're getting a lot of information out. So anytime we're moving from a small amount and we're basically going to a large amount of information, something has to fill in that information and that's going to be the large language model. And depending on how you view what it's doing, you could either consider it hallucination and an error or you could just consider it generating good content. Now, in this case I wanted it to generate a fake receipt for me. This is, by the way, a really powerful way of using a tool. If you're in an organization where you can't go and put in your private data, but you'd love to experiment, well, one way to do it is go and generate fake data. Use code interpreter to generate fake data that is close enough, but not going to expose private details or be a problem for you to use. So go generate fake data to your heart's content. As you can see right here, it generates a rental card receipt for us that's really effective. But in this case I want it to hallucinate, come up with different ideas. And now I'm not even going to call this hallucination, I think this is just generating valid good data for me. It's generating valid synthetic data for me to use, I don't think of this as hallucination. Some people say this is still hallucination, but I'm going to use hallucination a little bit differently. I'm going to say hallucinations typically I'm going to think of it in terms of a bad form, something we don't want. But anytime we go from a small amount of information to a much larger amount of information, something has to fill the gap and that's where we're more likely to get errors. Now, let's contrast that with doing something different. This is a really small prompt, manual identify key points and themes in this transcript. But the difference is I'm providing a document and that document is a really big document. So what it's going to do is it's going to look at the overall document or some piece of it, plus my prompt. So it's actually getting a lot of information and then it's going and producing the key points and themes down here. Now, the important point of this is it's actually going from a larger amount of information down to a smaller amount of information. I'm trying to have it essentially summarized by providing key points and themes. So in this case where I'm giving it a document and I'm giving it a very small prompt. I'm much less likely to end up in the case where it's generating errors because I'm giving it a lot to work with and I'm asking it to go from a lot of information down to a smaller amount of information. Now, it can still make mistakes, but generally the place where you're going to be more out on the edge is when you're going from a smaller amount to a larger amount. In this case I've got a much larger amount and I'm going to a smaller amount, it's not having to fill in new details. It's trying to do a good job of identifying and getting key points and themes. That's a different thing that's generally trying to shrink down the amount of information, make it more focused and concrete. Now it could get it wrong, it could still make mistakes. But if you're looking at these two cases, small amount of information up to large amount of information, that's where you're more likely probably to see mistakes than you are if you go from a large of information down to a small amount of information. Now, mistakes are always possible no matter what you want to fact check. You want to look at what's being done, you want to make sure that you take ownership of it. Because you are the author of whatever you take out of this and use it is not the author. You are personally responsible for the content. But you should be extremely careful when you go from small to large. In particular, you should put extra, extra scrutiny. Whatever baseline level of scrutiny you put on all the content, you should think very carefully in those cases where you go from small to large to be very careful in those cases as well. Now, it can become difficult sometimes to see the difference. If you have a long conversation and this is in the middle of it, it may actually have a large amount of information to work with or it may go and read something. Now, another thing you can use to help figure out is it pulling in some extra information is I've got a short prompt here, but I don't have any gray box that tells me that it's writing Python code. If I had start seeing a gray box here at the beginning, at the top of this, it would tell me it's writing Python code to do something. And not only then am I going to be using the prompt, but I'm going to be using the output of that Python code in many cases. In this case, what we see is when I say manually identify key points, we then see gray boxes where it's writing Python code. And this result down here, that long bit of text that I'm highlighting, that's going to end up being part of the input. And then we see it doing it again down here and getting more stuff from the input. And so it's building up and actually taking in a lot of different inputs to it. So if we don't see a gray box either, that also indicates to us that it's probably not pulling much in. The other thing is this is the very beginning of the conversation. If we were further down in the conversation, so down here in the conversation, if we were then going to follow up with a chat message, it has all of this information that's come before the chat message to rely on. So that has become part of the context. So you can look at all of these points that it's pulled out. All of this stuff that's come in the prior bit before it in the conversation is now going to be part of what comes next here. So if we've had it pull out of a document, get it into the chat and into the conversation history, and then we put in a simple message, that's a different story because it's taking into account what came before. In contrast, this is at the very beginning of the conversation. Simple message expanding into a lot of content. So when you're going through, watch for these places where you're asking something simple and there's not a lot of context, there's a lot of information, and then you're getting a lot out. Now, what's the classic example for that? You go into ChatGPT and you decide to ask it some factual question as if it's an Internet search engine. This is a classic mistake where you're going to potentially see errors. You go and ask it a question and expect it to pull in real documents, real data. It expands your question into some answer that looks extremely convincing. But you've gone from a very small sort of equivalent of an Internet search into what looks like search results for an Internet search. And in reality, what you've gotten is a lot of new information generated that may or may not be correct. In contrast, you give it a document with a prompt and it goes from a lot of information and a document and a prompt down to a smaller information, much less likely to end up in some problematic place.\n\nLet's look at two ways that we can help reduce the chance that we'll make a mistake and not catch it. And when I say make a mistake, I mean we'll have code interpreter or the GPT four model hallucinate, something that we then accept as correct. This is really important when we're working with documents, we want to try to do whatever we can to make sure that we don't get something that we didn't intend. Some hallucination into the output. Now, what is a hallucination? Well, that's basically anytime that it goes and dreams up something that wasn't really in our original text. And we're really going to focus on, we want the output to be consistent with the documents that we give it. We want the facts to be derived from the documents in most cases. Now, there's some cases where we want it to try to pull from its training data and do other things. But we're going to look specifically at the case where we're trying to build an analysis based on the documents that we've given it. And the documents that we've given it may not align with what it was trained on. Now, this is sort of an important but subtle distinction, is we're looking at the source of truth in this case as the documents. And if that's not where we're going for, these techniques may not be the best approach. But in the case where we really want the analysis to be based on what's in the documents, these are some techniques that can help us. So here's an example I've taken the IRS form 1040. It's a US tax document. And I say, please read the provided document so that you can answer questions about it. And so the Chat GBT goes through or code interpreter goes through and provides some information about it. And then I go and I say list all of the prompts for information in the form and the Identifier. Now, what's really important about this is I'm going and I'm telling it to list the Identifier for these pieces of information that are being asked for. Now, why am I doing this is because when it gives us an Identifier, an Identifier is something that we can then go and cross reference with the original document. What we want to try to do is we want to build ways that we can do consistency checks between what is being produced and the original set of documents. And an Identifier is one really useful way of doing a consistency check because we can take the output, we can look at the Identifier that it provides, it tells us this question and it gives us the Identifier, asks for this information. Well, we can always go back and check if that's consistent with what's in the document, is the question that that Identifier is referring to the same question that code interpreter is saying. And in this case, for example, we can go and we can look at all the different identifiers, like one A, one B, one C, and we could go back and compare those to the original form and see if those questions really do exist and if they really do have those identifiers. So anytime we want to go through and provide some type of consistency, we want to have identifiers or ways of pointing to specific parts of the original documents. Now this could be page numbers and line numbers, it could be section numbers. There's all kinds of ways that you could do this. Now, whatever approach you take, you're going to have to make sure when you provide the documents to code interpreter that all of those pieces of text are clearly identifiable so that it can talk about this section and this number or this page and this paragraph. And you're going to have to have a way of providing that information to code interpreter. Now, when you go and read a document, if it doesn't have it, you might want to have code interpreter go and break the text down line by line and then display it to you with line numbers and then ask it to go and provide an analysis and give you the original line numbers. And then you could try to go back. There's lots of ways of enriching the document with identifiers that you can go back and point to. And that the key, is that you want code interpreter to provide its analysis and in its analysis you want it to output identifiers. Now a second way that we can do this is we can have it go and reference back to the source document. So in this original chat I was going through and I was basically working through one of my transcripts. Now a transcript is kind of a big jumble of text. It doesn't really have any key identifiers, it doesn't have section numbers. It's just a raw recording and transcription of what I said in a video. So how do we go and deal with that? Well, if we don't have identifiers, what we can do is we can ask it to go and look at the text and provide appropriate quotations, essentially, go and pull quotations from the original text and provide them beneath the statements that they support. So in this case, I've asked it to take the outline that it produced and I've asked it to go through and provide me quotations from my transcript where I say something related to that. And then I can go and look at the quotations that it's pulling and see if they really do support the bullet within the outline line or whatever statement is being made. So that's another way that we can do it is we can ask it to try to go and pull from the source material. Now we may have a little bit harder of a time because now we have to go and search for these different quotations. But this is another way that we can go in through and do this. And I've done this several different times. And then you can say we can also go and then identify places where it can't find a quotation. That's interesting data. And so in this case, I had it go and build out an outline and it sort of dreamed up some new ideas based on what was in my transcript and what came earlier. But these are really things that it's injecting into the outline that really weren't present in the transcript. And when I tell it to go and pull from the transcript and find supporting quotations, what it says is it can't do it right here. So it says no specific sentence found in the transcript, but challenges may refer to difficulties in extracting specific details from unstructured data. And we actually see a number of different cases where it says there's no supporting quotations basically within the original transcript. Now, if I'm really paying attention and I see that, I can go and say, okay, well this is a place where I have to decide is it appropriate to include that or not? Because there was nothing about that in the original transcript. So this is in some sense a new idea or hallucination potentially that's being injected. Now, is it a hallucination? I think that's not the case here. It depends on your definition of hallucination. I'm trying to get it to generate an outline that's consistent with the topics that are being discussed in the transcript. And these aren't topics that are specifically discussed in the transcript, but they're related and relevant and valid ideas, they're not just errors. On the other hand, if my goal is to make it so that I'm only outlining and discussing things that are truly in the transcript, then I could view this as an error and I could go and remove all of these. But the key is that having it go and try to pull quotations or reference specific places in the original document is a way that you can then go and do a consistency check and see what's there, what's not. Now, I also could have done this same type of check with identifiers. I could have said produce the outline, now go and reference identifiers within the original document where they're supporting text or supporting statements or supporting whatever it is, basically supporting evidence for the ideas that it's putting into there. So whenever you need to make sure that the output is consistent with original documents, have it go and reference identifiers in the original document. Or have it go and produce essentially quotations that support the different outputs that it's producing so that you can then go and check them.\n\nOne of the best things you can do to help spot errors is to create test cases where you know the answer in advance and then check if code interpreter arrives at the same answer. This is something that you can use to help build confidence but also to just check. Anytime you're working with code interpreter, you can throw in a document or a question or something that you're working with, that you've already predetermined the answer. This will help you know that certain things seem to be firing on all cylinders and accurate. Now I'm going to show you what an example of this looks like and there's lots of different ways you can go about doing this. Now over here, what I've done is I have built out a fake car rental receipt and it looks very realistic. Now I could have gone and taken an actual one, but I wanted to be able to easily go and generate test cases for myself. In using synthetic data that then eyeball and as a human agree is a good set of synthetic data is a good way to do this. What do I want to do? I want to generate some synthetic data that has certain properties to it that then I can use to test inside a code interpreter. What I'm going to do is I'm going to tell it to generate a sample receipt from a car rental company that includes all of the various forms of insurance. Now the reason I'm doing that is over here I'm going to test in this conversation how well it reasons against the Vanderbilt travel expense policy. I know that buried in the travel expense policy is somewhere where it says that, well, you can get reimbursed for the car but you're not going to get reimbursed for the insurance if you get it. The reason for that is because there's already insurance as part of Vanderbilt. They already have the insurance, they don't want you to pay the rental car company for it. If you get that insurance and you haven't followed policy and you're not going to get paid back for it. I want to test that is the reasoning against the Vanderbilt business and travel expense policy accurate or not. One way I can do that is I can go and build test cases of data that specifically violate different rules in the policy and then go and see if code interpreter catches those issues. In this case, I've specifically had it generate a synthetic receipt that has that property. Now I could go and generate all synthetic data, but I've taken this rental car receipt, I turned it into a PDF to make it a little bit more accurate and a little bit more difficult to deal with, and then I have it analyze the receipt and tell me if it complies. Really importantly, it points out that the collision damage waiver for domestic travel, the CDW should be declined as rental vehicles are fully insured through Vanderbilt's insurance portfolio. This test case is telling me that it has dug out of the policy, the appropriate section identified that this receipt is violating that policy and now I can use that test case. Now if I wanted to go back in here and I wanted to do something else, I could just go and edit my prompt, I can generate another test case or I can keep it all in the conversation. I might just go and say, well, I'd like to have another test case where I'm going to test the positive, that does not include any of the various forms of insurance. Now I could go and generate the positive test case where I would expect it to pass the Vanderbilt travel expense policy. Well, look the nice thing about this is when we go through and we begin generating in one format, if we want to have somewhat, some more consistency, we're more likely to get more consistency if we keep generating data in the same conversation because it's already providing a pattern. In this case, we're getting some new charges that are generated. We can see in this case that there's no insurance that's included, whereas over here it has a collision damage waiver and over here it does not. Then I can take that data and I could put it back in as a new document, and you can generate as many synthetic documents as you want to your heart's content or you can take real documents. Again, this can be a great way when you're trying to pilot and test out, is it right for us to use code interpreter? Maybe you don't want to put your real data in it. Maybe you haven't gotten the appropriate legal agreements or privacy things. Place to do that, well, you can generate synthetic data like we are doing here. Then we can take that, bring it back in and take some public document like the Vanderbilt travel expense policy, which is public and is not sensitive, and then combine it with fake data that ordinarily would be sensitive, like an actual travel expense receipt and we can test if it's going to work or not. Test cases are an excellent way to help spot how effective this reason is going. Now one thing we could also do is at the very beginning of the conversation, we could upload the policy. We could have it do it's summarization, and then we could put in all the test cases and see if it passes all of them and is reasonably effectively, and then we could put in the new expense receipt or we could do it after. But it's a helpful check for us to be more confident. Now, it's not perfect. We have to think of code interpreter a lot of times more like a human. There is still the potential of mistakes but it's a way to help us build confidence and build trust that the result is correct and that the reason is correct by having different test cases where we essentially check it. This is the equivalent of when they have a lifeguard on duty to pool and they throw a dummy into the water while the lifeguard is not watching and see if the lifeguard spots the dummy and dives in to rescue it. We wanted to do the same thing with code interpreter. We want to throw some dummies in there and make sure that code interpreter correctly spots problems or correctly reasons with that fake data that we provide in there or correctly reasons with real data where we know the result in advance. Use test cases either with real data or go and generate fake data that has the right format and generate different variations, positive and negative to be able to check and test that the reasoning is correct and that you're getting the expected outcome.\n\nThe hardest things to do with code interpreter are trying to either read or build things that are bigger than a single chat message. So if you're going to go and try and create some product that requires generating multiple outputs and then putting them all together into one single final product. Or you're going to take one big document that's 100 pages long and can't fit into a single chat message that you send to do code interpreter. Those are the hardest types of things to do in code interpreter. And so we're going to go through and talk about how do we tackle problems when they're bigger than what we can do in a simple exchange with code interpreter. Now, the first thing we're going to take a look at is how do we deal with big documents? How do we get context out of some big document that's bigger than we can cut and paste into a single chat message? So we earlier looked at examples where we either took unstructured text that could fit into a single text message to the LLM, or we took a lot of structured data that it could write Python code for. But what happens when we need the LLM like ChatGPT or GPT-4 to read and understand a really big document? How do we go about doing that? Well, we have to do it by breaking the document down into individual pieces that will fit into GPT-4 or whatever LLM that we're working with and can be incrementally processed. So how do we go about doing that? So I'm going to give you three examples of ways that you can do it, but you can kind of pick your own increment. So in this first example, I've got the enrollment report from Vanderbilt. This total report has about 23 pages, it's more than I can cut and paste into a single message to code interpreter. So what do I do is I take the enrollment report and I ask code interpreter to extract each page of the PDF as plain text in a separate file. And so what I'm trying to do is I'm trying to split it up and break it apart into a format that's going to be easier to process. And this is one of the most common, simple things that you can do is you can try to take a long document and you can break it up into separate pages and then work with the document a page at a time. So in this case, I start off by breaking the document apart into a PDF, it's a plain text, and it has each page as a separate plain text file. And this is really important, when you start breaking documents apart, you want to break them apart into separate files. This is really important when you want to go and refer to specific pages or parts of the file or you need to incrementally process it. You need to have it able to go and write Python code that can go page by page or file by file, read in the text, and then have GPT-4 do something with it. Then what I'm going to do in this example is I'm going to say open each page and manually summarize what is on each page. And this is where breaking it apart into separate files is really important. Because, now that I've broke it into separate files, code interpreter can go and write Python code to read each file individually, but it can also help it get a sense of what files it's processed. So one of the things that we're going to face is, we're not only going to have to break the document apart, but we're going to have to help code interpreter remember where in this set of pages it is. And if we break it apart into separate files, typically that's easier to do, there's lots of ways that we can get about doing that. Here's another example. This is a little more advanced example in terms of the prompt that I've used to do this. But basically what I've done is I've taken a longer document, it's a paper that I wrote, it's a very dense paper. But rather than breaking it into individual pages, I've asked it to go and process 2000 characters of the document at a time. So basically 2000 letters at a time. So I've taken one big extraction of the document into a big thing of text. And then I'm going and looking at the first 2000 characters, then the next 2000 characters, and the next 2000 characters. And depending on what you're trying to accomplish, one way may work better than another way. You could also do it as 10,000 characters or 15,000 characters. But kind of thinking about one thing that's important to think about is, if you are breaking it apart into a page, the unit of summarization is going to be a page, the unit of outline is going to be a page. So if you want it to summarize less than a page, you might want to break it apart into chunks of characters. So say go and summarize the first 2000 characters and then the next 2000 characters and you may have several thousand characters on one page, you might have 5000 characters. I don't know how many characters you'll have on a page, but the key thing is that if you go into a smaller unit like a character, you're subdividing, you could go beneath the page level. You may be able to do it on paragraphs depending on how the document is marked up, but you want to have some unit that you're going to work with. Now when you break it apart into those units, those units are going to be your sort of fundamental size pieces. So if you give a summary, you're going to get a summary of that size piece or you're going to have to tell it to combine multiple pieces of that size. If you say 2000 characters, you're going to get summaries and outlines or whatever it is of that size, if you do page, you're going to get it at the page level. Another example of how you can do this is you can think about other types of media like slides. So in this example, I've uploaded 120 slides for a PowerPoint presentation and then I'm breaking the problem apart by telling it to read and summarize the key points on each slide. So what I'm doing is I'm giving it a unit of work, which is the slide, and you're going to go and within each slide do the summary. Now, if I told it to summarize the whole thing, it might work, but it's going to be harder to get all the information out. Because if you remember, one of the important pieces that we're typically trying to do is get information into the conversation so that we can reason about it. So if we start summarizing every page, it's easier for it to get the information in that we want or if we're outlining each page. Now, one of the challenges with this is that if you look at what's happening here, it's going slide by slide. And then it stops because there's a limited amount of work that it wants to do at one time in the output and there's a limited amount of work it can do in the output. So it gets to five slides and then it stops and I have to ask it to proceed and then it keeps going and then I have to ask it to proceed and proceed. And finally, we get through all of the different slides and we can go and do something with it. But when you start breaking it down, it's also going to slow things down because it's going to have to go and look at each page incrementally, it's going to have to summarize or do whatever it is. And each of these things takes time and work to go and pull that data and to process it. Now, when you begin doing this, what you're going to want to do is tell it to do things in some increment. So we're going to go and break it apart in two slides and do something to each slide. And then more than likely, we're going to have multiple iterations back and forth like we just saw where it goes and does, say, 5 or 10 or 15 slides and then tells us, do you want me to proceed? And you say yes. And that's a really important thing to note, is once you start breaking it down, it is going to be more time consuming, especially if you go through and walk through the whole document. So, one of the things we're going to have to think about is there a better way of doing this? Do we have to read through the entire document? Do we have to break every page apart? Do we have to go and read every single page to accomplish the task that we want to accomplish?\n\nWe've seen how we can break a document down into different little pieces that we can work with. They could either be pages or sections of text or paragraphs or slides. But sometimes what we want to do is we don't necessarily want to go and process all of it incrementally every single page, every time. Sometimes we need a way to help the LLM or code interpreter find exactly that page it needs. Now most of the time, we're going to have to go through and process the whole document in some form. But we need some way of helping it get to the information that it wants. Since we can't put everything into one prompt at once, even if we break it into files, we need a way of helping us find the information it needs to answer our question. How can we do that? Well, if we think about what a human does, if you pick up a book and you want to look for a particular topic, you're going to go to a table of contents or an index, or you're going to try to use some tool that allows you to search for keywords within the document. We have to be able to support these same types of things in code interpreter. Now sometimes it can go and use Python and just do a keyword search to find the relevant information. If you know exactly the terms that it needs to look for, it can go and find that exact spot in the document. But sometimes you don't know exactly the terms that are going to be used in the document, and so you need some way of building an index from a document. Here's an example of building an index from a document. I've taken a document which is the Vanderbilt travel policy, and I've broken it individual pages. Then what I'm going to do is I'm going to use code interpreter to build an index so it can know where to find things in the travel policy. Here's what I say. I say please analyze each page and provide me with a policy search index that maps travel policy topics to pages. Then down here we see it's mapped different types of policies like reimbursement, air travel, car rental, international travel, lodging, meals, and mileage into the pages in the document where those topics occur. Now why is this important? Is because I then go ask a question on a particular topic or related to a particular topic, code interpreter or GPD4 will build to figure out which pages it needs to load into the conversation and look at and process in order to answer the question. It helps it immediately hone in and zoom in on the information it needs. I'm going to show you how I use this now. After I've built the index, I can then say using your index, read the policies related to stain in an Airbnb and tell me if I can get reimbursed for this if the cost is less than the average hotel in the same city. Notice what it does. It then says, the policy related to stain and non-conventional lodging opportunities such as Airbnb is mentioned in the document. Here are the key points. Non-conventional lodging opportunities, such as those available through Airbnb, HomeAway, or similar providers or allowable expenses. Now notice what it did. It's translating policies related to Airbnb and it's figuring out that means non-conventional lodging. Why is it able to do that? Because it can go and figure out which pages in the document it needs to go and use to answer questions. If I then go and I give it something else, like let's assume I'm in a foreign country traveling and taxing it breaks down on the way to an important meeting, can I get reimbursed? It knows I need to go and look up policies related to probably car rental or some other aspect, mileage, things like that. It's going to look on similar pages, and then it allows it to go and pull out the relevant policy information. You can then go and ask different topics. The key is that when you begin building up an index or some way for it to look into the document, it helps it figure out what pages do I need to go and pull in. In this example here, where I say using your index, read the policies. Now normally, I don't want to show you the Python, but I do in this case because when I say using your index, read the policies, it goes and looks at two specific pages, Page 4 and Page 7. Right here, it's saying Page 4 texts and Page 7 texts. If you look up here, lodging is on Pages 4 and 7. It knew when I was talking about Airbnb that that was a form of lodging, it went to the index, it immediately saw that lodging was on Pages 4 and 7, and then it wrote Python code to read Pages 4 and 7 in, in order to answer your question. An index or a keyword mapping to pages or whatever it is, you want some way of it to figure out, if you break it into paragraphs, if you break it into slides, if you break it into sections, if you break it into pages, whatever it is, you need to build a master index. Now, notice one important thing. It's going to take you, if you start a new document, it can take a lot of work to build an index. To build this right here, can take a lot of work. Once you've built it, don't start from scratch if you're going to do a lot of work with that document. Copy and paste this into another document or ask it to save that index in that little chunk of text into a document for you and then upload it or reuse it in the future. If I ever go and have a conversation with this travel policy again, I don't need to start from scratch having to go through break that document apart into individual pages. I could have just had it create all the pages like it did up here. I could have downloaded them all and put them into a zip file. Similarly, I could have created an index like this, put it into a text file, and put that in the zip file, and the next time I started, rather than giving it the original document and saying go page by page and break everything down, summarize it then turned into this index of policies, no, I just go and give it my zip file that has all of the pages as plain text already there, that already has my index, and I say go and look in index.txt, and then figure out which pages you need to answer questions related to first-class international air travel. Then it would immediately be able to directly go in and pull in the relevant pages. I don't have to sit around waiting for it to go and process every single page before. Particularly when you start working with these larger chunks of work, you want to save the incremental pieces. If you build an index, save the index. If you break the document apart into multiple pages, save those pages. Don't start from scratch if you don't need to. If it does a good job on some piece of work, tell it to save it as a file or copy and paste it into something so that when you start next time, you can start with this intermediate products, either the individual pages of text or the indexes are the keyword index or whatever catalog you've got, you want to start there to make it easier. Or maybe you just take the zip file and create folders where you say lodging and then you dump Pages 4 and 7 in there, or better yet, ask code interpreter, go and rearrange these pages that I've extracted into folders based on the policies that they cover within those pages, and then put it in a zip file and the next time you upload it, just say, look for the page is relevant to lodging and it'll be smart enough probably to go and see, oh, there's a folder with lodging here, I should read these pages\n\nI'm going to show you an example with code interpreter where we go and analyze a policy document, and begin asking questions about the document, and getting answers from within it. Now, in this case, I'm going to use the Vanderbilt travel policy and expense policy. This isn't our favorite thing to go and read and look at, but a lot of times you have questions. If you go into business travel for Vanderbilt where you're going to buy something, you want to know what policies apply or what do I need to know? A lot of times, the way that we deal with this is we resort to emailing somebody and trying to wait for an answer. We probably could go and read this document, but let's go and take a look at what ChatGPT and code interpreter can do to help us with this. I've actually gone through and built an entire chat with ChatGPT and code interpreter around the Vanderbilt business policy. Now, I've already run through everything, so we're not going to do it in real-time because that takes a little bit of work because it has to go and do extraction of the PDF and a bunch of other things. I'm just going to walk through the chat that have already had and show you the capabilities that are there. We're going to start off by saying, please read the provided document so that you can answer questions about it. This is the start of our chat, and what I've done here is I've provided the PDF itself of the travel policy. This is the same document that you just saw open. We'll see what happens with ChatGPT. Basically, it goes through and it extracts the document and reads it, and so it says the document titled Travel and Business Expense Policy isn't administrative policy with the following main details. It discusses some high-level details about the document, who the responsible administrators are and some other things and it provides some information about the policy. Now, let's go and see the power of this. Now, one of the things that we always talk about and we hear talked about is that ChatGPT and these other AI tools, they don't have access to my data. It wasn't trained on my policies, so how will it know and be able to answer questions for me or for my business, or for whatever it is? We're going to be able to fix that because what we've done is we've uploaded the document, we've given it the travel policy, it's given an initial summary. But now this is the difference from if we just go and work directly with ChatGPT, is it's now working off and it's read the travel policy. It has gone and dissected it and is going to allow us to answer questions. I'm going to start off by saying just summarize the policies related to air travel. Then what we see below here are the summaries from the document. It specifically says the document outlines the following policies related to air travel. Travelers are required to use Vanderbilt's online booking tool or to contact the travel agency. Airfare upgrades and fees obtained using rewards, miles, or credits are considered a personal expense and not reimbursable. There's all kinds of policies related to air travel. Then it tells us, this is just the first thousand characters from the air travel section. Now, this is an interesting thing that we'll talk about at a later point. But the key is here, it's actually incrementally analyzing the document and giving us information, and so it's told us this is part of the travel policies. I'm just going to go ahead and tell it to go ahead and analyze the next thousand characters because that seems to be what it wants to talk about it in terms of. It goes and analyzes the next thousand characters, it tells us, wouldn't it be nice to fly first class? Well, here's the cases where you can actually do this and basically you're not going to fly first class is the answer. First class seating is reimbursable only if the traveler's Vice Chancellor and Chief Business Officer have approve the request. Then they give some other examples where you might be able to travel in first class. Again, I go through and analyze the next thousand characters, it gives me some more information about the travel policies related to flight. Now, I'm going to do something different. I'm going to actually go in process and transform the document itself. What I'm going to tell it to do is I'm going to tell it to take the document and to take this PDF and split it apart into text files where I have one file per page, so I'm basically breaking the PDF apart into separate files. Now, this in itself can be a really useful feature. If you have documents, you want to go and split them up, do different operations, get them in different files. It goes and actually extracts all of the individual pages for the PDF. It turns them into separate text files which I could download any of them right here using the links. I'll skip showing that to you, but just know that, at this point, I could have gone and downloaded the actual text. Now, I didn't actually care about downloading those files, I just wanted to extract them to help it do some analysis. Now I'm going to go and tell it to analyze each page and provide me with a policy search index that maps travel policy to pages. You can imagine if this thing didn't have an index, I could then go and quickly find what is the page that I need to be looking at. If I look at this, I'm not sure that it really does have a full index at the beginning and so I'm actually building the index right here. I'm building an index and I could have gone and use different keywords or different things, but I'm basically building up an index of what is where within the document. That's pretty neat. I'm taking the document, it's reading it, it's analyzing it, it's building an index of where things are. Car rental should theoretically be on Page 2, so if we went and looked for that, we will probably find Car Rental somewhere listed, here it is. On Page 2, car rental should be booked through the University online booking tool. It tells us and we're getting the index and we could go and look at different policies and procedures related to that. Now what I'm going to do is I'm going to say using your index, read policies related to staying in an Airbnb and tell me if I can get reimbursed for this cost if the cost is less than the average hotel in the same city. Now we're going beyond just building an index or splitting the document up. We're actually going to ask asking questions and trying to get it to help us answer questions related to the document and Vanderbilt's travel policy. It says the policy-related to stay in and non-conventional lodging opportunities. I suspect this is what Vanderbilt terms these things and you'll notice I said Airbnb in it translated that and understood it as being non-conventional lodging opportunities within the document. It says non-conventional lodging opportunities such as Airbnb is mentioned in the document, here are key points. Non-conventional lodging opportunities, such as those available through Airbnb, HomeAway or similar products, are allowable expenses. It's known what I'm asking for and it's translated it and figured out where the policy is. It tells me some other interesting things, like Vanderbilt does not have a separate policy on ride-sharing or non-conventional lodging. Travelers are allowed to stay in accommodations that are reasonable and appropriate for the business purpose and location. Now you notice that's not directly a non-conventional lodging fact so why is it bringing that information up? Well, it's interesting because then at the end, it's trying to answer our original question, and our original question was, can I stay in an Airbnb if the cost is similar? What it says is from this information, it can be inferred that you can get reimbursed for staying in an Airbnb, if the cost is less than the average hotel in the same city, as long as the cost is reasonable and appropriate for the business purpose and location. However, you should be aware of the terms of agreement with Airbnb and consider the ability of Airbnb to provide complete, reliable and safe services and accommodations. Interesting add-on at the end of it but the key is, is that it's basically taken this whole set of information and it said it has to be reasonable and appropriate, it has to be less and it's basically combining all of the policies in order to give me an answer. It's basically saying, yes, you could go and do that and it's pulled out relevant pieces of information from the document in order to answer my question. Again, from a big picture, Chat GPT might not have ever seen Vanderbilt's 2022 travel expense guidelines. I didn't actually check for the year so let's go back and check and see. This is effective. It was originally issued in 2018, current version is effective as of 2022. It probably wouldn't have seen the updated versions of this. But the key is it's actually going in and looking at this document and pulling out the relevant sections in order to answer the question. Let's go and get a little trickier and see about how it's reasoning works. I say, let's assume I'm in a foreign country traveling in a taxi and it breaks down on the way to an important meeting, can I get reimbursed if I pay someone to drive me on the back of their motorcycle to the meeting, assuming they are a private citizen? I have no idea if the Vanderbilt travel policy covers this or not, but let's see how it reasons about it. It says based on the information provided in the document, the key points relevant to your question are as follows. The University requires travelers to select the most reasonable and economical form of transportation when traveling on University business. Non-conventional transportation options are not explicitly mentioned in the policy. Vanderbilt does not have a separate policy on ride-sharing or non-conventional lodging. Given these points, it seems plausible that in an emergency situation where no other reasonable and economical form of transportation is available, the cost of transportation by private citizens motorcycle might be considered as an allowable expense. However, the University's policy does not explicitly state this and reimbursement may be subject to review and approval by the appropriate authority. That's a pretty good answer. Hey, you're riding in an emergency situation on a back of a motorcycle to somebody that you've handed $20 to probably isn't covered, but that's a pretty reasonable assessment and they say, hey, it has to be approved Then let's say, from your reading of the document, who would likely need to review and approve this expense? It basically states that your financial unit manager or business expense approver, we need to review and approve it. But it does point out and it's fairly good and saying, however, in the case of an unusual or exceptional expense such as the motorcycle ride in your scenario, it might be necessary to seek approval from higher authorities. I suspect that would be the case. Then I go on and I say, well, let's really test its knowledge and ability to dissect here. I say is the rental of equipment like a bulldozer covered in this policy? Not sure why I would ever need to run a bulldozer, but you never know from research purposes. But I'll throw it out there and see how it handles this question. It says very nicely the document does not explicitly mention the rental of equipment such as a bulldozer. However, there are several important points. Vanderbilt requires travelers to select the most reasonable and economical form of transportation. If you're implying that you're running a bulldozer to go to the airport, that's probably not the most reasonable and economical form of transportation. I think that's what it's hinting at here. Expenses for damages to any form of lodging, rental accommodations, or vehicles are not reimbursable. If you decide to rent a bulldozer and drive it around and you break something, you should just know that you're probably going to have to cover that expense yourself potentially. I think it's trying to warn the traveler here that maybe you should think twice about renting a bulldozer and driving it. Particularly if it's going to the airport and you're going to damage a lot of things. All expense reports require a valid business purpose. I think it's trying to signal to you it's not clear why you would need to rent a bulldozer particularly under the travel policy, and original receipt of all expenses greater than $75, it's probably going to cost you more than $75. Now I think part of the reason it's asking me and pointing out all these things is I just finished asking it about riding on the back of a motorcycle. I think it's just trying to make sure that based on the context that I previously asked riding on the back of a motorcycle, that I'm not trying to rent a bulldozer and drive it somewhere. It does then very clearly hedge its bets and say given the lack of specific information regarding equipment rental in the policy, it's recommended to consult with the appropriate authorities. Let's ask a more reasonable question. If I book a flight and it gets canceled, can I book a rental car to drive home and still get reimbursed? Sometimes when I've been stuck in the airport, I wondered if maybe I should just go over to the rental car counter and book a rental car instead. It says, based on the document, the policy appears to allow for flexibility in choosing the most reasonable and economical form of transportation while traveling on university business. However, it does not explicitly mentioned the scenario of a flight cancellation leading to a car rental. It's reasonable to infer that if a flight gets canceled and the most appropriate practical alternative is to rent a car to drive home, this could be an allowable expense. But then it goes on to say they must be documented, they must be a valid business purpose, and that you might have to go and get some type of approval or have some interpretation of it. I think it's doing a great job. But I want to just back up for a minute and realize the power of what we've just done. We've taken information that's in Vanderbilt travel and expense policy, and we've turned it into a QA. We've taken information that it wasn't trained on or potentially wasn't trained on, and we're now having to back-and-forth discussion about that travel policy. At the same time, it was also able to go into a lot of operations on the document, like it extracted a series of an index force that wasn't present in the original document to tell us where certain topics were covered. It also went through and extracted all of the individual pages for us. If we want to go and process the document and be able to work with the individual pages or do something with them, we could do that. It also gave us a lot of other information so we can walk through the policies, for example, related to air travel. It can go and filter the document down, and then give us listings of information that are relevant to our filter or our search. It's going and doing a lot of really complex operations, even though we're apparently doing something fairly simple, which is taking a document and asking questions about the document and conversing in it. I say this is simple but if you went back in time, not very far in the past, this would not seem simple at all. It's going and doing a really good job of analyzing the document, applying different transformations on the document, different types of analyses, it's helping us get questions answered where the information is trapped inside of a PDF. Which is not one of the most ideal forms for going and consuming it and getting some type of automated analysis.\n\nWhen we're trying to produce something that's bigger than we can get in a single output. Meaning that when code interpreter responds to us, if it can't give us a single message or chunk of text to give us the answer that we need, or to produce the document that we need, we're going to have to work a little bit harder. Now we're going to see over and over this sort of pattern, like, I'm about to show you where it's doing some work and then it gets cut off or it stops. And sometimes we can get lucky and we can just say, hey, continue what you were doing, and it'll pick up what it was doing and where it left off, and then give us a file. So in this case I was trying to get it to produce a Jupyter Notebook, which is basically an interactive notebook where you can interact with data. And so I had it going through and producing the notebook, but it turned out the notebook was bigger than it could fit into this output up here, particularly because it was doing a lot of work before it and making mistakes. And so it ended up running out of space in order to give me the output. And so in this case I got lucky because I could just say continue and then it went on and picked up where it left off and gave me the notebook. But there's a lot of cases where we're going to work on something that's so much bigger than a single output that it can give us from a prompt that we're not going to be able to get it in there. And we have to have a strategy for working with it. And how are we going to do that? So what we're typically going to do is we're going to have a plan in place where we incrementally build the product that we're trying to do. Now this is an example where I'm going to have it go and create an AI planning example. So we talked about AI planning and how we can have it plan how to accomplish a particular task force. And so I'm having it basically go and build a plan. And part of the plan is going to be that it incrementally writes all of the different pieces it needs. So if you're writing a book, for example, and you needed to produce all of the different pieces, it's going to have to write it probably one page at a time. And then you're going to take the individual pages and you're going to put them together into chapters and then you're going to take the individual chapters and put them into the book. But the key piece is you have to have a plan where you go step by step by step and you produce each piece of the final output incrementally. And then you can take all of those final outputs and put them together. So in this example, I've had it put together a plan and now I'm asking it to proceed and basically executing its plan or basically, writing or producing this piece of content step by step. Now, in this case, what I was asking it to do was I had recorded a transcript of a video and I wanted to turn it into a blog post. And so I had it produce a plan for producing the blog post which included incrementally, doing particular things, and writing different pieces of it. And then I had it go and start executing its plan. And at different points in time, I'm basically telling it to proceed to the next step, proceed to the next step. And what I'm doing is telling it to write or output the next piece of content. Now, the way that you use this is when you're going to build something big is you have it go and try to write it a section or a piece at a time. And each time it produces something, ideally you save it in a file. And the reason behind this is you want it to write a bunch of individual pieces or produce a bunch of individual whatever it is, that you can then assemble all the files into the final product. So in this case, I had it go through and take a transcript of one of my videos and I had it produce individual sections describing the concepts from that video. I had it write each section incrementally. And you can see as I scroll up this how long this conversation is. This is way beyond a single piece of text. And each time it's doing something, it's basically producing a file that's saving that incremental product. So each time it produces a new piece of the final overall output that I want, I have it save it to a file. And I'm going through here and I'm basically building up all the different pieces that I'm going to need of this final output. One by one, I'm building them up, and then towards the very end down here, when we get all the way down to the very bottom of this thing, I finally get to the point where I can say combine all of the sections into a single file for me to download. And so the idea behind this is I can go and work for a long time. I can have it make file after file after file after file and each file has a separate piece of the overall thing I'm trying to create. And then at the end I just tell it, combine it into one file, combine it into one presentation, combine it into one whatever it is that you're trying to produce. So if you're working with a big document and you need it to understand it, you're going to have to break it down into pieces. But if you're trying to produce some large document, you're going to have to have it probably go and write the individual pieces one by one. Now, I want to just take one moment to contrast this with structured data. If you're working purely with structured data, there's a good chance that you're never going to have to do any of this stuff right, because it can just write Python code to automate all of this for you behind the scenes. So you can take some Gargantuan Excel file or data set in whatever form it is, you can upload it. It can write code to do really complex processes on it. It can output really big files as a result of those processes. So it may go and take an Excel file, crunch a ton of numbers, and produce another huge file as output. And that can probably happen in a single chat message because it's behind the scenes and it doesn't all have to be visible. The moment you start reading unstructured text or writing unstructured text, meaning that you're having it have to reason over the text and produce and write the output. And the output is not write a Python program that produces the real output, but meaning, literally, it's writing or it's having to do a lot of work. It's having to write a really long Python program. It's these cases where we have to start breaking the output down. If you're writing a program, this might be getting to write Python functions for individual pieces and then put them all together. If you're writing a novel, it might be writing individual pages and then putting all the pages together into a chapter, and then putting all the chapters together into a book. Now note when you get to this scale, it gets harder and harder to work with and to do it well. But the key is you're going to have to start breaking things down, both on the reasoning side, when you're reading them, you break it into pages, find the pages you need, have it read just those pages. And on the writing side, you're going to have this larger product that you're trying to work on, but you're going to have it break it down a page at a time, or a paragraph at a time, or a section at a time. Write individual pieces of it. Save them as separate files, incrementally as you go, and then have it assemble them at the end. That's the way that you're going to have to go and build these larger products that you're trying to create.\n\nI said that we're going to have to break our outputs apart into individual pieces that we're going to save to files, and then we're going to later reassemble. Now, this sounds much easier than it actually is, and because there's a really important point to this, in which is that if you break it apart into individual pieces and you're working on one piece at a time, you can have code interpreter lose track of the big picture and understand how the pieces fit together. Also when it's writing or working on individual piece, it may not have the full context or information in order to appropriately write that piece. Now, when I say right, I'm using this term very liberally. It can be writing software, it could be writing and creating some visualization, it could be going and writing a part of a book, it could be producing slides, whatever it is, whatever big thing you're doing when it's trying to write or produce output. If it doesn't have the big picture, then it's going to be harder for it to do the right thing. You might get one piece that says one thing, another piece that says something very close, duplicates a lot of what came before. It only says a little bit new, or you may get something that's just completely disconnected and incoherent. If you don't have full context, if you don't have everything in one chat message, it gets harder for it to reason about how to write the individual pieces correctly and save them as individual files that when you put them together actually makes sense. How do we go about tackling this problem? Well, what we need to do is we need to think about outlining. Outlining is the mental model. As soon as you start working with big files, big outputs, you want to think about outlines. Now, the outline may take many different forms. The outline can be the plan of how we're going to incrementally go and tackle the problem, and we can use the outline as something that can remind code interpreter of where it is in the process. The outline maybe instead of steps that are going to take place in a certain order and then are going to be applied to every file, it could be a variety of different things. We went into a lot of detail on AI planning and also contrasting that with human planning, and what you're really doing is building an outline. You are building an outline of the process. What we wanna do, just like we did when we were doing planning and we're breaking down the task step-by-step, is we want to build a road map of step-by-step. What are all the individual pieces of content and how do they fit together? That's what the outline gives us. In this example. I'm going to take a transcript from one of my videos, and I'm going to ask it to outline that transcript, and I'm going to ask you to outline for certain things. I'm asking you to look for skills or techniques or patterns that I talked about and really emphasize those in the outline. Because that's the form that I want the overall structure to take. I want it to really be focused around patterns and skills. When you're building that outline, make sure it emphasizes. You can say just outline it and sometimes that works, but really we want to think about how do you want to structure everything? It goes in, it builds an outline for me, and notice we have four sections here. Now what I want to show you is I want to show you how one of the sections evolves. In the beginning we had Section 1, and it just had a paragraph of text, and this is now section one. As I'm evolving this outline, I keep asking it to expand on different parts of the outline. As I'm doing that, you'll notice now section 1 has a bunch of subsections underneath it, including this section 1.2.2, and then I'm going to go and I'm going to expand section 1.2.2, and now I have 1.2.2.1, and 1.2.2.2, and 1.2.2.3. I keep expanding this until it gets bigger and bigger. Basically what I'm doing is I'm incrementally expanding the road map or the overall structure that I can provide to code interpreter to help it assemble the pieces, but also to know what all the pieces are and to know where it is. Now, sometimes what's going to happen is code interpreter is going to forget where it is, or code interpreter may time-out or something like this. This outline that you're producing is a really valuable product that you want to save incrementally. You'll see I'm doing that right here. I'm actually saving it to a file. As I'm going and I'm building out the outline, I start saving the outline to a file because more than likely what's going to happen is, at some point my outline itself may be bigger than what I can fit into a single message. This is one of the parts where outlining is really effective, because once I get to the point where, let's say all four sections can't fit into one chat message, which is really what's starting to happen here, I start breaking it apart and I just say, go work with section 1. I can provide it the high level titles of section 1, 2 and 4, and 3, whatever the important sections are related to it and then I can give it the detail for one individual section. Or if even that gets too big, I can go and drill down to one particular level within the outline. The key is, that you can zoom up or down in the outline in order to control how much of the big picture is present in code interpreter at one time. Now, we're doing this because we can't fit it into one message. We can't fit it into one output and we need code interpreter to understand, how does everything fit together? If you can get it all to fit together, by all means do that but if you can't build an outline and start incrementally expanding it and then when you put the pieces together, you want to give code interpret and instruct it to put the pieces together as specified in the outline. An outline is essentially a plan for how all of the different pieces fit together. But it's also a plan that is very effective because you can break it apart at a certain level of granularity in order to provide code interpreter in a message, the information it needs to accomplish a particular task. If I'm writing Section 1.2.2, or maybe let's say I'm writing these subsections down here I may not need to provide it information in 1.2.1 or 1.2.2.1 I can just leave that out. I may just provide it the information about 1.2.2. I may provide this high-level bullet here, but I may eliminate and not show it these things here. I may not show it any of the things that come after. It just really depends on how important it is for these to be integrated together. Now this is another important piece to know. The more independent the individual pieces are, the easier it's going to be to do this. If you can just have it go and write and do things completely independently from one another and they don't need to have any context of the other pieces, this is when it's easy. Now, let's imagine that I'm writing Section 1.2.2.2 here dealing with unstructured text, and I need it to know about what was said in Structure 1 or in Section 1.2.2.1, which is what came before it. If I needed to know that, I'm going to have to provide that context back to it before I have it go and right those sections. You always have to be thinking, this is why an outline is also helpful what comes before or after that it needs to be aware of, and can I pull that out of the outline and put it into the context of what's being written? Now and it's when all the pieces have to fit together and hang together and this piece that comes before S to has to have a little hook for the next piece of content, and that has to have a little hook, that's when things get more difficult. That's when the outline becomes really important because you can provide different chunks to help make sure it has the context to put things together. The context may also be go and load the last two paragraphs of text from 1.2.2.1.2 and provide them at the start of this section so that you can see the last two paragraphs you wrote, refresh its memory, and then it can start picking up from there and it doesn't write something that is completely disconnected. You can get all the individual pieces to be completely independent from each other and then you just assemble them according to the roadmap that is ideal. If you can't do that, then you have to start thinking about which pieces of the outline need to be present at the point that I write another piece of content. You can then use the outline to help you figure out. Here's the bullets that it needs to know before it writes this piece of content to make sure that it has appropriate context or you may also have to go and think about what are the prior outputs like paragraphs or text that I can need to provide it to fit in to make sure the writing is more closely tuned and aligned. You'll have to come up with strategies basically, to use the outline, to figure out what needs to go into the individual pieces, how to put them together, and how to make sure that they're all cohesive. That's a really tough problem but outlining is your friend. Outlining is going to be the backbone of what you do. As you produce these outlines, make sure that you save them. Now I'm going to show you one other example of why saving an outline is so important. As you'll see here, I'm going through and as I'm producing every single thing, as I'm going along here, I'm saving it to a file. That's because when you're working with code interpreter, it's going to timeout sometimes. You're going to have to go and pick up your work where you left off, and at some point, you're going to want to do something that looks similar to this. Whereas it timed out, it lost some files and now I'm just uploading different pieces of the outline, different intermediate products that it created and I'm giving it back to it. Part of the beautiful thing about this is since I've got the outline, I can say here's the overall structure, here's different pieces that you've created up to this point and it can begin picking up where it left off, and the outline gives it the structure to help remember and pick up what it did before or you can start a completely new conversation for some subsection of that outline. Say, here's the overall structure now in this new conversation, just go and work on this piece over here and you can go and increment on, iterate on it, produce some intermediate outputs, and then you can take those and in a later conversation, bring everything back together, give it one big zip file of all the sections, tell it what the naming scheme is and how to match what the different files are, back to the overall outline and then ask it to put everything back together using the overall outline."
  }
]