## 5. RAG Systems in Production

[Study Notes](#study-notes)

[Questions](#questions)



### Key Points

#### 1. ‚öôÔ∏è Production Challenges in RAG Systems  
- More traffic increases latency and memory/compute costs.  
- User prompts are unpredictable and creative, making testing incomplete.  
- Real-world data is often fragmented, messy, and includes non-text formats like images and PDFs.  
- Security and privacy are essential, especially for proprietary or sensitive data.  
- Mistakes in production can cause financial and reputational damage.  

#### 2. üìä Evaluation Metrics for RAG Systems  
- Software metrics include latency, throughput, memory, and compute usage.  
- Quality metrics include user satisfaction (thumbs up/down) and output quality (relevance, faithfulness).  
- Code-based evaluators are cheap and fast but limited; human feedback is costly but more accurate.  
- LLM-as-a-judge balances cost and flexibility by judging relevance with clear rubrics.  

#### 3. üîç Observability and Logging  
- Observability platforms capture system-wide and component-level metrics.  
- Traces show prompt flow: initial prompt ‚Üí retriever ‚Üí reranker ‚Üí LLM ‚Üí response.  
- Latency can be analyzed at each pipeline step to identify bottlenecks.  
- A/B testing and interactive prompt trials help evaluate system changes.  

#### 4. üßÆ Quantization of Models and Vectors  
- Quantization compresses 16-bit parameters to 8-bit or 4-bit integers, reducing memory and compute costs.  
- 8-bit quantization causes minimal loss in recall and response quality.  
- 1-bit quantization compresses size by 32x but may reduce performance noticeably.  
- Quantized vectors enable faster retrieval with minor accuracy tradeoffs.  

#### 5. üí∞ Cost Optimization Strategies  
- Use smaller or quantized models to reduce inference costs.  
- Retrieve fewer documents by lowering top_k values.  
- Use system prompts or token limits to shorten responses.  
- Store vector indexes in RAM for speed; move rarely accessed data to SSD or cloud storage.  
- Multi-tenancy allows dynamic loading of tenant data to optimize memory use.  

#### 6. ‚ö° Latency Reduction Techniques  
- Most latency comes from transformer-based LLM calls, not retrieval.  
- Router LLMs can skip unnecessary steps to save time.  
- Caching responses for similar prompts can avoid repeated generation.  
- Smaller or quantized LLMs run faster on the same hardware.  
- Database sharding splits large indexes to improve retrieval speed.  

#### 7. üîí Security and Privacy Measures  
- Authenticate users to control access to sensitive knowledge bases.  
- Use tenant separation to isolate user data in databases.  
- Encrypt text chunks stored in vector databases; decrypt only when needed.  
- Vector databases are vulnerable to reconstruction attacks; mitigation includes adding noise or transformations.  
- Running RAG systems locally/on-premises increases data control and security.  

#### 8. üñºÔ∏è Multimodal RAG Systems  
- Both retriever and LLM must support multimodal inputs (text, images, PDFs, audio, video).  
- Multimodal embedding models represent text and images in a shared vector space.  
- Language-vision models tokenize images into patches (100‚Äì1,000 tokens) for unified processing.  
- PDF/slide documents are split into patches and vectorized for retrieval.  
- Multimodal RAG requires storing many vectors but offers flexible and effective retrieval.  

#### 9. üèÅ Summary of Production Management  
- Production RAG systems face higher traffic, unpredictable errors, and higher stakes than prototypes.  
- Continuous monitoring, evaluation, and experimentation are essential for system improvement.  
- Trade-offs between cost, latency, and quality must be carefully managed.  
- Security and privacy must be maintained without sacrificing performance.  
- Supporting multimodal data expands system capabilities beyond text-only retrieval.



<br>

## Study Notes

### 1. ‚öôÔ∏è Introduction to RAG Systems in Production

Retrieval-Augmented Generation (RAG) systems combine retrieval of relevant documents with language model generation to produce informed, context-aware responses. While building a prototype RAG system is challenging, deploying and maintaining one in production introduces a whole new set of complexities. This module focuses on the practical aspects of running RAG systems at scale, including performance monitoring, optimization, security, and handling multimodal data like images and PDFs.

In production, RAG systems must balance **cost**, **speed**, and **quality** while dealing with unpredictable user inputs, messy real-world data, and strict privacy requirements. Understanding these challenges and how to evaluate and improve your system continuously is critical for success.


### 2. üöÄ Challenges of Production-Scale RAG Systems

#### Scaling Performance

When your RAG system faces more users and requests, it must handle increased **latency** (response time) and **load** (memory and compute resources). More traffic means higher costs and potential slowdowns. Maintaining fast, reliable performance while scaling is difficult because:

- Large language models (LLMs) consume significant compute power.
- Memory usage grows with more simultaneous requests.
- System components like retrievers and rerankers must keep up without bottlenecks.

#### Unpredictability of Prompts

Users can ask anything, often in unexpected or creative ways. Even with thorough testing, you cannot predict every question your system will receive. For example, a user might ask, ‚ÄúHow many rocks should I eat?‚Äù which is nonsensical but must be handled gracefully.

#### Messy Real-World Data

Data in production is rarely clean or uniform. It may be:

- Fragmented or incomplete.
- Non-textual, such as images, PDFs, or slide decks.
- Missing metadata that helps organize or interpret it.

Extracting useful information from such diverse sources requires specialized tools and pipelines to build a reliable knowledge base.

#### Security and Privacy

Many RAG systems handle sensitive or proprietary data. Ensuring **privacy by design** means:

- Restricting access to authorized users only.
- Protecting data from leaks or unauthorized exposure.
- Balancing security measures with system performance.

Mistakes in production can be costly, damaging reputation and finances. For example, airline chatbots have mistakenly offered fake discounts, and malicious users may try to exploit RAG systems for unauthorized access.


### 3. üìä Evaluation and Logging: Measuring RAG System Performance

To maintain and improve a RAG system, you need to **measure** and **monitor** its performance continuously. This involves tracking both **software performance metrics** and **quality metrics**.

#### Software Performance Metrics

- **Latency:** How long it takes to respond to a prompt.
- **Throughput:** Number of requests handled per second.
- **Memory and Compute Usage:** Resources consumed during processing.

#### Quality Metrics

- **User Satisfaction:** Often measured by thumbs up/down or detailed feedback.
- **Output Quality:** Accuracy, relevance, and faithfulness of responses.

#### Tracking and Logging

- Aggregate statistics help identify trends and detect regressions over time.
- Detailed logs trace individual prompts through the entire pipeline, showing each step from query to final response.
- Logging enables debugging and understanding where problems occur.

#### Experimentation

- Use **A/B testing** to compare system versions or components.
- Run secure experiments to validate improvements.
- Interactive tools allow trying new prompts and generating reports on system performance.

#### Types of Evaluators

- **Code-Based Evaluators:** Automated checks, e.g., validating JSON output. Cheap and fast but limited.
- **Human Feedback:** Most accurate but costly. Includes thumbs up/down and detailed assessments.
- **LLM as a Judge:** Uses language models to judge relevance or quality. Balances cost and flexibility.


### 4. üîç Observability and Monitoring Tools

Observability platforms provide visibility into your RAG system‚Äôs behavior at both system-wide and component levels.

#### What Observability Provides

- Logs system traffic and metrics.
- Traces the path of each prompt through components like retrievers, rerankers, and the LLM.
- Measures latency at each step to identify bottlenecks.

#### Example: Phoenix by Arize

An open-source platform that captures detailed traces, showing:

- Initial prompt.
- Retriever queries and returned chunks.
- Reranker processing.
- Final prompt to the LLM.
- Generated response and latency.

#### Using Observability for Improvement

- Identify bugs and performance issues in real user traffic.
- Experiment with system changes and measure impact.
- Build a feedback loop to iteratively improve the system.


### 5. üóÉÔ∏è Custom Datasets and Data Analysis

Collecting and analyzing data from your RAG system is essential for targeted improvements.

#### What to Collect

- Prompts and responses for overall system evaluation.
- Component-level data like retrieved documents, reranker scores, and context precision.

#### Managing Dataset Size

Datasets can grow very large, so it‚Äôs important to store only what‚Äôs necessary for your evaluation goals.

#### Example Analysis

- Performance by topic (e.g., account setup, refunds).
- Component metrics like answer relevance and faithfulness.
- Identifying problems such as misrouted prompts or low-quality diagrams.

#### Visualizing Data

- Use clustering to group similar prompts and analyze trends.
- Classify queries into categories (technical, non-technical) for deeper insights.


### 6. üßÆ Quantization: Making Models Smaller and Faster

Large language models and embedding vectors require huge memory and compute resources. **Quantization** is a technique to compress these models and vectors to reduce costs and speed up inference.

#### What is Quantization?

- Converts 16-bit floating-point parameters to 8-bit or even 4-bit integers.
- Shrinks model size and memory footprint.
- Minimal loss in quality or retrieval relevance.

#### Quantization Process

- Divide the range of values into discrete sections.
- Store integers representing these sections along with scale and minimum values.
- Recover approximate original values during inference.

#### Benefits and Tradeoffs

- 8-bit quantization delivers strong performance with only minor drops in accuracy.
- 1-bit quantization compresses models even more but may reduce quality noticeably.
- Use smaller vectors for quick retrieval, then full vectors for precise reranking.


### 7. üí∞ Cost Optimization in RAG Systems

Running RAG systems in production can be expensive. Key cost drivers include:

- LLM inference and generation.
- Storage and querying of vector databases.

#### Strategies to Reduce Costs

- Use smaller or quantized models where possible.
- Fine-tune small models for specific tasks.
- Retrieve fewer documents by reducing top_k.
- Use system prompts to encourage shorter responses.
- Host models on dedicated cloud endpoints to control costs.
- Optimize vector database storage by:

  - Keeping indexes in RAM for speed.
  - Moving rarely accessed data to SSD or cloud object storage.
  - Using multi-tenancy to separate user data and load only what‚Äôs needed.


### 8. ‚ö° Latency and Performance Optimization

Latency is critical, especially in applications like e-commerce or medical diagnosis where speed affects user experience or outcomes.

#### Latency Breakdown

- Most latency comes from the transformer-based LLM calls.
- Retrieval and database queries are usually fast.

#### Techniques to Reduce Latency

- Use router LLMs to skip unnecessary steps.
- Employ smaller or quantized LLMs.
- Implement caching:

  - **Direct caching:** Return cached responses for similar prompts immediately.
  - **Personalized caching:** Adjust cached responses with a small LLM for better relevance.

- Remove components that don‚Äôt improve performance.
- Use database sharding to split large indexes.
- Leverage cloud provider tools for scaling.


### 9. üîí Security and Privacy in RAG Systems

Security is paramount when your knowledge base contains private or proprietary information.

#### Key Security Practices

- Authenticate users properly to control access.
- Use tenant separation to isolate data by user or group.
- Encrypt text chunks stored in the database.
- Balance encryption with latency and complexity.
- Be aware of risks like vector reconstruction attacks, where attackers try to recover original text from embeddings.

#### Mitigation Techniques

- Add noise or transformations to vectors.
- Reduce vector dimensionality carefully.
- Run RAG systems locally or on-premises if needed for maximum control.


### 10. üñºÔ∏è Multimodal RAG Systems: Beyond Text

Modern RAG systems increasingly handle **multimodal data** ‚Äî not just text, but also images, PDFs, slides, audio, and video.

#### Requirements for Multimodal RAG

- Both retriever and LLM must understand multiple data types.
- Use multimodal embedding models that represent text and images in a shared vector space.
- Language-vision models process text and images together using unified transformers.

#### Handling PDFs and Slides

- Split documents into patches (small chunks).
- Vectorize patches for retrieval.
- Score patches based on similarity to query tokens.
- This approach is flexible and performs well but requires storing many vectors.


### 11. üèÅ Conclusion: Managing RAG Systems in Production

Running RAG systems in production is much more complex than prototyping. You must:

- Handle increased traffic and unpredictable user behavior.
- Monitor and evaluate system performance continuously.
- Balance trade-offs between cost, latency, and response quality.
- Secure your knowledge base against leaks and attacks.
- Support multimodal data to meet diverse user needs.

By building strong observability pipelines, collecting detailed data, and iteratively improving your system, you can maintain a robust, efficient, and secure RAG system that delivers high-quality responses at scale.


### Summary

This module covered the full lifecycle of RAG systems in production, from scaling challenges and unpredictable inputs to evaluation, optimization, security, and multimodal capabilities. Understanding these aspects is essential for deploying reliable, cost-effective, and secure RAG systems that serve real-world applications.



<br>

## Questions

#### 1. What are the primary challenges when scaling a RAG system in production?  
A) Increased latency and load on memory and compute resources  
B) Predictable user prompts that simplify testing  
C) Maintaining high performance while handling more traffic  
D) Decreasing the number of requests to reduce costs  

#### 2. Why is unpredictability of user prompts a significant challenge for RAG systems?  
A) Because users often ask questions that are nonsensical or out of scope  
B) Because all prompts can be anticipated with enough testing  
C) Because unpredictable prompts can cause unexpected system failures  
D) Because it allows the system to cache all possible responses  

#### 3. Which of the following are common issues with real-world data used in RAG systems?  
A) Data is often fragmented and missing metadata  
B) Data is always clean and well-structured  
C) Much data is non-textual, such as images and PDFs  
D) Data extraction tools are unnecessary for knowledge base construction  

#### 4. What are the key software performance metrics to monitor in a RAG system?  
A) Latency, throughput, memory usage, and compute usage  
B) User satisfaction and response quality  
C) Number of human feedback ratings collected  
D) Token usage and citation accuracy  

#### 5. Which evaluation method balances cost and flexibility by using a language model to judge relevance?  
A) Code-based evaluators  
B) Human feedback  
C) LLM as a judge  
D) Automated unit tests  

#### 6. What is the main benefit of using human feedback in RAG system evaluation?  
A) It is the cheapest evaluation method  
B) It captures nuances that automated methods miss  
C) It requires no manual effort  
D) It can be scaled infinitely without cost  

#### 7. How does caching improve latency in RAG systems?  
A) By skipping the retrieval step entirely  
B) By returning cached responses for similar prompts immediately  
C) By feeding cached responses and user prompts to a small LLM for personalization  
D) By increasing the number of documents retrieved  

#### 8. Which of the following are true about quantization in RAG systems?  
A) It reduces model size by converting parameters to lower-bit integers  
B) It always causes significant drops in model accuracy  
C) 8-bit quantization offers a good balance between compression and performance  
D) 1-bit quantization compresses models by 32x but may reduce quality noticeably  

#### 9. What are effective strategies to reduce vector database costs?  
A) Store the entire index in RAM regardless of size  
B) Move rarely accessed vectors to slower storage like SSD or cloud object storage  
C) Use multi-tenancy to separate tenant data and load only what is needed  
D) Avoid sharding indexes across multiple instances  

#### 10. Why is latency primarily caused by the transformer component in a RAG pipeline?  
A) Because retrieval and database queries are computationally expensive  
B) Because transformer-based LLM calls require significant compute time  
C) Because rerankers always add the most latency  
D) Because caching eliminates all latency from transformers  

#### 11. Which of the following are valid methods to secure a RAG knowledge base?  
A) Authenticate users to restrict access to authorized data only  
B) Store all tenant data in a single database without separation  
C) Encrypt text chunks and decrypt them only when building prompts  
D) Run the entire RAG system locally on-premises for maximum control  

#### 12. What risks are associated with vector databases in RAG systems?  
A) Vector reconstruction attacks that recover original text from embeddings  
B) Complete immunity to hacking due to encryption  
C) Data leakage if vectors are stored unencrypted  
D) No risk because vectors cannot be reverse-engineered  

#### 13. In multimodal RAG systems, what is the role of a multimodal embedding model?  
A) To represent text and images in a shared vector space  
B) To process only text data for retrieval  
C) To tokenize images into patch-based tokens for transformer input  
D) To separate text and image processing into different pipelines  

#### 14. How does PDF RAG handle information-dense documents like slides and PDFs?  
A) By treating the entire document as a single vector  
B) By splitting documents into patches and vectorizing each patch  
C) By ignoring images and charts in the document  
D) By using sophisticated detection algorithms to extract text only  

#### 15. Which of the following best describes the trade-offs involved in production RAG system optimization?  
A) Always prioritize response quality over cost and latency  
B) Balance cost, speed, and quality to meet application requirements  
C) Minimize latency at the expense of system security  
D) Ignore user satisfaction metrics to reduce compute costs  

#### 16. What is the purpose of a router LLM in a RAG pipeline?  
A) To generate final responses to user prompts  
B) To skip unnecessary processing steps and reduce latency  
C) To cache responses for repeated queries  
D) To encrypt knowledge base documents  

#### 17. Why might you choose to quantize embedding vectors before retrieval?  
A) To increase recall@K benchmarks significantly  
B) To reduce memory footprint and speed up retrieval with minimal quality loss  
C) To make vectors incompatible with approximate nearest neighbor (ANN) algorithms  
D) To eliminate the need for reranking  

#### 18. How can multi-tenancy improve vector database efficiency?  
A) By storing all users‚Äô data in a single large index  
B) By dividing documents by tenant and loading data into RAM only when needed  
C) By moving tenant data into faster storage only during their active time zone  
D) By duplicating all tenant data across all storage tiers  

#### 19. Which of the following are true about logging and observability in RAG systems?  
A) They help trace individual prompts through the entire pipeline  
B) They are unnecessary if you have human feedback  
C) They enable experimentation and A/B testing of system changes  
D) They only capture system-wide metrics, not component-level details  

#### 20. What are the main reasons for implementing multimodal RAG systems?  
A) To handle only text-based queries more efficiently  
B) To incorporate images, PDFs, audio, and video into retrieval and generation  
C) To use a unified transformer that understands relationships between text and images  
D) To reduce the number of tokens processed by the LLM



<br>

## Answers

#### 1. What are the primary challenges when scaling a RAG system in production?  
A) ‚úì Increased latency and load on memory and compute resources ‚Äî More traffic increases resource demands.  
B) ‚úó Predictable user prompts that simplify testing ‚Äî Prompts are unpredictable, not predictable.  
C) ‚úì Maintaining high performance while handling more traffic ‚Äî Critical to keep performance despite scaling.  
D) ‚úó Decreasing the number of requests to reduce costs ‚Äî Not a challenge but a hypothetical solution, not a scaling challenge itself.  

**Correct:** A, C


#### 2. Why is unpredictability of user prompts a significant challenge for RAG systems?  
A) ‚úì Because users often ask questions that are nonsensical or out of scope ‚Äî Real users can be creative or confusing.  
B) ‚úó Because all prompts can be anticipated with enough testing ‚Äî Impossible to predict every prompt.  
C) ‚úì Because unpredictable prompts can cause unexpected system failures ‚Äî Unhandled inputs can break the system.  
D) ‚úó Because it allows the system to cache all possible responses ‚Äî Unpredictability makes caching all responses impossible.  

**Correct:** A, C


#### 3. Which of the following are common issues with real-world data used in RAG systems?  
A) ‚úì Data is often fragmented and missing metadata ‚Äî Real data is messy and incomplete.  
B) ‚úó Data is always clean and well-structured ‚Äî Rarely true in production.  
C) ‚úì Much data is non-textual, such as images and PDFs ‚Äî Multimodal data is common.  
D) ‚úó Data extraction tools are unnecessary for knowledge base construction ‚Äî Extraction tools are essential for non-text data.  

**Correct:** A, C


#### 4. What are the key software performance metrics to monitor in a RAG system?  
A) ‚úì Latency, throughput, memory usage, and compute usage ‚Äî Core system performance metrics.  
B) ‚úó User satisfaction and response quality ‚Äî These are quality metrics, not software performance metrics.  
C) ‚úó Number of human feedback ratings collected ‚Äî Not a software performance metric.  
D) ‚úì Token usage and citation accuracy ‚Äî Token usage relates to compute; citation accuracy is a quality metric but often tracked alongside performance.  

**Correct:** A, D (D is borderline but relevant)


#### 5. Which evaluation method balances cost and flexibility by using a language model to judge relevance?  
A) ‚úó Code-based evaluators ‚Äî Cheap but inflexible.  
B) ‚úó Human feedback ‚Äî Most costly, not cost-effective.  
C) ‚úì LLM as a judge ‚Äî Balances cost and flexibility well.  
D) ‚úó Automated unit tests ‚Äî Limited to code correctness, not relevance judgment.  

**Correct:** C


#### 6. What is the main benefit of using human feedback in RAG system evaluation?  
A) ‚úó It is the cheapest evaluation method ‚Äî It is the most expensive.  
B) ‚úì It captures nuances that automated methods miss ‚Äî Humans understand subtle quality aspects.  
C) ‚úó It requires no manual effort ‚Äî Requires significant manual work.  
D) ‚úó It can be scaled infinitely without cost ‚Äî Scaling human feedback is costly.  

**Correct:** B


#### 7. How does caching improve latency in RAG systems?  
A) ‚úó By skipping the retrieval step entirely ‚Äî Retrieval is usually fast and necessary.  
B) ‚úì By returning cached responses for similar prompts immediately ‚Äî Avoids expensive generation.  
C) ‚úì By feeding cached responses and user prompts to a small LLM for personalization ‚Äî Improves relevance while saving time.  
D) ‚úó By increasing the number of documents retrieved ‚Äî Would increase latency, not reduce it.  

**Correct:** B, C


#### 8. Which of the following are true about quantization in RAG systems?  
A) ‚úì It reduces model size by converting parameters to lower-bit integers ‚Äî Core idea of quantization.  
B) ‚úó It always causes significant drops in model accuracy ‚Äî Usually minor drops, especially with 8-bit.  
C) ‚úì 8-bit quantization offers a good balance between compression and performance ‚Äî Widely used standard.  
D) ‚úì 1-bit quantization compresses models by 32x but may reduce quality noticeably ‚Äî Extreme compression with tradeoffs.  

**Correct:** A, C, D


#### 9. What are effective strategies to reduce vector database costs?  
A) ‚úó Store the entire index in RAM regardless of size ‚Äî Expensive and inefficient.  
B) ‚úì Move rarely accessed vectors to slower storage like SSD or cloud object storage ‚Äî Cost-effective tiering.  
C) ‚úì Use multi-tenancy to separate tenant data and load only what is needed ‚Äî Efficient resource use.  
D) ‚úó Avoid sharding indexes across multiple instances ‚Äî Sharding improves scalability and cost.  

**Correct:** B, C


#### 10. Why is latency primarily caused by the transformer component in a RAG pipeline?  
A) ‚úó Because retrieval and database queries are computationally expensive ‚Äî Usually fast operations.  
B) ‚úì Because transformer-based LLM calls require significant compute time ‚Äî Main bottleneck.  
C) ‚úó Because rerankers always add the most latency ‚Äî Rerankers are generally faster than LLMs.  
D) ‚úó Because caching eliminates all latency from transformers ‚Äî Caching helps but doesn‚Äôt eliminate transformer latency.  

**Correct:** B


#### 11. Which of the following are valid methods to secure a RAG knowledge base?  
A) ‚úì Authenticate users to restrict access to authorized data only ‚Äî Fundamental security practice.  
B) ‚úó Store all tenant data in a single database without separation ‚Äî Increases risk of data leakage.  
C) ‚úì Encrypt text chunks and decrypt them only when building prompts ‚Äî Protects data at rest.  
D) ‚úì Run the entire RAG system locally on-premises for maximum control ‚Äî Avoids cloud exposure.  

**Correct:** A, C, D


#### 12. What risks are associated with vector databases in RAG systems?  
A) ‚úì Vector reconstruction attacks that recover original text from embeddings ‚Äî Proven vulnerability.  
B) ‚úó Complete immunity to hacking due to encryption ‚Äî No system is completely immune.  
C) ‚úì Data leakage if vectors are stored unencrypted ‚Äî Unencrypted vectors can leak info.  
D) ‚úó No risk because vectors cannot be reverse-engineered ‚Äî Reverse engineering is possible.  

**Correct:** A, C


#### 13. In multimodal RAG systems, what is the role of a multimodal embedding model?  
A) ‚úì To represent text and images in a shared vector space ‚Äî Enables unified retrieval.  
B) ‚úó To process only text data for retrieval ‚Äî Multimodal means multiple data types.  
C) ‚úì To tokenize images into patch-based tokens for transformer input ‚Äî Part of image processing.  
D) ‚úó To separate text and image processing into different pipelines ‚Äî Multimodal models unify processing.  

**Correct:** A, C


#### 14. How does PDF RAG handle information-dense documents like slides and PDFs?  
A) ‚úó By treating the entire document as a single vector ‚Äî Too coarse, loses detail.  
B) ‚úì By splitting documents into patches and vectorizing each patch ‚Äî Enables fine-grained retrieval.  
C) ‚úó By ignoring images and charts in the document ‚Äî These are important information sources.  
D) ‚úó By using sophisticated detection algorithms to extract text only ‚Äî Modern approach uses patch vectorization, not just text extraction.  

**Correct:** B


#### 15. Which of the following best describes the trade-offs involved in production RAG system optimization?  
A) ‚úó Always prioritize response quality over cost and latency ‚Äî Must balance all three.  
B) ‚úì Balance cost, speed, and quality to meet application requirements ‚Äî Realistic approach.  
C) ‚úó Minimize latency at the expense of system security ‚Äî Security cannot be sacrificed.  
D) ‚úó Ignore user satisfaction metrics to reduce compute costs ‚Äî User satisfaction is critical.  

**Correct:** B


#### 16. What is the purpose of a router LLM in a RAG pipeline?  
A) ‚úó To generate final responses to user prompts ‚Äî That‚Äôs the main LLM‚Äôs job.  
B) ‚úì To skip unnecessary processing steps and reduce latency ‚Äî Routes prompts efficiently.  
C) ‚úó To cache responses for repeated queries ‚Äî Caching is a separate mechanism.  
D) ‚úó To encrypt knowledge base documents ‚Äî Not a router function.  

**Correct:** B


#### 17. Why might you choose to quantize embedding vectors before retrieval?  
A) ‚úó To increase recall@K benchmarks significantly ‚Äî Quantization may slightly reduce recall.  
B) ‚úì To reduce memory footprint and speed up retrieval with minimal quality loss ‚Äî Main benefit.  
C) ‚úó To make vectors incompatible with approximate nearest neighbor (ANN) algorithms ‚Äî Quantized vectors still work with ANN.  
D) ‚úó To eliminate the need for reranking ‚Äî Reranking is still needed for precision.  

**Correct:** B


#### 18. How can multi-tenancy improve vector database efficiency?  
A) ‚úó By storing all users‚Äô data in a single large index ‚Äî Inefficient and risky.  
B) ‚úì By dividing documents by tenant and loading data into RAM only when needed ‚Äî Saves resources.  
C) ‚úì By moving tenant data into faster storage only during their active time zone ‚Äî Optimizes cost and performance.  
D) ‚úó By duplicating all tenant data across all storage tiers ‚Äî Wasteful and costly.  

**Correct:** B, C


#### 19. Which of the following are true about logging and observability in RAG systems?  
A) ‚úì They help trace individual prompts through the entire pipeline ‚Äî Essential for debugging.  
B) ‚úó They are unnecessary if you have human feedback ‚Äî Observability complements feedback.  
C) ‚úì They enable experimentation and A/B testing of system changes ‚Äî Critical for iterative improvement.  
D) ‚úó They only capture system-wide metrics, not component-level details ‚Äî Good observability captures both.  

**Correct:** A, C


#### 20. What are the main reasons for implementing multimodal RAG systems?  
A) ‚úó To handle only text-based queries more efficiently ‚Äî Multimodal means handling multiple data types.  
B) ‚úì To incorporate images, PDFs, audio, and video into retrieval and generation ‚Äî Expands system capabilities.  
C) ‚úì To use a unified transformer that understands relationships between text and images ‚Äî Enables joint understanding.  
D) ‚úó To reduce the number of tokens processed by the LLM ‚Äî Multimodal often increases token count.  

**Correct:** B, C