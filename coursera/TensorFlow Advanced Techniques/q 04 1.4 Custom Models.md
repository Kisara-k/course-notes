## 1.4 Custom Models

## Questions

#### 1. What are the main advantages of subclassing `tf.keras.Model` over using the Sequential or Functional API?  
A) Ability to implement dynamic control flow inside the model  
B) Automatic generation of model summary without any code  
C) Support for models with loops or recursive connections  
D) Simplifies saving and loading models compared to Functional API  


#### 2. In the Wide and Deep model example, why is the auxiliary output added from the deep path?  
A) To provide an additional training signal that can improve convergence  
B) To reduce the number of parameters in the model  
C) To allow the model to predict multiple targets simultaneously  
D) To replace the main output during inference  


#### 3. Which of the following statements about the `call()` method in a subclassed model are true?  
A) It defines the forward pass of the model  
B) It must always return a single tensor output  
C) It can accept multiple inputs and return multiple outputs  
D) It is automatically called during `model.fit()` and `model.predict()`  


#### 4. What is a key limitation of the Sequential API that the Functional API overcomes?  
A) Sequential API cannot handle models with multiple inputs or outputs  
B) Sequential API cannot be saved or serialized  
C) Sequential API does not support activation functions  
D) Sequential API cannot be used for convolutional layers  


#### 5. Why are residual connections important in very deep neural networks?  
A) They prevent the network from overfitting by reducing parameters  
B) They help mitigate the vanishing gradient problem by allowing gradients to flow directly  
C) They increase the depth of the network without increasing computation  
D) They allow the network to learn identity mappings more easily  


#### 6. In the `CNNResidual` layer, what does the addition of `inputs + x` represent?  
A) Concatenation of input and output features  
B) A skip connection that adds the input tensor to the output of convolutional layers  
C) A method to normalize the output features  
D) A way to reduce the dimensionality of the output  


#### 7. Which of the following are true about the Functional API in TensorFlow/Keras?  
A) It represents models as Directed Acyclic Graphs (DAGs) of layers  
B) It supports dynamic loops and recursive connections natively  
C) It allows multiple inputs and outputs in a model  
D) It requires subclassing `Model` to define the forward pass  


#### 8. What is the primary role of Batch Normalization in ResNet blocks?  
A) To add non-linearity to the model  
B) To normalize activations and stabilize training  
C) To reduce the number of parameters in the model  
D) To perform dimensionality reduction before convolution  


#### 9. In the IdentityBlock class, why is the input tensor added to the output of the convolutional layers?  
A) To implement a residual connection that helps gradient flow  
B) To concatenate features for richer representations  
C) To enforce the output to have the same shape as the input  
D) To apply dropout regularization  


#### 10. Which of the following are reasons to use Global Average Pooling before the final dense layer in ResNet?  
A) To reduce the spatial dimensions to a single value per feature map  
B) To reduce the number of parameters and prevent overfitting  
C) To increase the spatial resolution of feature maps  
D) To replace fully connected layers with convolutional layers  


#### 11. When subclassing a model, which of the following are true about the `__init__` and `call` methods?  
A) `__init__` is used to define layers and initialize variables  
B) `call` defines the computation performed on inputs  
C) `call` must be called explicitly by the user during training  
D) Layers defined in `__init__` are automatically tracked by Keras  


#### 12. What is a key difference between the `CNNResidual` and `DNNResidual` classes shown in the lecture?  
A) `CNNResidual` uses convolutional layers, while `DNNResidual` uses dense layers  
B) `CNNResidual` adds inputs and outputs by concatenation, `DNNResidual` uses addition  
C) `DNNResidual` is only used for image data, `CNNResidual` for tabular data  
D) Both implement residual connections but differ in layer types  


#### 13. Which of the following statements about the ResNet architecture are correct?  
A) It uses large kernel convolutions (e.g., 7x7) at the beginning to capture broad features  
B) It relies solely on dense layers without convolutional layers  
C) It stacks multiple residual blocks to enable very deep networks  
D) It uses max pooling to reduce spatial dimensions early in the network  


#### 14. Why might the Functional and Sequential APIs be insufficient for some advanced neural network architectures?  
A) They cannot handle models with multiple outputs  
B) They do not support models with cycles or dynamic computation graphs  
C) They cannot be used with convolutional layers  
D) They require manual implementation of training loops  


#### 15. In the Wide and Deep model example, what is the purpose of concatenating the wide input with the output of the deep layers?  
A) To combine simple features with learned complex representations  
B) To reduce the dimensionality of the input data  
C) To enforce the model to use only linear transformations  
D) To separate the training of wide and deep parts of the model  


#### 16. Which of the following are true about saving and loading subclassed models?  
A) You can save the entire model architecture and weights using `model.save()`  
B) Subclassed models cannot be saved or loaded in TensorFlow  
C) You can save only the weights using `model.save_weights()`  
D) The Functional API models cannot be saved, only subclassed models can  


#### 17. What is the effect of repeating a residual block multiple times in a model, as shown in the `MyResidual` example?  
A) It increases the model’s depth and capacity to learn complex features  
B) It reduces the number of parameters by weight sharing  
C) It helps the model learn hierarchical feature representations  
D) It prevents overfitting by limiting the number of layers  


#### 18. In the ResNet example, what is the role of the `Activation('relu')` layer after batch normalization?  
A) To introduce non-linearity so the network can learn complex functions  
B) To normalize the output of the convolutional layers  
C) To reduce the dimensionality of the feature maps  
D) To perform element-wise addition with the input tensor  


#### 19. Which of the following are true about the training process of a ResNet model on a dataset like MNIST?  
A) The model can be compiled with an optimizer like Adam and a loss like sparse categorical crossentropy  
B) The dataset must be preprocessed and batched before training  
C) ResNet cannot be trained on simple datasets like MNIST due to its complexity  
D) The model’s accuracy can be monitored using metrics during training  


#### 20. What are the benefits of using subclassing to build modular architectures in TensorFlow/Keras?  
A) It allows quick experimentation with new ideas and architectures  
B) It forces the use of only sequential layers  
C) It enables control over the forward pass and custom training logic  
D) It restricts the model to only DAG structures



<br>

## Answers

#### 1. What are the main advantages of subclassing `tf.keras.Model` over using the Sequential or Functional API?  
A) ✓ Allows dynamic control flow inside the model, which Sequential/Functional APIs cannot handle  
B) ✗ Model summary is available in all APIs, not unique to subclassing  
C) ✓ Supports loops or recursive connections not possible in Sequential/Functional APIs  
D) ✗ Saving/loading is equally supported in Functional API  

**Correct:** A, C


#### 2. In the Wide and Deep model example, why is the auxiliary output added from the deep path?  
A) ✓ Provides an additional training signal that can improve convergence  
B) ✗ Auxiliary output does not reduce parameters; it adds complexity  
C) ✓ Allows predicting multiple targets or helps regularize training  
D) ✗ Auxiliary output is not a replacement for main output during inference  

**Correct:** A, C


#### 3. Which of the following statements about the `call()` method in a subclassed model are true?  
A) ✓ Defines the forward pass of the model  
B) ✗ Can return multiple outputs, not limited to one  
C) ✓ Can accept multiple inputs and return multiple outputs  
D) ✓ Automatically called during `fit()`, `predict()`, etc.  

**Correct:** A, C, D


#### 4. What is a key limitation of the Sequential API that the Functional API overcomes?  
A) ✓ Sequential API cannot handle multiple inputs or outputs; Functional API can  
B) ✗ Both APIs support saving and serialization  
C) ✗ Sequential API supports activation functions  
D) ✗ Sequential API supports convolutional layers  

**Correct:** A


#### 5. Why are residual connections important in very deep neural networks?  
A) ✗ They do not primarily reduce parameters or prevent overfitting  
B) ✓ Help mitigate vanishing gradients by allowing gradients to flow directly  
C) ✗ They increase depth but also increase computation  
D) ✓ Allow the network to learn identity mappings more easily  

**Correct:** B, D


#### 6. In the `CNNResidual` layer, what does the addition of `inputs + x` represent?  
A) ✗ It is addition, not concatenation  
B) ✓ Skip connection adding input tensor to output of conv layers  
C) ✗ Not a normalization method  
D) ✗ Does not reduce dimensionality; shapes must match  

**Correct:** B


#### 7. Which of the following are true about the Functional API in TensorFlow/Keras?  
A) ✓ Models are represented as DAGs of layers  
B) ✗ Does not support dynamic loops or recursion natively  
C) ✓ Supports multiple inputs and outputs  
D) ✗ Does not require subclassing to define forward pass  

**Correct:** A, C


#### 8. What is the primary role of Batch Normalization in ResNet blocks?  
A) ✗ It does not add non-linearity (activation does that)  
B) ✓ Normalizes activations to stabilize and speed up training  
C) ✗ Does not reduce parameters  
D) ✗ Does not perform dimensionality reduction  

**Correct:** B


#### 9. In the IdentityBlock class, why is the input tensor added to the output of the convolutional layers?  
A) ✓ Implements residual connection to help gradient flow  
B) ✗ It is addition, not concatenation  
C) ✓ Ensures output shape matches input for addition  
D) ✗ Not related to dropout  

**Correct:** A, C


#### 10. Which of the following are reasons to use Global Average Pooling before the final dense layer in ResNet?  
A) ✓ Reduces spatial dimensions to one value per feature map  
B) ✓ Reduces parameters and helps prevent overfitting  
C) ✗ Does not increase spatial resolution  
D) ✗ Does not replace fully connected layers with conv layers  

**Correct:** A, B


#### 11. When subclassing a model, which of the following are true about the `__init__` and `call` methods?  
A) ✓ `__init__` defines layers and initializes variables  
B) ✓ `call` defines computation on inputs  
C) ✗ `call` is called automatically, not manually by user  
D) ✓ Layers defined in `__init__` are tracked by Keras automatically  

**Correct:** A, B, D


#### 12. What is a key difference between the `CNNResidual` and `DNNResidual` classes shown in the lecture?  
A) ✓ `CNNResidual` uses Conv2D layers; `DNNResidual` uses Dense layers  
B) ✗ Both use addition, not concatenation  
C) ✗ CNNResidual is for images; DNNResidual is for dense data, not vice versa  
D) ✓ Both implement residual connections but differ in layer types  

**Correct:** A, D


#### 13. Which of the following statements about the ResNet architecture are correct?  
A) ✓ Uses large 7x7 convolutions at the start to capture broad features  
B) ✗ Uses convolutional layers extensively, not just dense layers  
C) ✓ Stacks multiple residual blocks to build very deep networks  
D) ✓ Uses max pooling early to reduce spatial dimensions  

**Correct:** A, C, D


#### 14. Why might the Functional and Sequential APIs be insufficient for some advanced neural network architectures?  
A) ✗ Both support multiple outputs  
B) ✓ Cannot handle cycles or dynamic computation graphs  
C) ✗ Both support convolutional layers  
D) ✗ Training loops can be customized but are available by default  

**Correct:** B


#### 15. In the Wide and Deep model example, what is the purpose of concatenating the wide input with the output of the deep layers?  
A) ✓ Combines simple features with complex learned representations  
B) ✗ Does not reduce dimensionality; concatenation increases it  
C) ✗ Does not enforce linear transformations only  
D) ✗ Does not separate training of wide and deep parts  

**Correct:** A


#### 16. Which of the following are true about saving and loading subclassed models?  
A) ✓ Entire model architecture and weights can be saved with `model.save()`  
B) ✗ Subclassed models can be saved and loaded, though with some caveats  
C) ✓ Weights can be saved separately with `model.save_weights()`  
D) ✗ Functional API models can also be saved  

**Correct:** A, C


#### 17. What is the effect of repeating a residual block multiple times in a model, as shown in the `MyResidual` example?  
A) ✓ Increases model depth and capacity to learn complex features  
B) ✗ Does not reduce parameters by weight sharing (no weight sharing shown)  
C) ✓ Helps learn hierarchical feature representations  
D) ✗ Does not inherently prevent overfitting  

**Correct:** A, C


#### 18. In the ResNet example, what is the role of the `Activation('relu')` layer after batch normalization?  
A) ✓ Introduces non-linearity for learning complex functions  
B) ✗ BatchNorm normalizes, activation adds non-linearity  
C) ✗ Does not reduce dimensionality  
D) ✗ Does not perform addition with input tensor  

**Correct:** A


#### 19. Which of the following are true about the training process of a ResNet model on a dataset like MNIST?  
A) ✓ Can be compiled with Adam optimizer and sparse categorical crossentropy loss  
B) ✓ Dataset must be preprocessed and batched before training  
C) ✗ ResNet can be trained on MNIST despite its complexity  
D) ✓ Accuracy can be monitored using metrics during training  

**Correct:** A, B, D


#### 20. What are the benefits of using subclassing to build modular architectures in TensorFlow/Keras?  
A) ✓ Allows quick experimentation with new ideas and architectures  
B) ✗ Does not force use of only sequential layers; it enables arbitrary architectures  
C) ✓ Enables control over forward pass and custom training logic  
D) ✗ Does not restrict model to DAG structures; supports dynamic graphs  

**Correct:** A, C